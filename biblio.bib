@PREAMBLE{ {\providecommand{\noopsort}[1]{}} }
@STRING{academic= {Academic Press} }
@STRING{acmmathsoft={{ACM} Trans. Math. Softw.} }
@STRING{acmpress= {{ACM} Press} }
@STRING{actanumerica={Acta Numer.} }
@STRING{adamhilger={Adam Hilger} }
@STRING{addisonwesley={Addison-Wesley} }
@STRING{allynbacon={Allyn and Bacon} }
@STRING{amermathmonthly={Amer. Math. Monthly} }
@STRING{amersocio={Amer. J. Sociology} }
@STRING{amerstatassoc={J. Amer. Statist. Assoc.} }
@STRING{ams	= {American Mathematical Society} }
@STRING{amstrans= {Amer. Math. Soc. Transl.} }
@STRING{annalsstats={Ann. Statist.} }
@STRING{applmathcomp={Appl. Math. Comput.} }
@STRING{appnummath={Appl. Numer. Math.} }
@STRING{athena	= {Athena Scientific} }
@STRING{birkhauser={Birkha{\"u}ser} }
@STRING{bit	= {{BIT}} }
@STRING{britstatpsych={Brit. J. Math. Statist. Psych.} }
@STRING{bullams	= {Bull. Amer. Math. Soc.} }
@STRING{cacm	= {Comm. {ACM}} }
@STRING{cambridgepress={Cambridge University Press} }
@STRING{canmathbull={Canad. Math. Bull.} }
@STRING{chelsea	= {Chelsea} }
@STRING{claredonpress={Claredon Press} }
@STRING{compapplmath={J. Comput. Appl. Math.} }
@STRING{computeappliedmath={Comput. Appl. Math.}}
@STRING{compapplopt={Comput. Optim. Appl.} }
@STRING{compjour= {Comput. J.} }
@STRING{compoptsoft={Comput. Optim. Softw.} }
@STRING{compphys= {J. Comput. Phys.} }
@STRING{compserv= {Comput. Surveys} }
@STRING{compstruct={Comput. \& Structures} }
@STRING{compsyssci={J. Comput. System Sci.} }
@STRING{computer= {{IEEE} Computer} }
@STRING{computing={Computing} }
@STRING{contempmath={Contemp. Math.} }
@STRING{crelle	= {Crelle's J.} }
@STRING{doverpub= {Dover Publications} }
@STRING{etna = {Elec. Trans. Numer. Anal.}}
@STRING{eyolles	= {Eyolles} }
@STRING{focm	= {Found. Comput. Math.} }
@STRING{geophysics={Geophys.} }
@STRING{giornalemath={Giorn. Mat.} }
@STRING{holtrinehartwinston={Holt, Rinehart and Winston} }
@STRING{ieeespec= {{IEEE} Spectrum} }
@STRING{ieeetransac={{IEEE} Trans. Automat. Control} }
@STRING{ieeetransaeroelec={{IEEE} Trans. Aerospace Electron. Systems} }
@STRING{ieeetranscomp={{IEEE} Trans. Comput.} }
@STRING{ieeetransimproc={{IEEE} Trans. Image Process.} }
@STRING{ieeetransinfo={{IEEE} Trans. Inform. Theory} }
@STRING{ieeetranssigproc={{IEEE} Trans. Sig. Proc.} }
@STRING{ieeesigprocmag={{IEEE} Sig. Proc. Mag.} }
@STRING{imanumerana={{IMA} J. Numer. Anal.} }
@STRING{imanumerana-={{IMA} Journal of Numerical Analysis} }
@STRING{imainfoinfer={{IMA} Inform. Inference} }
@STRING{infproclet={Inform. Process. Lett.} }
@STRING{infcomp={Inform. and Comput.} }
@STRING{instmathapp={J. Inst. Math. Appl.} }
@STRING{intcontrol={Internat. J. Control} }
@STRING{interscience={Interscience} }
@STRING{intnumereng={Internat. J. Numer. Methods Engrg.} }
@STRING{intsuper= {Internat. J. Supercomputing Applic.} }
@STRING{jacm	= {J. Assoc. Comput. Mach.} }
@STRING{jconvexanal={J. Convex Anal.} }
@STRING{johnshopkinspress={The Johns Hopkins University Press} }
@STRING{johnwileysons={John Wiley and Sons} }
@STRING{jota	= {J. Optim. Theory Appl.} }
@STRING{jmathimagingvis={J. Math. Imaging. Vis.} }
@STRING{jresnatburstand={J. Res. Nat. Bur. Standards} }
@STRING{jsiam	= {J. Soc. Indust. Appl. Math.} }
@STRING{jsiamb	= {J. Soc. Indust. Appl. Math. Ser. B Numer. Anal.} }
@STRING{jmaa = {J. Math. Anal. Appl.}}
@STRING{jmlr = {J. Mach. Learn. Res.}}
@STRING{kibernetika={Kibernetika} }
@STRING{linalgapp={Linear Algebra Appl.} }
@STRING{macmillan={Macmillan} }
@STRING{managesci={Mgmnt Sci.} }
@STRING{mathanaappl={J. Math. Anal. Appl.} }
@STRING{mathannalen={Math. Ann.} }
@STRING{mathcomp= {Math. Comp.} }
@STRING{mathofor= {Math. Op. Res.} }
@STRING{mathphys= {J. Math. Phys.} }
@STRING{mathprog= {Math. Program.} }
@STRING{mathprogb={Math. Program., Ser. B} }
@STRING{mathprogc={Math. Program. Comp.} }
@STRING{mathprogstudy={Math. Program. Study} }
@STRING{mathscand={Math. Scand.} }
@STRING{mathworks={The Math Works Inc.} }
@STRING{mcgrawhill={McGraw-Hill} }
@STRING{natburstd={National Bureau of Standards} }
@STRING{northholland={North-Holland} }
@STRING{numermath={Numer. Math.} }
@STRING{optimmeth={Optim. Methods Softw.} }
@STRING{oxfordpress={Oxford University Press} }
@STRING{orl={Oper. Res. Lett.} }
@STRING{pacificmath={Pacific J. Math.} }
@STRING{parcomputing={Parallel Comput.} }
@STRING{pardistcomp={J. Parallel and Distrib. Comput.} }
@STRING{pergamonpress={Pergamon Press} }
@STRING{philmag	= {Philos. Mag.} }
@STRING{plenumpress={Plenum Press} }
@STRING{prenticehall={Prentice-Hall} }
@STRING{procams	= {Proc. Amer. Math. Soc.} }
@STRING{procieee= {Proc. {IEEE}} }
@STRING{procnas	= {Proc.\@ Natl.\@ Acad.\@ Sci.\@ USA} }
@STRING{psychometrika={Psychometrika} }
@STRING{quartapplmath={Quart. Appl. Math.} }
@STRING{quartmath={Quart. J. Math. Oxford Ser. (2)} }
@STRING{revueinststat={Rev. Inst. Internat. Statist.} }
@STRING{royalstatsb={J. Royal Stat. Soc. Ser. B}}
@STRING{scientific={The Scientific Press} }
@STRING{siamalgmeth={{SIAM} J. Algebraic Discrete Methods} }
@STRING{siamappmath={{SIAM} J. Appl. Math.} }
@STRING{siamcomp= {{SIAM} J. Comput.} }
@STRING{siamcontrol={{SIAM} J. Control Optim.} }
@STRING{siammath= {{SIAM} J. Math. Anal.} }
@STRING{siammatrix={{SIAM} J. Matrix Anal. Appl.} }
@STRING{siammms	= {Multiscale Model. Simul.} }
@STRING{siamnumanal={{SIAM} J. Numer. Anal.} }
@STRING{siamopt	= {{SIAM} J. Optim.} }
@STRING{siampub	= {Society of Industrial and Applied Mathematics} }
@STRING{siamreview={{SIAM} Rev.} }
@STRING{siamscicomp={{SIAM} J. Sci. Comput.} }
@STRING{siamscistatcomp={{SIAM} J. Sci. Stat. Comput.} }
@STRING{siamsiims={{SIAM} J. Imag. Sci.} }
@STRING{signum	= {{ACM} {SIGNUM} Newslett.} }
@STRING{softpracexp={Software Prac. Experience} }
@STRING{springer= {Springer-Verlag} }
@STRING{stanford= {Stanford University Press} }
@STRING{statscience={Statist. Sci.} }
@STRING{tablesaidscomp={Math. Tables Aids Comput.} }
@STRING{techno	= {Technometrics} }
@STRING{texaspress={University of Texas Press} }
@STRING{transams= {Trans. Amer. Math. Soc.} }
@STRING{ussrcompmathphys={{U. S. S. R.} Comput. Math. and Math. Phys.} }
@STRING{vannostrand={Van Nostrand} }
@STRING{vlsicompsys={J. {VLSI} Comput. Syst.} }
@STRING{whfreeman={W. H. Freeman and Co.} }
@STRING{zangewmathmech={Z. Angew. Math. Mech.} }
@STRING{zangewmathphys={Z. Angew. Math. Phys.} }
@STRING{jmlr={J. Mach. Learn. Res.} }
@STRING{setvalued={Set-Valued Var. Anal.}}
@STRING{jasa={J. Amer. Statist. Assoc.}}

@misc{fan2020polar,
  author  =  {Z. Fan and H. Jeong and B. Joshi and M. P. Friedlander},
  title   =  {Polar deconvolution of mixed signal},
  eprint={2010.10508},
  archivePrefix={arXiv},
  year =         2020,
  primaryClass={cs.IR},
  usera = {1 2 3}
}

@ARTICLE{fang2020subgradient,
  author =       {H. Fang and Z. Fan and M. P. Friedlander},
  title =        {Smooth Structured Prediction Using Quantum and Classical Gibbs Samplers},
  journal =      {ArXiv e-prints},
  archivePrefix ="arXiv",
  eprint =       {1809.04091},
  year =         2018,
  month =        {October},
  usera = {}
}


@InProceedings{fang2020online,
    title={Online mirror descent and dual averaging: keeping pace in the dynamic case},
    author={Huang Fang and Nicholas J. A. Harvey and Victor S. Portella and Michael P. Friedlander},
    year={2020},
    booktitle={37th Intern. Conf. on Machine Learning (ICML)},
    usera = {1 3}
}

@InProceedings{sun19:_one,
  author = {Yifan Sun and Michael P. Friedlander},
  title =        {One-shot atomic detection},
  booktitle = {IEEE Intern. Workshop Comput. Adv. Multi-Sensor Adaptive Processing (CAMSAP)},
  year =      2019,
  usera = {1}
}

@article{fan2019alignment,
url = {http://dx.doi.org/10.1561/2400000028},
year = {2020},
volume = {3},
journal = {Foundations and Trends in Optimization},
title = {Atomic Decomposition via Polar Alignment: The Geometry of Structured Optimization},
doi = {10.1561/2400000028},
issn = {2167-3888},
number = {4},
pages = {280-366},
author = {Zhenan Fan and Halyun Jeong and Yifan Sun and Michael P. Friedlander},
usera = {1 2 3}
}
@InProceedings{fang2020greed,
  Author = {Huang Fang and Zhenan Fan and Yifan Sun and Michael P. Friedlander},
  Title = {Greed Meets Sparsity: Understanding and Improving Greedy Coordinate
                  Descent for Sparse Optimization},
  booktitle = {Proc. 22th Intern. Conf. Artificial Intelligence and Statistics (AISTATS)}, 
  Year = {2020},
  usera = {1 2 3}
}

@inproceedings{fan2019bundle,
  title={Bundle methods for dual atomic pursuit},
  author={Fan, Zhenan and Sun, Yifan and Friedlander, Michael P},
  booktitle={Asilomar Conference on Signals, Systems, and Computers (ACSSC 2019)},
  pages={264--270},
  year={2019},
  organization={IEEE},
  usera = {1 2}
}

@PhdThesis{Estrin2019,
  author =       {Ron Estrin},
  title =        {The Merits of Keeping It Smooth: Iterative Linear
                  Solvers and A Smooth Exact Penalty Function for
                  Constrained Nonlinear Optimization},
  school =       {Stanford University},
  year =         2019,
  usera = {1}
}

@article{estrin2020implementing,
  author  =  {R. Estrin and M. P. Friedlander and D. Orban and M. A. Saunders},
  usera   =  1,
  title   =  {Implementing a smooth exact penalty function for equality-constrained nonlinear optimization},
  journal =  {SIAM J. Sci. Comput.},
  volume  =  {42},
  number  =  {3},
  pages   =  {A1809–A1835},
  year    =  {2020},
  DOI     =  {10.1137/19M1238265},
}

@article{estrin2020general,
  author  =  {R. Estrin and M. P. Friedlander and D. Orban and M. A. Saunders},
  usera   =  1,
  title   =  {Implementing a smooth exact penalty function for general constrained nonlinear optimization},
  journal =  {SIAM J. Sci. Comput.},
  volume  =  {42},
  number  =  {3},
  pages   =  {A1836–A1859},
  year    =  {2020},
  DOI     =  {10.1137/19M1255069}
}

@InProceedings{fan2019fast,
  author =       {H. Fang and M. Cheng and C.-J. Hsieh and
                  M. P. Friedlander},
  title =        {Fast training for large-scale one-versus-all linear
                  classifiers using tree-structured initialization},
  year =         2019,
  booktitle =    {Proc. SIAM Inter. Conf. Data Mining (SDM19)},
  usera = {1}
}

@InProceedings{sephery2019smooth,
  author =       {B. Sepehry and E. Iranmanesh and M. P. Friedlander and P. Ronagh},
  title =        {Smooth Structured Prediction Using Quantum and Classical Gibbs Samplers},
  booktitle = {Proceedings of the Adiabatic Quantum Computing Conference
(AQC)},
year =         2019,
  month =        {June},
  usera = {}
}
@ARTICLE{2016arXiv160201506A,
  author =       {B. Sepehry and E. Iranmanesh and M. P. Friedlander and P. Ronagh},
  title =        {Smooth Structured Prediction Using Quantum and Classical Gibbs Samplers},
  journal =      {ArXiv e-prints},
  archivePrefix ="arXiv",
  eprint =       {1809.04091},
  year =         2018,
  month =        {October},
  usera = {}
}

@article{estrin2020perturbation,
  title={A perturbation view of level-set methods for convex optimization},
  author={Estrin, R. and Friedlander, M. P.},
  journal={Optimization Letters},
  pages={1--18},
  year={2020},
  publisher={Springer},
  usera = {1}
}

@ARTICLE{EstrinFriedlander:2018,
  author =       {R. Estrin and M. P. Friedlander},
  title =        {A perturbation view of level-set methods for convex
                  optimization},
  year =         2020,
  month =        {January},
  journal =      {Submitted to Optimization Letters},
  usera =        1
}

@ARTICLE{friedlander2019polarconvolution,
  author =       {M. P. Friedlander and I. Mac\^edo and T. K. Pong},
  title =        {Polar convolution},
  year =         2019,
  journal =      siamopt,
  volume =       29,
  number =       4,
  pages =        {1366--1391},
  usera =        {2 3}
}


@ARTICLE{FriedlanderGoh:2017,
  author =       {M. P. Friedlander and G. Goh},
  title =        {Efficient evaluation of scaled proximal operators},
  journal =      etna,
  year =         2017,
  volume =       46,
  pages =        {1-22},
  usera =        2
}

@article{FriedlanderKrislockPong:2016,
  title =        {Social Resistance},
  author =       {M. P. Friedlander and M. Krislock and T.  K. Pong},
  journal =      {IEEE Computing in Science and Engineering},
  year =         2016,
  note = {(Republished by Computing Edge, Aug 2016)},
  usera = {2 3}
}

@InProceedings{goh2016satisfying,
  author =       {G. Goh and A. Cotter and M. Gupta and
                  M. P. Friedlander},
  usera =        1,
  title =        {Satisfying Real-world Goals with Dataset
                  Constraints},
  booktitle =    {Advances in Neural Information Processing Systems
                  (NIPS 2016)},
  year =         2016,
  volume =       29,
  pages =        {2415--2423},
  url =
                  {http://papers.nips.cc/paper/6316-satisfying-real-world-goals-with-dataset-constraints.pdf},
}

@ARTICLE{friedlander2016low,
  author =       {M. P. Friedlander and I. Mac\^edo},
  title =        {Low-rank spectral optimization via gauge duality},
  journal =      siamscicomp,
  year =         2016,
  volume =       38,
  number =       3,
  pages =        {A1616-A1638},
  usera =        2
}


@ARTICLE{aravkin2016levelset,
  author =       {{Aravkin}, A.~Y. and {Burke}, J.~V. and
                  {Drusvyatskiy}, D. and {Friedlander}, M.~P. and
                  {Roy}, S.},
  title =        "{Level-set methods for convex optimization}",
  journal =      mathprogb,
  year =         2018,
  volume =       174,
  number =       {1-2},
  pages =        {359--390},
  month =        {December},
  doi =          {10.1007/s10107-018-1351-8},
  usera =        5
}

@ARTICLE{2017:1702.08649,
  author =       {{Aravkin}, A.~Y. and {Burke}, J.~V. and
                  {Drusvyatskiy}, D. and {Friedlander}, M.~P. and
                  {MacPhee}, K.},
  title =        "{Foundations of gauge and perspective duality}",
  journal =      {ArXiv e-prints},
  archivePrefix ="arXiv",
  eprint =       {1702.08649},
  primaryClass = "math.OC",
  keywords =     {Mathematics - Optimization and Control, Computer
                  Science - Numerical Analysis},
  year =         2017,
  month =        {February},
  note = {Submitted to SIAM Journal on Optimization},
  usera = {5}
}

@ARTICLE{aravkin2018foundations,
  author =       {A. Y. Aravkin and J. V. Burke and D. Drusvyatskiy
                  and M. P. Friedlander and K. MacPhee},
  title =        {Foundations of gauge and perspective duality},
  year =         2018,
  journal =      siamopt,
  volume =       28,
  number =       3,
  pages =        {2406-2434},
  doi =          {10.1137/17M1119020},
  usera =        5
}


@Article{aravkin2012robustmath,
  author =       {A. Y. Aravkin and M. P. Friedlander and
                  F. Herrmann and T. van Leeuwen},
  usera =        {1 4},
  title =        {Robust inversion, dimensionality reduction, and
                  randomized sampling},
  journal =      mathprog,
  year =         2012,
  volume =       134,
  number =       1,
  pages =        {101--125},
  usera = {1 4}
}

@Article{aravkin2013variational,
  author =       {A. Y. Aravkin and J. Burke and M. P. Friedlander},
  title =        {Variational properties of value functions},
  usera =        1,
  journal =      siamopt,
  volume =       23,
  number =       3,
  pages =        {1689-1717},
  year =         2013,
  doi =          {10.1137/120899157},
  eprint =       {http://epubs.siam.org/doi/pdf/10.1137/120899157},
}

@INPROCEEDINGS{aravkin2012robusticassp,
  author =       {A. Y. Aravkin and M. P. Friedlander and T. van
                  Leeuwen},
  usera =        {1 3},
  booktitle =    {2012 IEEE International Conference on Acoustics,
                  Speech, and Signal Processing (ICASSP)},
  title =        {Robust inversion via semistochastic dimensionality
                  reduction},
  year =         2012,
  month =        {March},
  pages =        {5245-5248},
  abstract =     {We consider a class of inverse problems where it is
                  possible to aggregate the results of multiple
                  experiments. This class includes problems where the
                  forward model is the solution operator to linear
                  ODEs or PDEs. The tremendous size of such problems
                  motivates the use dimensionality reduction (DR)
                  techniques based on randomly mixing
                  experiments. These techniques break down, however,
                  when robust data-fitting formulations are used,
                  which are essential in cases of missing data,
                  unusually large errors, and systematic features in
                  the data unexplained by the forward model. We survey
                  robust methods within a statistical framework, and
                  propose a sampling optimization approach that allows
                  DR. The efficacy of the methods are demonstrated for
                  a large-scale seismic inverse problem using the
                  robust Student's t-distribution, where a useful
                  synthetic velocity model is recovered in the extreme
                  scenario of 60\% corrupted data. The sampling
                  approach achieves this recovery using 20\% of the
                  effort required by a direct robust approach.},
  doi =          {10.1109/ICASSP.2012.6289103},
  ISSN =         {1520-6149},
}

@article{berg2008probing,
  Author =       {E. van den Berg and M. P. Friedlander},
  usera =        1,
  Title =        {Probing the {Pareto} frontier for basis pursuit
                  solutions},
  year =         2008,
  journal =      siamscicomp,
  volume =       31,
  number =       2,
  pages =        {890-912},
  keywords =     {basis pursuit, convex program, duality,
                  root-finding, Newton's method, projected gradient,
                  one-norm regularization, sparse solutions },
  doi =          {10.1137/080714488},
  abstract =     { The basis pursuit problem seeks a minimum one-norm
                  solution of an underdetermined least-squares
                  problem. Basis pursuit denoise (BPDN) fits the
                  least-squares problem only approximately, and a
                  single parameter determines a curve that traces the
                  optimal trade-off between the least-squares fit and
                  the one-norm of the solution. We prove that this
                  curve is convex and continuously differentiable over
                  all points of interest, and show that it gives an
                  explicit relationship to two other optimization
                  problems closely related to BPDN.  We describe a
                  root-finding algorithm for finding arbitrary points
                  on this curve; the algorithm is suitable for
                  problems that are large scale and for those that are
                  in the complex domain. At each iteration, a spectral
                  gradient-projection method approximately minimizes a
                  least-squares problem with an explicit one-norm
                  constraint. Only matrix-vector operations are
                  required. The primal-dual solution of this problem
                  gives function and derivative information needed for
                  the root-finding method. Numerical experiments on a
                  comprehensive set of test problems demonstrate that
                  the method scales well to large problems.}
}

@PhdThesis{Berg:2009,
  author =       {E. van den Berg},
  usera =        1,
  title =        {Convex optimization for generalized sparse recovery},
  school =       {University of British Columbia},
  year =         2009,
  month =        {December}
}

@misc{BergFrie:2007b,
  Author =       {E. van den Berg and M. P. Friedlander},
  usera =        1,
  url =          {https://www.cs.ubc.ca/~mpf/spgl1/},
  Month =        {May},
  Title =        {{SPGL1}: A solver for large-scale sparse
                  reconstruction},
  Year =         2013
}


@techreport{BergFrie:2008tr,
  Author =       {E. van den Berg and M. P. Friedlander},
  usera =        1,
  Address =      {University of British Columbia, Vancouver},
  Institution =  {Department of Computer Science},
  Number =       {TR-2008-01},
  Title =        {Probing the {Pareto} frontier for basis pursuit
                  solutions},
  Type =         {Tech. rep.},
  Month =        {January},
  Year =         2008,
  Note =         {To appear in {\it SIAM J. Sci. Comp.}},
  abstract =     { The basis pursuit problem seeks a minimum one-norm
                  solution of an underdetermined least-squares
                  problem. Basis pursuit denoise (BPDN) fits the
                  least-squares problem only approximately, and a
                  single parameter determines a curve that traces the
                  optimal trade-off between the least-squares fit and
                  the one-norm of the solution. We prove that this
                  curve is convex and continuously differentiable over
                  all points of interest, and show that it gives an
                  explicit relationship to two other optimization
                  problems closely related to BPDN.  We describe a
                  root-finding algorithm for finding arbitrary points
                  on this curve; the algorithm is suitable for
                  problems that are large scale and for those that are
                  in the complex domain. At each iteration, a spectral
                  gradient-projection method approximately minimizes a
                  least-squares problem with an explicit one-norm
                  constraint. Only matrix-vector operations are
                  required. The primal-dual solution of this problem
                  gives function and derivative information needed for
                  the root-finding method. Numerical experiments on a
                  comprehensive set of test problems demonstrate that
                  the method scales well to large problems.}
}


@InProceedings{khan2013fast,
  author =       {M. E. Khan and A. Y. Aravkin and
                  M. P. Friedlander and M. Seeger},
  usera =        {1 2},
  title =        {Fast dual variational inference for non-conjugate
                  latent gaussian models},
  booktitle =    {Proc.\@ 30th Inter.\@ Conf.\@ on Machine Learning
                  (ICML-13)},
  year =         2013,
  address =      {Atlanta},
  month =        {May}
}

@Article{BergFrieHennHerrSaabYilm:2008,
  author =       {E. van den Berg and M. P. Friedlander and
                  G. Hennenfent and F. J. Herrmann and R. Saab and
                  O. Yilmaz},
  usera =        {1 3 5},
  title =        "Algorithm 890: {Sparco}: A Testing Framework for
                  Sparse Reconstruction",
  journal =      acmmathsoft,
  volume =       35,
  number =       4,
  year =         2008,
  accepted =     "10 June 2008",
  upcoming =     "true",
  abstract =     "Sparco is a framework for testing and benchmarking
                  algorithms for sparse reconstruction. It includes a
                  large collection of sparse reconstruction problems
                  drawn from the imaging, compressed sensing, and
                  geophysics literature.  Sparco is also a framework
                  for implementing new test problems and can be used
                  as a tool for reproducible research.  Sparco is
                  implemented entirely in Matlab, and is released as
                  open-source software under the GNU Public License.",
}

@Article{BergFrieHennHerrSaabYilm:2008tr,
  Address =      {University of British Columbia, Vancouver},
  Author =       {E. van den Berg and M. P. Friedlander and
                  G.  Hennenfent and F. Herrmann and
                  R. Saab and O.  Yilmaz},
  usera =        {1 3 5},
  Institution =  {Dept. Computer Science},
  Month =        {July},
  Number =       {TR-2007-20},
  Title =        {Sparco: {A} testing framework for sparse
                  reconstruction},
  Type =         {Tech. rep.},
  Year =         2008,
  url =          {http://www.cs.ubc.ca/labs/scl/sparco/},
  note =         {To appear in {\it ACM Trans.\@ on Math. Soft.}},
  abstract =     { Sparco is a framework for testing and benchmarking
                  algorithms for sparse reconstruction. It includes a
                  large collection of sparse reconstruction problems
                  drawn from the imaging, compressed sensing, and
                  geophysics literature. Sparco is also a framework
                  for implementing new test problems and can be used
                  as a tool for reproducible research. Sparco is
                  implemented entirely in Matlab, and is released as
                  open-source software under the GNU Public License. }
}

@techreport{BergFried:2009,
  Address =      {University of British Columbia, Vancouver},
  Author =       {E. van den Berg and M. P. Friedlander},
  usera =        1,
  Institution =  {Department of Computer Science},
  Month =        {September},
  Type =         {Tech. Rep.},
  Number =       {TR-2009-7},
  Title =        {Theoretical and empirical results for recovery from
                  multiple measurements},
  Year =         2009,
  Note =         {To appear in {\it IEEE Trans.\@ Inform.\@ Theory}}
}

@techreport{BergFriedlander2007,
  author =       {E. van den Berg and M. P. Friedlander},
  usera =        1,
  title =        {In pursuit of a root},
  institution =  {Dept. of Computer Science, {UBC}},
  year =         2007,
  number =       {TR-2007-19},
  month =        {June},
  abstract =     {The basis pursuit technique is used to find a
                  minimum one-norm solution of an underdetermined
                  least-squares problem. Basis pursuit denoise fits
                  the least-squares problem only approximately, and a
                  single parameter determines a curve that traces the
                  trade-off between the least-squares fit and the
                  one-norm of the solution. We show that the function
                  that describes this curve is convex and continuously
                  differentiable over all points of interest. The dual
                  solution of a least-squares problem with an explicit
                  one-norm constraint gives function and derivative
                  information needed for a root-finding method. As a
                  result, we can compute arbitrary points on this
                  curve. Numerical experiments demonstrate that our
                  method, which relies on only matrix-vector
                  operations, scales well to large problems.},
  note =         {8pp}
}

@Article{berg2010theoretical,
  author =       {E. van den Berg and M. P. Friedlander},
  usera =        1,
  Title =        {Theoretical and empirical results for recovery from
                  multiple measurements},
  journal =      ieeetransinfo,
  year =         2010,
  volume =       56,
  number =       5,
  pages =        {2516-2527},
  DOI =          {10.1109/TIT.2010.2043876}
}

@article{berg2011sparse,
  Author =       {E. van den Berg and M. P. Friedlander},
  usera =        1,
  Title =        {Sparse optimization with least-squares constraints},
  Journal =      siamopt,
  Volume =       21,
  Number =       4,
  Pages =        {1201--1229},
  Year =         2011,
  doi =          {10.1137/100785028}
}


@InProceedings{schmidt2014coordinate,
  author =       {M. Schmidt and M. P. Friedlander},
  title =        {Coordinate descent converges faster with the
                  {Gauss-Southwell} rule than random selection},
  booktitle =    {NIPS Workshop on Optimization},
  year =         2014,
  usera = {},
}

@techreport{BergSchmFrieMurp:2008,
  author =       {E. van den Berg and M. Schmidt
                  and M. P. Friedlander and K. Murphy},
  usera =        {1 2},
  title =        {Group sparsity via linear-time projection},
  institution =  {Dept. of Computer Science, University of British
                  Columbia},
  year =         2008,
  number =       {TR-2008-09},
  month =        {June},
  abstract =     {We present an efficient spectral projected-gradient
                  algorithm for optimization subject to a group
                  one-norm constraint. Our approach is based on a
                  novel linear-time algorithm for Euclidean projection
                  onto the one- and group one-norm
                  constraints. Numerical experiments on large data
                  sets suggest that the proposed method is
                  substantially more efficient and scalable than
                  existing methods.},
  note =          {8pp}
}

@mastersthesis{Crowe:2010,
  Address =      {Vancouver},
  Author =       {Mitch Crowe},
  usera =        1,
  Month =        {August},
  School =       {Dept. Computer Science, University of British
                  Columbia},
  Title =        {Nonlinearly constrained optimization via sequential
                  regularized linear programming},
  Year =         2010
}

@techreport{DeMiFrieNogaScho:2004,
  Address =      {Argonne, IL},
  Author =       {A.-V. DeMiguel and M. P. Friedlander and
                  F. J. Nogales and S. Scholtes},
  usera = {},
  Institution =  {Argonne National Laboratory},
  Month =        {April},
  Number =       {ANL/MCS-P1150-0404},
  Title =        {An interior-point method for {MPECs} based on
                  strictly feasible relaxations},
  Year =         2004,
  note =         {28pp}
}

@article{DeMiFrieNogaScho:2005,
  author =       {A. V. DeMiguel and M. P. Friedlander and F. Nogales
                  and S. Scholtes},
  usera =        {},
  title =        {A two-sided relaxation scheme for mathematical
                  programs with equilibrium constraints},
  journal =      siamopt,
  volume =       16,
  number =       2,
  pages =        {587-609},
  year =         2005,
  doi =          {10.1137/04060754x},
  abstract =     {We propose a relaxation scheme for mathematical
                  programs with equilibrium constraints (MPECs). In
                  contrast to previous approaches, our relaxation is
                  two-sided: both the complementarity and the
                  nonnegativity constraints are relaxed. The proposed
                  relaxation update rule guarantees (under certain
                  conditions) that the sequence of relaxed subproblems
                  will maintain a strictly feasible interior---even in
                  the limit. We show how the relaxation scheme can be
                  used in combination with a standard interior-point
                  method to achieve superlinear convergence. Numerical
                  results on the MacMPEC test problem set demonstrate
                  the fast local convergence properties of the
                  approach.}
}

@Article{friedlander2012recovering,
  author =       {M. P. Friedlander and H. Mansour and
                  R. Saab and O. Yilmaz},
  usera =        {2 3},
  title =        {Recovering compressively sampled signals using
                  partial support information},
  journal =      {IEEE Trans. Inform. Theory},
  year =         2012,
  volume =       58,
  number =       2,
  pages =        {1122--1134}
}

@phdthesis{Frie:2002,
  Address =      {Stanford, CA},
  usera =        {},
  Author =       {M. P. Friedlander},
  Month =        {August},
  School =       {Stanford University},
  Title =        {A globally convergent linearly constrained
                  {L}agrangian method for nonlinearly constrained
                  optimization},
  Year =         2002
}

@techreport{Frie:2005,
  Address =      {University of British Columbia, Vancouver},
  usera =        {},
  Author =       {M. P. Friedlander},
  Institution =  {Dept. Computer Science},
  Month =        {December},
  Number =       {TR-2005-31},
  Title =        {Exact regularization of linear programs},
  Type =         {Tech. rep.},
  Year =         2005,
  note =         {10pp}
}

@unpublished{Frie:2006,
  Author =       {M. P. Friedlander},
  usera =        {},
  Note =         {Available at \url{http://www.cs.ubc.ca/~mpf/bcls/}},
  Title =        {{BCLS}: {A} large-scale solver for bound-constrained
                  least squares},
  Year =         2006
}

@techreport{FrieGold:1999a,
  Author =       {M. P. Friedlander and M. J. Goldbach},
  usera =        {},
  Institution =  {Rapt Technologies},
  Month =        {July},
  Number =       {TR-7-99},
  Title =        {Algebraic segmentation of disconnected {MCMP}
                  graphs},
  Year =         1999
}

@techreport{FrieGold:1999b,
  Author =       {M. P. Friedlander and M. J. Goldbach},
  usera =        {},
  Institution =  {Rapt Technologies},
  Month =        {November},
  Number =       {TR-11-99},
  Title =        {Multivariate normal distributions induced by
                  rank-deficient linear transformations},
  Year =         1999
}

@techreport{FrieGold:2000,
  Author =       {M. P. Friedlander and M. J. Goldbach},
  usera =        {},
  Institution =  {Rapt Technologies},
  Month =        {January},
  Number =       {TR-1-00},
  Title =        {Optimal marginal procurement: A constrained
                  optimization approach},
  Year =         2000
}

@techreport{FrieGoulLeyfMuns:2007,
  Author =       {M. P. Friedlander and N. I. M. Gould and S. Leyffer
                  and T. S. Munson},
  usera =        {},
  Institution =  {Argonne National Laboratory},
  Month =        {September},
  Number =       {ANL/MCS-P1456-0907},
  Title =        {A filter active-set trust-region method},
  Type =         {Preprint},
  Year =         2007
}

@techreport{FrieGupt:2004,
  Author =       {M. P. Friedlander and M. R. Gupta},
  usera =        {},
  Date-Modified ={2007-07-31 16:32:55 -0700},
  Institution =  {Argonne National Laboratory},
  Month =        {September},
  Note =         {ANL/MCS-P1110-1203.},
  Title =        {On minimizing distortion and relative entropy},
  Year =         2004
}

@article{friedlander2006distortion,
  author =       {M. P. Friedlander and M. Gupta},
  usera =        {},
  title =        {On minimizing distortion and relative entropy},
  Journal =      IEEETransInfo,
  volume =       52,
  number =       1,
  year =         2006,
  abstract =     {A common approach for estimating a probability mass
                  function $w$ when given a prior $q$ and moment
                  constraints given by $Aw < b$ is to minimize the
                  relative entropy between $w$ and $q$ subject to the
                  set of linear constraints. In such cases, the
                  solution $w$ is known to have exponential form. We
                  consider the case in which the linear constraints
                  are noisy, uncertain, infeasible, or otherwise
                  ``soft'' A solution can then be obtained by
                  minimizing both the relative entropy and violation
                  of the constraints $Aw < b$. A penalty parameter
                  $\sigma$ weights the relative importance of these
                  two objectives.We show that this penalty formulation
                  also yields a solution $w$ with exponential form. If
                  the distortion is based on an $L_{p}$norm, then the
                  exponential form of $w$ is shown to have exponential
                  decay parameters that are bounded as a function of
                  $\sigma$. We also state conditions under which the
                  solution $w$ to the penalty formulation will result
                  in zero distortion, so that the moment constraints
                  hold exactly. These properties are useful in
                  choosing penalty parameters, evaluating the impact
                  of chosen penalty parameters, and proving properties
                  about methods that use such penalty formulations.},
  doi =          {10.1109/TIT.2005.860448}
}

@techreport{FrieHatz:2007,
  author =       {M. P. Friedlander and K. Hatz},
  usera =        2,
  title =        {Computing nonnegative tensor factorizations},
  institution =  {Dept. of Computer Science},
  year =         2007,
  number =       {TR-2006-21},
  month =        {October},
  abstract =     {Nonnegative tensor factorization (NTF) is a
                  technique for computing a parts-based representation
                  of high-dimensional data. NTF excels at exposing
                  latent structures in datasets, and at finding good
                  low-rank approximations to the data. We describe an
                  approach for computing the NTF of a dataset that
                  relies only on iterative linear-algebra techniques
                  and that is comparable in cost to the nonnegative
                  matrix factorization. (The better-known nonnegative
                  matrix factorization is a special case of NTF and is
                  also handled by our implementation.) Some important
                  features of our implementation include mechanisms
                  for encouraging sparse factors and for ensuring that
                  they are equilibrated in norm. The complete Matlab
                  software package is available under the GPL
                  license.},
}

@article{friedlander2008computing,
  Author =       {M. P. Friedlander and K. Hatz},
  usera =        2,
  Month =        {March},
  Journal =      compoptsoft,
  Title =        {Computing Nonnegative Tensor Factorizations},
  Year =         2008,
  DOI =          {10.1080/10556780801996244},
  abstract =     {Nonnegative tensor factorization (NTF) is a
                  technique for computing a parts-based representation
                  of high-dimensional data. NTF excels at exposing
                  latent structures in datasets, and at finding good
                  low-rank approximations to the data. We describe an
                  approach for computing the NTF of a dataset that
                  relies only on iterative linear-algebra techniques
                  and that is comparable in cost to the nonnegative
                  matrix factorization. (The better-known nonnegative
                  matrix factorization is a special case of NTF and is
                  also handled by our implementation.) Some important
                  features of our implementation include mechanisms
                  for encouraging sparse factors and for ensuring that
                  they are equilibrated in norm. The complete Matlab
                  software package is available under the GPL
                  license.},
  volume =       23,
  number =       4,
  pages =        {631-647},
}

@techreport{FrieLeyf:2007,
  Title =        {Global and finite termination of a two-phase
                  augmented {L}agrangian filter method for general
                  quadratic programs},
  Author =       {M. P. Friedlander and S. Leyffer},
  usera =        {},
  Abstract =     { We present a two-phase algorithm for solving
                  large-scale quadratic programs (QPs).  In the first
                  phase, gradient-projection iterations approximately
                  minimize an augmented Lagrangian function and
                  provide an estimate of the optimal active set.  In
                  the second phase, an equality-constrained QP defined
                  by the current inactive variables is approximately
                  minimized in order to generate a second-order search
                  direction.  A filter determines the required
                  accuracy of the subproblem solutions and provides an
                  acceptance criterion for the search directions.  The
                  resulting algorithm is globally and finitely
                  convergent.  The algorithm is suitable for
                  large-scale problems with many degrees of freedom,
                  and provides an alternative to interior-point
                  methods when iterative methods must be used to solve
                  the underlying linear systems.  Numerical
                  experiments on a subset of the CUTEr QP test
                  problems demonstrate the effectiveness of the
                  approach.  },
  Address =      {University of British Columbia, Vancouver, BC,
                  Canada},
  Institution =  {Department of Computer Science},
  Month =        {September},
  Note =         {To appear {\it SIAM J. Sci. Comp.}},
  Number =       {TR-2007-16},
  Type =         {Tech. rep.},
  Year =         2007
}

@article{FrieLeyf:2008,
  author =       {M. P. Friedlander and S. Leyffer},
  usera =        {},
  title =        {Global and finite termination of a two-phase
                  augmented {L}agrangian filter method for general
                  quadratic programs},
  Abstract =     { We present a two-phase algorithm for solving
                  large-scale quadratic programs (QPs).  In the first
                  phase, gradient-projection iterations approximately
                  minimize an augmented Lagrangian function and
                  provide an estimate of the optimal active set.  In
                  the second phase, an equality-constrained QP defined
                  by the current inactive variables is approximately
                  minimized in order to generate a second-order search
                  direction.  A filter determines the required
                  accuracy of the subproblem solutions and provides an
                  acceptance criterion for the search directions.  The
                  resulting algorithm is globally and finitely
                  convergent.  The algorithm is suitable for
                  large-scale problems with many degrees of freedom,
                  and provides an alternative to interior-point
                  methods when iterative methods must be used to solve
                  the underlying linear systems.  Numerical
                  experiments on a subset of the CUTEr QP test
                  problems demonstrate the effectiveness of the
                  approach.},
  publisher =    {SIAM},
  year =         2008,
  journal =      siamscicomp,
  volume =       30,
  number =       4,
  pages =        {1706-1729},
  keywords =     {large-scale optimization; quadratic programming;
                  gradient projection; active-set methods; filter
                  methods; augmented {L}agrangian},
  doi =          {10.1137/060669930}
}

@article{friedlander2012primal,
  Author =       {M. P. Friedlander and D. Orban},
  usera =        {},
  Title =        {A primal-dual regularized interior-point method for
                  convex quadratic programs},
  Year =         2012,
  journal =      mathprogc,
  volume =       4,
  number =       1,
  pages =        {71--107}
}

@unpublished{FrieSaun:2003,
  Author =       {M. P. Friedlander and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Note =         {http://www.stanford.edu/group/SOL/talks.html},
  Title =        {An {LCL} implementation for nonlinear optimization,
                  {{\rm presented at 18th International Symposium on
                  Mathematical Programming, Copenhagen, Denmark}}},
  Year =         {August 2003}
}

@article{FrieSaun:2005,
  author =       {M. P. Friedlander and M. A. Saunders},
  usera =        {},
  title =        {A globally convergent linearly constrained
                  {Lagrangian} method for nonlinear optimization},
  journal =      siamopt,
  volume =       15,
  number =       3,
  pages =        {863-897},
  year =         2005,
  doi =          {10.1137/S1052623402419789},
  abstract =     {For optimization problems with nonlinear
                  constraints, linearly constrained Lagrangian (LCL)
                  methods solve a sequence of subproblems of the form
                  "minimize an augmented Lagrangian function subject
                  to linearized constraints." Such methods converge
                  rapidly near a solution but may not be reliable from
                  arbitrary starting points. Nevertheless, the
                  well-known software package MINOS has proved
                  effective on many large problems. Its success
                  motivates us to derive a related LCL algorithm that
                  possesses three important properties: it is globally
                  convergent, the subproblem constraints are always
                  feasible, and the subproblems may be solved
                  inexactly. The new algorithm has been implemented in
                  \textsc{Matlab}, with an option to use either MINOS
                  or SNOPT (Fortran codes) to solve the linearly
                  constrained subproblems. Only first derivatives are
                  required. We present numerical results on a subset
                  of the COPS, HS, and CUTE test problems, which
                  include many large examples. The results demonstrate
                  the robustness and efficiency of the stabilized LCL
                  procedure.}
}

@Article{FrieSaun:2007,
  Author =       {M. P. Friedlander and M. A. Saunders},
  usera =        {},
  title =        {Discussion: the {Dantzig} selector: statistical
                  estimation when $p$ is much larger than $n$},
  journal =      annalsstats,
  year =         2007,
  volume =       35,
  number =       6,
  pages =        {2385-2391},
  month =        {December},
  doi =          {10.1214/009053607000000479}
}

@misc{FrieSaun:2007tr,
  title =        {Discussion: the {Dantzig} selector: {Statistical}
                  estimation when $p$ is much larger than $n$},
  Address =      {University of British Columbia, Vancouver, BC,
                  Canada},
  Author =       {M. P. Friedlander and M. A. Saunders},
  usera =        {},
  Howpublished = {To appear in {\it Ann. Statist.}},
  Institution =  {Department of Computer Science},
  Year =         2007
}

@techreport{FrieTsen:2006,
  Address =      {University of British Columbia, Vancouver, BC,
                  Canada},
  usera =        {},
  Author =       {M. P. Friedlander and P. Tseng},
  Institution =  {Department of Computer Science},
  Month =        {November},
  Note =         {To appear in {\it SIAM J. Optim.}},
  Number =       {TR-2006-26},
  Title =        {Exact regularization of convex programs},
  Year =         2006
}

@article{friedlander2007exact,
  Abstract =     { The regularization of a convex program is
                  \emph{exact} if all solutions of the regularized
                  problem are also solutions of the original problem
                  for all values of the regularization parameter below
                  some positive threshold.  For a general convex
                  program, we show that the regularization is exact if
                  and only if a certain selection problem has a
                  Lagrange multiplier. Moreover, the regularization
                  parameter threshold is inversely related to the
                  Lagrange multiplier.  We use this result to
                  generalize an exact regularization result of Ferris
                  and Mangasarian (1991) involving a linearized
                  selection problem.  We also use it to derive
                  necessary and sufficient conditions for exact
                  penalization, similar to those obtained by Bertsekas
                  (1975) and by Bertsekas, Nedi\'c, and Ozdaglar
                  (2003).  When the regularization is not exact, we
                  derive error bounds on the distance from the
                  regularized solution to the original solution set.
                  We also show that existence of a ``weak sharp
                  minimum'' is in some sense close to being necessary
                  for exact regularization.  We illustrate the main
                  result with numerical experiments on the $\ell_1$
                  regularization of benchmark (degenerate) linear
                  programs and semidefinite/second-order cone
                  programs.  The experiments demonstrate the
                  usefulness of $\ell_1$ regularization in finding
                  sparse solutions.  },
  Author =       {M. P. Friedlander and P. Tseng},
  usera =        {},
  Doi =          {10.1137/060675320},
  Journal =      siamopt,
  Keywords =     {Exact regularization},
  Number =       4,
  Pages =        {1326--1350},
  Title =        {Exact regularization of convex programs},
  Volume =       18,
  Year =         2007
}

@Misc{FriedlanderGoh:2012,
  author =       {M. P. Friedlander and G. Goh},
  usera =        2,
  title =        {Tail bounds for stochastic approximation},
  year =         2013,
  month =        {April},
  archivePrefix ="arXiv",
  eprint =       "1304.5586",
  primaryClass = "math.OC",
  note =         {Revised January 2014}
}

@Misc{FriedlanderMacedoPong:2013,
  author =       {M. P. Friedlander and I. Mac\^edo and T. K. Pong},
  usera =        {2 3},
  title =        {Gauge optimization, duality, and applications},
  year =         2013,
  month =        {October},
  archivePrefix ="arXiv",
  eprint =       "1310.2639",
  note =         {Submitted to {\it SIAM J. on Optimization}}
}



@InProceedings{nutini2015coordinate,
  author =       {J. Nutini and I. Laradji and M. Schmidt and
                  M. P. Friedlander},
  title =        {Coordinate Descent Converges Faster with the
                  {Gauss-Southwell} Rule Than Random Selection},
  booktitle =    {Inter. Conf. Mach. Learning (ICML 2015)},
  year =         2015,
  usera = {1 2}
}

@Article{friedlander2014gauge,
  author =       {M. P. Friedlander and I. Mac\^edo and T. K. Pong},
  usera =        {2 3},
  title =        {Gauge optimization and duality},
  year =         2014,
  journal =      siamopt,
  number =       4,
  volume =       24,
  pages =        {1999-2022}
}

@article{stodden2010reproducible,
  title =        {Reproducible research: Addressing the need for data
                  and code sharing in computational science},
  author =       {Stodden, Victoria C},
  journal =      {Computing in Science \& Engineering},
  volume =       12,
  number =       5,
  pages =        {8--12},
  year =         2010
}

@Article{friedlander2011hybrid,
  title =        {Hybrid deterministic-stochastic methods for data
                  fitting},
  author =       {M. P. Friedlander and M. Schmidt},
  usera =        2,
  journal =      siamscicomp,
  year =         2012,
  volume =       34,
  number =       3,
  pages =        {A1380-A1405},
  doi =          {10.1137/110830629},
  eprint =       {http://epubs.siam.org/doi/pdf/10.1137/110830629}
}

@mastersthesis{Garr:2008,
  Address =      {Vancouver},
  Author =       {M. F. Garrido},
  usera =        1,
  Month =        {August},
  School =       {Dept. Computer Science, University of British
                  Columbia},
  Title =        {An all-at-once approach for computing nonnegative
                  tensor factorizations},
  Year =         2008
}

@inproceedings{GuptFrieGray:2000,
  Abstract =     {We present a new method for classijication using the
                  maximum entropy principle, allowing full use of
                  relevant training data and smoothing the data
                  space. To classify a test point we compute a maximum
                  entropy weight distribution over a subset of
                  training data and constrain the weights to exactly
                  reconstruct the test point. The classification
                  problem is formulated as a linearly constrained
                  optimization problem and solved using a primal-dual
                  logarithmic barrier method, well suited for
                  high-dimensional data. We discuss theoretical
                  advantages and present experimental results on vowel
                  data which demonstrate that the method performs
                  competitively for speech classification tasks.},
  Address =      {Pacific Grove, California},
  Author =       {M. R. Gupta and M. P. Friedlander and R. M. Gray},
  usera =        {},
  Booktitle =    {Conference Record of the Thirty-Fourth Asilomar
                  Conference on Signals, Systems and Computers, 2000.},
  Month =        {October},
  Pages =        {1480-1483},
  Title =        {Maximum entropy classification applied to speech},
  Volume =       2,
  Year =         2000
}

@Article{herrmann2012fighting,
  author =       {F. J. Herrmann and M. P. Friedlander and O. Yilmaz},
  title =        {Fighting the curse of dimensionality: compressive
                  sensing in exploration seismology},
  usera = {},
journal =      {IEEE Signal Proc. Magazine},
  year =         2012,
  volume =       29,
  number =       3,
  pages =        {88--100},
  doi =          {10.1109/MSP.2012.2185859}
}

@article{hennenfent2008insights,
  Title =        {New insights into one-norm solvers from the {Pareto}
                  curve},
  Author =       {G. Hennenfent and E. van den
                  Berg and M. P.  Friedlander and F. J. Herrmann},
  usera =        {1 2},
  Volume =       73,
  Number =       4,
  Journal =      geophysics,
  Month =        {July--August},
  pages =        {A23--A26},
  Year =         2008,
  abstract =     { Geophysical inverse problems typically involve a
                  trade off between data misfit and some prior. Pareto
                  curves trace the optimal trade off between these two
                  competing aims. These curves are commonly used in
                  problems with two-norm priors where they are plotted
                  on a log-log scale and are known as L-curves. For
                  other priors, such as the sparsity-promoting one
                  norm, Pareto curves remain relatively unexplored. We
                  show how these curves lead to new insights into
                  one-norm regularization. First, we confirm the
                  theoretical properties of smoothness and convexity
                  of these curves from a stylized and a geophysical
                  example. Second, we exploit these crucial properties
                  to approximate the Pareto curve for a large-scale
                  problem. Third, we show how Pareto curves provide an
                  objective criterion to gauge how different one-norm
                  solvers advance towards the solution.},
  doi =          {10.1190/1.2944169}
}

@inproceedings{leblond2007diffuse,
  author =       {F. Leblond and S. Fortier and M. P. Friedlander},
  usera =        {},
  title =        {Diffuse optical fluorescence tomography using
                  time-resolved data acquired in transmission},
  booktitle =    {Multimodal Biomedical Imaging II, vol. 6431, Proc.\@
                  Inter.\@ Soc.\@ of Optical Imaging},
  year =         2007,
  month =        {February},
  abstract =     {We present an algorithm using data acquired with a
                  time-resolved system with the goal of reconstructing
                  sources of fluorescence emanating from the deep
                  interior of highly scattering biological tissues. A
                  novelty in our tomography algorithm is the
                  integration of a light transport model adapted to
                  rodent geometries. For small volumes, our analysis
                  suggest that neglecting the index of refraction
                  mismatch between diffusive and non-diffusive
                  regions, as well as the curved nature of the
                  boundary, can have a profound impact on fluorescent
                  images and spectroscopic applications relying on
                  diffusion curve fitting. Moreover, we introduce a
                  new least-squares solver with bound constraints
                  adapted for optical problems where a physical
                  non-negative constraint can be imposed. Finally, we
                  find that maximizing the time-related information
                  content of the data in the reconstruction process
                  significantly enhances the quality of fluorescence
                  images. Preliminary noise propagation and detector
                  placement optimization analysis are also presented.}
}

@inproceedings{schmidt2009optimizing,
  Author =       {M. Schmidt and E. van den Berg
                  and M. P. Friedlander and K. Murphy},
  usera =        {1 2},
  Title =        {Optimizing costly functions with simple constraints:
                  a limited-memory projected quasi-{N}ewton algorithm},
  Booktitle =    {Proc.\@ 12th Inter.\@ Conf.\@ Artificial
                  Intelligence and Stat.},
  Location =     {Clearwater Beach, Florida},
  Year =         2009,
  Pages =        {448--455},
  Month =        {April},
  note =         {(Received best-paper award.)}
}

@mastersthesis{Shan:2008,
  Address =      {Vancouver},
  Author =       {Shidong Shan},
  usera =        1,
  Month =        {August},
  School =       {Dept. Computer Science, University of British
                  Columbia},
  Title =        {A {Levenberg-Marquardt} method for large-scale
                  bound-constrained nonlinear least-squares},
  Year =         2008
}

@mastersthesis{Siro:2007,
  Author =       {J. Sirovljevic},
  usera =        1,
  Address =      {Vancouver},
  Month =        {August},
  School =       {Dept. Computer Science, University of British
                  Columbia},
  Title =        {Incomplete Factorization Preconditioners for Least
                  Squares and Linear and Quadratic Programming},
  Year =         2007
}

@article{BergFriedlander:2008,
  Author = {E. van den Berg and M. P. Friedlander},
  Title = {Probing the Pareto frontier for basis pursuit solutions},
  publisher = {SIAM},
  year = {2008},
  journal = siamscicomp,
  volume = {31},
  number = {2},
  pages = {890-912},
  url = {http://link.aip.org/link/?SCE/31/890},
  doi = {10.1137/080714488}
}

@article{burke2013epi,
  title={Epi-convergent smoothing with applications to convex composite functions},
  author={Burke, James V and Hoheisel, Tim},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={3},
  pages={1457--1479},
  year={2013},
  publisher={SIAM}
}

@article{mazumder2010spectral,
  title={Spectral regularization algorithms for learning large incomplete matrices},
  author={Mazumder, Rahul and Hastie, Trevor and Tibshirani, Robert},
  journal={Journal of machine learning research},
  volume={11},
  number={Aug},
  pages={2287--2322},
  year={2010}
}

@inproceedings{hsieh2014nuclear,
  title={Nuclear Norm Minimization via Active Subspace Selection.},
  author={Hsieh, Cho-Jui and Olsen, Peder A},
  year={2014},
  booktitle = {Proceedings of ICML},
}

@inproceedings{FangZSH17,
  author    = {Huang Fang and
               Zhen Zhang and
               Yiqun Shao and
               Cho{-}Jui Hsieh},
  title     = {Improved Bounded Matrix Completion for Large-Scale Recommender Systems},
  booktitle = {Proceedings of IJCAI},
  pages     = {1654--1660},
  publisher = {ijcai.org},
  year      = {2017}
}

@inproceedings{Lin11,
  author = "Zhouchen Lin and M. Chen and L. q. Wu and Yi Ma",
  title = "Linearized Alternating Direction Method with Adaptive Penalty for Low Rank Representation",
  booktitle = {Proceedings of NeurIPS},
  year = "2011",
}

@article{YuanLZ17,
  author    = {Xiao{-}Tong Yuan and
               Ping Li and
               Tong Zhang},
  title     = {Gradient Hard Thresholding Pursuit},
  journal   = {J. Mach. Learn. Res.},
  volume    = {18},
  pages     = {166:1--166:43},
  year      = {2017}
}

@article{DingYCTU21,
  author    = {Lijun Ding and
               Alp Yurtsever and
               Volkan Cevher and
               Joel A. Tropp and
               Madeleine Udell},
  title     = {An Optimal-Storage Approach to Semidefinite Programming Using Approximate
               Complementarity},
  journal   = {{SIAM} J. Optim.},
  volume    = {31},
  number    = {4},
  pages     = {2695--2725},
  year      = {2021}
}

@inproceedings{Allen-ZhuHHL17,
  author    = {Zeyuan Allen{-}Zhu and
               Elad Hazan and
               Wei Hu and
               Yuanzhi Li},
  title     = {Linear Convergence of a Frank-Wolfe Type Algorithm over Trace-Norm
               Balls},
  booktitle = {Proceedings of NeurIPS},
  pages     = {6191--6200},
  year      = {2017},
}

@article{meng2008lagrangian,
  title={Lagrangian-dual functions and Moreau--Yosida regularization},
  author={Meng, Fanwen and Zhao, Gongyun and Goh, Mark and De Souza, Robert},
  journal={SIAM Journal on Optimization},
  volume={19},
  number={1},
  pages={39--61},
  year={2008},
  publisher={SIAM}
}

@article{meng2005semismoothness,
  title={Semismoothness of solutions to generalized equations and the Moreau-Yosida regularization},
  author={Meng, Fanwen and Sun, Defeng and Zhao, Gongyun},
  journal={Mathematical programming},
  volume={104},
  number={2-3},
  pages={561--581},
  year={2005},
  publisher={Springer}
}

@article{chierchia2015epigraphical,
  title={Epigraphical projection and proximal tools for solving constrained convex optimization problems},
  author={Chierchia, Giovanni and Pustelnik, Nelly and Pesquet, J-C and Pesquet-Popescu, B{\'e}atrice},
  journal={Signal, Image and Video Processing},
  volume={9},
  number={8},
  pages={1737--1749},
  year={2015},
  publisher={Springer}
}


@article{mclean2002spectral,
  title={Spectral factorizations and sums of squares representations via semidefinite programming},
  author={McLean, Jeremy W and Woerdeman, Hugo J},
  journal=siammatrix,
  volume={23},
  number={3},
  pages={646--655},
  year={2002},
  publisher={SIAM}
}

@book{vershynin2018high,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge University Press}
}

@inproceedings{vasilescu2002multilinear,
  author = {Vasilescu, M. A. O. and Terzopoulos, Demetri},
  title = {Multilinear Analysis of Image Ensembles: TensorFaces},
  year = {2002},
  isbn = {3540437452},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 7th European Conference on Computer Vision-Part I},
  pages = {447–460},
  numpages = {14},
  series = {ECCV ’02}
}

@inproceedings{valiant1977graph,
  title={Graph-theoretic arguments in low-level complexity},
  author={Valiant, Leslie G},
  booktitle={International Symposium on Mathematical Foundations of Computer Science},
  pages={162--176},
  year={1977},
  organization={Springer}
}

@article{savas2007digit,
  title={Handwritten digit classification using higher order singular value decomposition},
  author={Savas, B. and Eldén, L.},
  journal={Pattern Recognition},
  volume={40},
  pages={993–1003},
  year={2007}
}

@article{quiros2012dependent,
  title={Dependent Gaussian mixture models for source separation},
  author={Quir{\'o}s, Alicia and Wilson, Simon P},
  journal={EURASIP Journal on Advances in Signal Processing},
  volume={2012},
  number={1},
  pages={239},
  year={2012},
  publisher={Springer}
}

@incollection{tropp2015convex,
  title={Convex recovery of a structured signal from independent random linear measurements},
  author={Tropp, Joel A},
  booktitle={Sampling Theory, a Renaissance},
  pages={67--101},
  year={2015},
  publisher={Springer}
}

@article{pati1994phase,
  title={Phase-shifting masks for microlithography: automated design and mask requirements},
  author={Pati, YC and Kailath, Thomas},
  journal={JOSA A},
  volume={11},
  number={9},
  pages={2438--2452},
  year={1994},
  publisher={Optical Society of America}
}

@article{ong2016beyond,
  title={Beyond low rank+ sparse: Multiscale low rank matrix decomposition},
  author={Ong, Frank and Lustig, Michael},
  journal={IEEE journal of selected topics in signal processing},
  volume={10},
  number={4},
  pages={672--687},
  year={2016},
  publisher={IEEE}
}

@article{obert1991angle,
  title={The angle between two cones},
  author={Obert, David G},
  journal={Linear Algebra and its Applications},
  volume={144},
  pages={63--70},
  year={1991},
  publisher={Elsevier}
}

@article{mccoy2013achievable,
  title={The achievable performance of convex demixing},
  author={McCoy, Michael B and Tropp, Joel A},
  journal={arXiv preprint arXiv:1309.7478},
  year={2013}
}

@article{mccoy2014convexity,
  title={Convexity in source separation: Models, geometry, and algorithms},
  author={McCoy, Michael B and Cevher, Volkan and Dinh, Quoc Tran and Asaei, Afsaneh and Baldassarre, Luca},
  journal={IEEE Signal Processing Magazine},
  volume={31},
  number={3},
  pages={87--95},
  year={2014},
  publisher={IEEE}
}

@inproceedings{maleki2009coherence,
  title={Coherence analysis of iterative thresholding algorithms},
  author={Maleki, Arian},
  booktitle={2009 47th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  pages={236--243},
  year={2009},
  organization={IEEE}
}

@incollection{gordon1988milman,
  title={On {Milman's} inequality and random subspaces which escape through a mesh in {$R^n$}},
  author={Gordon, Yehoram},
  booktitle={Geometric Aspects of Functional Analysis},
  pages={84--106},
  year={1988},
  publisher={Springer}
}

@inproceedings{jaggi2013revisiting,
  title={Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization.},
  author={Jaggi, Martin},
  booktitle =    {Inter. Conf. Mach. Learning (ICML 2013)},
  pages={427--435},
  year={2013}
}

@book{ledoux2001concentration,
  title={The concentration of measure phenomenon},
  author={Ledoux, Michel},
  number={89},
  year={2001},
  publisher={American Mathematical Soc.}
}

@article{claerbout1973robust,
  title={Robust modeling with erratic data},
  author={Claerbout, Jon F and Muir, Francis},
  journal={Geophysics},
  volume={38},
  number={5},
  pages={826--844},
  year={1973},
  publisher={Society of Exploration Geophysicists}
}

@article{fazel1998approximations,
  title={Approximations for partially coherent optical imaging systems},
  author={Fazel, M and Goodman, J},
  journal={Technical Report},
  year={1998}
}

@article{chan2008convex,
  title={A convex analysis framework for blind separation of non-negative sources},
  author={Chan, Tsung-Han and Ma, Wing-Kin and Chi, Chong-Yung and Wang, Yue},
  journal={IEEE Transactions on Signal Processing},
  volume={56},
  number={10},
  pages={5120--5134},
  year={2008},
  publisher={IEEE}
}

@article{chandrasekaran2009sparse,
  title={Sparse and low-rank matrix decompositions},
  author={Chandrasekaran, Venkat and Sanghavi, Sujay and Parrilo, Pablo A and Willsky, Alan S},
  journal={IFAC ProcMilmaneedings Volumes},
  volume={42},
  number={10},
  pages={1493--1498},
  year={2009},
  publisher={Elsevier}
}

@article{carando2008atomic,
  title={Atomic decompositions for tensor products and polynomial spaces},
  author={Carando, Daniel and Lassalle, Silvia},
  journal={Journal of mathematical analysis and applications},
  volume={347},
  number={1},
  pages={243--254},
  year={2008},
  publisher={Elsevier}
}

@article{bobin2007morphological,
  title={Morphological component analysis: An adaptive thresholding strategy},
  author={Bobin, J{\'e}r{\^o}me and Starck, Jean-Luc and Fadili, Jalal M and Moudden, Yassir and Donoho, David L},
  journal={IEEE transactions on image processing},
  volume={16},
  number={11},
  pages={2675--2681},
  year={2007},
  publisher={IEEE}
}

@article{amelunxen2014living,
  title={Living on the edge: Phase transitions in convex programs with random data},
  author={Amelunxen, Dennis and Lotz, Martin and McCoy, Michael B and Tropp, Joel A},
  journal={Information and Inference: A Journal of the IMA},
  volume={3},
  number={3},
  pages={224--294},
  year={2014},
  publisher={OUP}
}

@inproceedings{araki2009blind,
  title={Blind sparse source separation for unknown number of sources using Gaussian mixture model fitting with Dirichlet prior},
  author={Araki, Shoko and Nakatani, Tomohiro and Sawada, Hiroshi and Makino, Shoji},
  booktitle={2009 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={33--36},
  year={2009},
}

@article{tibshirani1997lasso,
  title={The lasso method for variable selection in the Cox model},
  author={Tibshirani, Robert},
  journal={Stat. Med.},
  volume={16},
  number={4},
  pages={385--395},
  year={1997},
  publisher={Wiley Online Library}
}

@book{zalinescu2002convex,
  title={Convex analysis in general vector spaces},
  author={Z\u alinescu, Constantin},
  year={2002},
  publisher={World scientific}
}

@inproceedings{ndiaye2016gap,
  title={Gap safe screening rules for sparse-group lasso},
  author={Ndiaye, Eugene and Fercoq, Olivier and Gramfort, Alexandre and Salmon, Joseph},
  booktitle={Advances in Neural Information Processing Systems
                  (NIPS 2016)},
  pages={388--396},
  year={2016}
}

@Misc{		  1401.4220,
  author =       {Sahar Karimi and Stephen Vavasis},
  title =        {{IMRO}: a proximal quasi-{Newton} method for solving
                  $\ell_1$-regularized least square problem},
  year =         2014,
  eprint =       {arXiv:1401.4220}
}

@article{freund2017extended,
  title={An extended {Frank-Wolfe} method with “in-face” directions, and its application to low-rank matrix completion},
  author={Freund, Robert M and Grigas, Paul and Mazumder, Rahul},
  journal=siamopt,
  volume={27},
  number={1},
  pages={319--346},
  year={2017},
  publisher={SIAM}
}

@article{bell2007lessons,
  title =        {Lessons from the {Netflix} prize challenge},
  author =       {Bell, Robert M and Koren, Yehuda},
  journal =      {ACM SIGKDD Explorations Newsletter},
  volume =       9,
  number =       2,
  pages =        {75--79},
  year =         2007,
  publisher =    {ACM}
}

@Article{	  2015arxiv150607868w,
  author =       {{White}, C.~D. and {Sanghavi}, S. and {Ward}, R.},
  title =        "{The local convexity of solving systems of quadratic
                  equations}",
  journal =      {ArXiv e-prints},
  archiveprefix ="arXiv",
  eprint =       {1506.07868},
  primaryclass = "math.NA",
  keywords =     {Mathematics - Numerical Analysis, Mathematics - Optimization
                  and Control, Statistics - Machine Learning},
  year =         2015,
  month =        jun,
  adsurl =       {http://adsabs.harvard.edu/abs/2015arXiv150607868W},
  adsnote =      {Provided by the SAO/NASA Astrophysics Data System}
}

@Article{	  7029630,
  author =       {Candes, E.J. and Xiaodong Li and Soltanolkotabi, M.},
  journal =      ieeetransinfo,
  title =        {Phase Retrieval via Wirtinger Flow: Theory and Algorithms},
  year =         2015,
  month =        {April},
  volume =       61,
  number =       4,
  pages =        {1985-2007},
  keywords =     {computational complexity;concave programming;gradient
                  methods;information retrieval;Wirtinger flow;coded diffraction
                  patterns;concrete solution algorithm;gradient descent
                  scheme;low computational complexity;near-linear time
                  algorithm;nonconvex formulation;nonconvex optimization
                  scheme;phase information retrieval;random
                  measurements;spectral method;Accuracy;Computational
                  modeling;Convergence;Diffraction;Fourier
                  transforms;Optimization;Vectors;Non-convex
                  optimization;Wirtinger derivatives;convergence to global
                  optimum;non-convex optimization;phase retrieval},
  doi =          {10.1109/TIT.2015.2399924}
}

@article{BRUCKER1984163,
  title =        "An O(n) algorithm for quadratic knapsack problems",
  journal =      "Operations Research Letters",
  volume =       3,
  number =       3,
  pages =        "163 - 166",
  year =         1984,
  doi =          "http://dx.doi.org/10.1016/0167-6377(84)90010-5",
  url =
                  "http://www.sciencedirect.com/science/article/pii/0167637784900105",
  author =       "Peter Brucker",
  keywords =     "nonlinear programming",
  keywords =     "convex programming",
  keywords =     "quadratic programming",
  keywords =     "knapsack problem",
  keywords =     "parametric programming",
  abstract =     "An algorithm is presented which solves bounded quadratic
                  optimization problems with n variables and one linear
                  constraint in at most O(n) steps. The algorithm is based on a
                  parametric approach combined with well-known ideas for
                  constructing efficient algorithms. It improves an O(n log n)
                  algorithm which has been developed for a more restricted case
                  of the problem."
}

@Article{Bur1989,
  author =       {J. V. Burke},
  title =        {A sequential quadratic programming method for potentially
                  infeasible mathematical programs},
  journal =      jmaa,
  year =         1989,
  volume =       139,
  pages =        {319-351}
}

@Article{BurM88,
  author =       {J. V. Burke and J. J. More},
  title =        {On the identification of active constraints},
  journal =      siamnumanal,
  year =         1988,
  volume =       25,
  number =       2,
  pages =        {1197-1211}
}

@Article{Burke85,
  author =       {J. V. Burke},
  title =        {Descent methods for composite nondifferentiable optimization
                  problems},
  journal =      mathprog,
  year =         1985,
  number =       33,
  pages =        {260-279}
}

@article{COT2005REKa,
  Author =       {Shane F. Cotter and Bhaskar D. Rao and Kjersti Engang and
                  Kenneth Kreutz-Delgado},
  Title =        {Sparse Solutions to Linear Inverse Problems with Multiple
                  Measurement Vectors},
  Journal =      IEEETransSigProc,
  Volume =       53,
  Issue =        7,
  Month =        {July},
  Year =         2005,
  Pages =        {2477--2488},
  Abstract =     {We address the problem of finding sparse solutions to an
                  underdetermined system of equations when there are multiple
                  measurement vectors having the same, but unknown, sparsity
                  structure. The single measurement sparse solution problem has
                  been extensively studied in the past. Although known to be
                  NP-hard, many single-measurement suboptimal algorithms have
                  been formulated that have found utility in many different
                  applications. Here, we consider in depth the extension of two
                  classes of algorithms-Matching Pursuit (MP) and FOCal
                  Underdetermined System Solver (FOCUSS)-to the multiple
                  measurement case so that they may be used in applications such
                  as neuromagnetic imaging, where multiple measurement vectors
                  are available, and solutions with a common sparsity structure
                  must be computed. Cost functions appropriate to the multiple
                  measurement problem are developed, and algorithms are derived
                  based on their minimization. A simulation study is conducted
                  on a test-case dictionary to show how the utilization of more
                  than one measurement vector improves the performance of the MP
                  and FOCUSS classes of algorithm, and their performances are
                  compared.}
}

@article{ChambollePock:2011,
  title =        {A first-order primal-dual algorithm for convex problems with
                  applications to imaging},
  author =       {Chambolle, Antonin and Pock, Thomas},
  journal =      jmathimagingvis,
  volume =       40,
  number =       1,
  pages =        {120--145},
  year =         2011,
  publisher =    {Springer}
}

@article{Combettes2016,
  title =        "Perspective functions: Proximal calculus and applications in
                  high-dimensional statistics ",
  journal =      jmaa,
  year =         2016,
  issn =         "0022-247X",
  doi =          "http://doi.org/10.1016/j.jmaa.2016.12.021",
  url =
                  "http://www.sciencedirect.com/science/article/pii/S0022247X16308071",
  author =       "Patrick L. Combettes and Christian L. M{\"u}ler",
  keywords =     "Convex function",
  keywords =     "Perspective function",
  keywords =     "Proximal algorithm",
  keywords =     "Proximity operator",
  keywords =     "Statistics ",
  abstract =     "Abstract Perspective functions arise explicitly or implicitly
                  in various forms in applied mathematics and in statistical
                  data analysis. To date, no systematic strategy is available to
                  solve the associated, typically nonsmooth, optimization
                  problems. In this paper, we fill this gap by showing that
                  proximal methods provide an efficient framework to model and
                  solve problems involving perspective functions. We study the
                  construction of the proximity operator of a perspective
                  function under general assumptions and present important
                  instances in which the proximity operator can be computed
                  explicitly or via straightforward numerical operations. These
                  results constitute central building blocks in the design of
                  proximal optimization algorithms. We showcase the versatility
                  of the framework by designing novel proximal algorithms for
                  state-of-the-art regression and variable selection schemes in
                  high-dimensional statistics. "
}

@Article{Combettes2017,
  author =       "Combettes, Patrick L.",
  title =        "Perspective Functions: Properties, Constructions, and
                  Examples",
  journal =      setvalued,
  year =         2017,
  pages =        "1--18",
  abstract =     "Many functions encountered in applied mathematics and in
                  statistical data analysis can be expressed in terms of
                  perspective functions. One of the earliest examples is the
                  Fisher information, which appeared in statistics in the 1920s.
                  We analyze various algebraic and convex-analytical properties
                  of perspective functions and provide general schemes to
                  construct lower semicontinuous convex functions from them.
                  Several new examples are presented and existing instances are
                  featured as special cases.",
  issn =         "1877-0541",
  doi =          "10.1007/s11228-017-0407-x",
  url =          "http://dx.doi.org/10.1007/s11228-017-0407-x"
}

@inproceedings{Forster:2000:REI:648299.755178,
  author =       {Forster, J\"{u}rgen and Warmuth, Manfred K.},
  title =        {Relative Expected Instantaneous Loss Bounds},
  booktitle =    {Proceedings of the Thirteenth Annual Conference on
                  Computational Learning Theory},
  series =       {COLT '00},
  year =         2000,
  isbn =         {1-55860-703-X},
  pages =        {90--99},
  numpages =     10,
  url =          {http://dl.acm.org/citation.cfm?id=648299.755178},
  acmid =        755178,
  publisher =    {Morgan Kaufmann Publishers Inc.},
  address =      {San Francisco, CA, USA},
}

@article{GOR1995GRa,
  Author =       {Irina F. Gorodnitsky and John S. George and Bhaskar D. Rao},
  Title =        {Neuromagnetic Source Imaging with {FOCUSS}: A Recursive
                  Weighted Minimum Norm Algorithm},
  Journal =      {Electroencephalography and Clinical Neurophysiology},
  Volume =       95,
  Number =       4,
  Month =        10,
  Year =         1995,
  Pages =        {231--251},
  Keywords =     {Recursive weighted minimum norm algorithm, neuromagnetic
                  source localization, EEG/MEG},
  Abstract =     {The paper describes a new algorithm for tomographic source
                  reconstruction in neural electromagnetic inverse problems.
                  Termed FOCUSS (FOCal Underdetermined System Solution), this
                  algorithm combines the desired features of the two major
                  approaches to electromagnetic inverse procedures. Like
                  multiple current dipole modeling methods, FOCUSS produces high
                  resolution solutions appropriate for the highly localized
                  sources often encountered in electromagnetic imaging. Like
                  linear estimation methods, FOCUSS allows current sources to
                  assume arbitrary shapes and it preserves the generality and
                  ease of application characteristic of this group of methods.
                  It stands apart from standard signal processing techniques
                  because, as an initialization-dependent algorithm, it
                  accommodates the non-unique set of feasible solutions that
                  arise from the neuroelectric source constraints. FOCUSS is
                  based on recursive, weighted norm minimization. The
                  consequence of the repeated weighting procedure is, in effect,
                  to concentrate the solution in the minimal active regions that
                  are essential for accurately reproducing the measurements. The
                  FOCUSS algorithm is introduced and its properties are
                  illustrated in the context of a number of simulations, first
                  using exact measurements in 2- and 3-D problems, and then in
                  the presence of noise and modeling errors. The results suggest
                  that FOCUSS is a powerful algorithm with considerable utility
                  for tomographic current estimation.}
}

@article{GabayMercier:76,
  title =        {A dual algorithm for the solution of nonlinear variational
                  problems via finite element approximations},
  author =       {D. Gabay and B. Mercier},
  journal =      {Computers and Mathematics with Applications},
  volume =       2,
  number =       1,
  pages =        {17-40},
  year =         1976
}

@article{Guler:1991,
  author =       {G\"uler, O.},
  title =        {On the Convergence of the Proximal Point Algorithm for Convex
                  Minimization},
  journal =      siamcontrol,
  volume =       29,
  number =       2,
  pages =        {403-419},
  year =         1991,
  doi =          {10.1137/0329022},
  URL =          { http://dx.doi.org/10.1137/0329022 },
  eprint =       { http://dx.doi.org/10.1137/0329022 }
}

@article{Guler:1992,
  author =       {G\"uler, O.},
  title =        {New Proximal Point Algorithms for Convex Minimization},
  journal =      siamopt,
  volume =       2,
  number =       4,
  pages =        {649-664},
  year =         1992,
  doi =          {10.1137/0802032},
  URL =          { http://dx.doi.org/10.1137/0802032 },
  eprint =       { http://dx.doi.org/10.1137/0802032 }
}

@Article{HanBur1989,
  author =       {S. Han and J. V. Burke},
  title =        {A robust sequential quadratic programming method},
  journal =      mathprog,
  year =         1989,
  volume =       43
}

@Article{McCoy2014,
  author =       "McCoy, Michael B. and Tropp, Joel A.",
  title =        "Sharp Recovery Bounds for Convex Demixing, with Applications",
  journal =      focm,
  year =         2014,
  month =        6,
  day =          1,
  volume =       14,
  number =       3,
  pages =        "503--567",
  abstract =     "Demixing refers to the challenge of identifying two structured
                  signals given only the sum of the two signals and prior
                  information about their structures. Examples include the
                  problem of separating a signal that is sparse with respect to
                  one basis from a signal that is sparse with respect to a
                  second basis, and the problem of decomposing an observed
                  matrix into a low-rank matrix plus a sparse matrix. This paper
                  describes and analyzes a framework, based on convex
                  optimization, for solving these demixing problems, and many
                  others. This work introduces a randomized signal model that
                  ensures that the two structures are incoherent, i.e.,
                  generically oriented. For an observation from this model, this
                  approach identifies a summary statistic that reflects the
                  complexity of a particular signal. The difficulty of
                  separating two structured, incoherent signals depends only on
                  the total complexity of the two structures. Some applications
                  include (1) demixing two signals that are sparse in mutually
                  incoherent bases, (2) decoding spread-spectrum transmissions
                  in the presence of impulsive errors, and (3) removing sparse
                  corruptions from a low-rank matrix. In each case, the
                  theoretical analysis of the convex demixing method closely
                  matches its empirical behavior."
}

@Article{	  RTR:1993,
  title =        {Lagrange Multipliers and Optimality},
  author =       {Rockafellar, R. T.},
  journal =      {SIAM Review},
  volume =       35,
  number =       2,
  pages =        {pp. 183-238},
  url =          {http://www.jstor.org/stable/2133143},
  abstract =     {Lagrange multipliers used to be viewed as auxiliary variables
                  introduced in a problem of constrained minimization in order
                  to write first-order optimality conditions formally as a
                  system of equations. Modern applications, with their emphasis
                  on numerical methods and more complicated side conditions than
                  equations, have demanded deeper understanding of the concept
                  and how it fits into a larger theoretical picture. A major
                  line of research has been the nonsmooth geometry of one-sided
                  tangent and normal vectors to the set of points satisfying the
                  given constraints. Another has been the game-theoretic role of
                  multiplier vectors as solutions to a dual problem.
                  Interpretations as generalized derivatives of the optimal
                  value with respect to problem parameters have also been
                  explored. Lagrange multipliers are now being seen as arising
                  from a general rule for the subdifferentiation of a nonsmooth
                  objective function which allows black-and-white constraints to
                  be replaced by penalty expressions. This paper traces such
                  themes in the current theory of Lagrange multipliers,
                  providing along the way a free-standing exposition of basic
                  nonsmooth analysis as motivated by and applied to this
                  subject.},
  year =         1993
}

@Article{Rockafellar-1973,
  author =       {R. T. Rockafellar},
  title =        {The Multiplier Method of {H}estenes and {P}owell Applied to
                  Convex Programming},
  journal =      {Journal of Optimization Theory and Applications},
  volume =       12,
  pages =        {555--562},
  year =         1973
}

@Article{Rockafellar-prox-1976,
  author =       {R. T. Rockafellar},
  title =        {Monotone Operators and the Proximal Point Algorithm},
  journal =      {SIAM Journal on Control and Optimization},
  volume =       14,
  number =       5,
  pages =        {877--898},
  year =         1976
}

@Article{Seeger11,
  author =       "A. Seeger",
  title =        "Epigrahical cones {I}",
  journal =      jconvexanal,
  year =         2011,
  volume =       18,
  pages =        {1171--1196}
}

@Article{SeegerVolle95,
  author =       "A. Seeger and M. Volle",
  title =        "On a convolution operation obtained by adding level sets:
                  classical and new results",
  journal =      "RAIRO Recherche Op\'{e}rationnelle",
  year =         1995,
  volume =       29,
  pages =        {131--154}
}

@InBook{	  abad:1967,
  address =      {Amsterdam},
  author =       {J. Abadie},
  date-modified ={2007-07-18 14:59:33 -0700},
  editor =       {J. Abadie},
  pages =        {19--36},
  publisher =    northholland,
  title =        {Nonlinear Programming},
  year =         1967
}

@Article{	  abev09,
  author =       "Jacob Abernethy and Francis Bach and Theodoros Evgeniou and
                  Jean-Philippe Vert",
  title =        "A new approach to collaborative filtering: operator estimation
                  with spectral regularization",
  journal =      "Journal of Machine Learning Research",
  year =         2009
}

@Article{	  aep08,
  author =       "Andreas Argyriou and Theodoros Evgeniou and Massimiliano
                  Pontil",
  title =        "Convex multi-task feature learning",
  journal =      "Machine Learning",
  year =         2008,
  volume =       73,
  page =         {243--272}
}

@article{afonso2010fast,
  title =        {Fast image recovery using variable splitting and constrained
                  optimization},
  author =       {Afonso, Manya V and Bioucas-Dias, Jos{\'e} M and Figueiredo,
                  M{\'a}rio AT},
  journal =      ieeetransimproc,
  volume =       19,
  number =       9,
  pages =        {2345--2356},
  year =         2010,
  publisher =    {IEEE}
}

@article{agarwal2012,
  author =       "Agarwal, Alekh and Negahban, Sahand and Wainwright, Martin J.",
  doi =          "10.1214/12-AOS1032",
  fjournal =     "The Annals of Statistics",
  journal =      "Ann. Statist.",
  month =        10,
  number =       5,
  pages =        "2452--2482",
  publisher =    "The Institute of Mathematical Statistics",
  title =        "Fast global convergence of gradient methods for
                  high-dimensional statistical recovery",
  url =          "https://doi.org/10.1214/12-AOS1032",
  volume =       40,
  year =         2012
}

@InProceedings{	  agy04,
  title =        "On the computational complexity of sensor network
                  localization",
  author =       "James Aspnes and David Goldenberg and Yang Richard Yang",
  booktitle =    "Algorithmic Aspects of Wireless Sensor Networks: First
                  International Workshop, ALGOSENSORS 2004",
  address =      {Turku, Finland},
  series =       {Lecture Notes in Computer Science},
  volume =       3121,
  publisher =    "Springer-Verlag",
  year =         2004,
  month =        {July},
  pages =        {32--44}
}

@Article{	  ahmed:2014,
  author =       {Ahmed, Ali and Recht, Benjamin and Romberg, Justin},
  title =        {Blind deconvolution using convex programming},
  journal =      ieeetransinfo,
  fjournal =     {Institute of Electrical and Electronics Engineers.
                  Transactions on Information Theory},
  volume =       60,
  year =         2014,
  number =       3,
  pages =        {1711--1732},
  mrclass =      {94A12},
  mrnumber =     3168432,
  mrreviewer =   {Joseph D. Lakey},
  doi =          {10.1109/TIT.2013.2294644},
  url =          {http://dx.doi.org/10.1109/TIT.2013.2294644}
}

@Article{	  alf00,
  author =       "A. Y. Alfakih",
  title =        "Graph rigidity via {Euclidean} distance matrices",
  journal =      "Linear Algebra and its Applications",
  year =         2000,
  volume =       310,
  page =         {149--165}
}

@Misc{		  alipanahi:2012,
  title =        {Determining Protein Structures from {NOESY} Distance
                  Constraints by Semidefinite Programming},
  author =       {Babak Alipanahi and Nathan Krislock and Ali Ghodsi and Henry
                  Wolkowicz and Logan Donaldson and Ming Li},
  year =         2012,
  note =         {To appear in {\it Journal of Computational Biology}}
}

@InCollection{	  alizadehschmieta:2000,
  author =       {Farid Alizadeh and Stefan Schmieta},
  title =        {Symmetric Cones, Potential Reduction Methods},
  booktitle =    {Handbook of semidefinite programming: theory, algorithms, and
                  applications},
  publisher =    {Springer},
  year =         2000,
  editor =       {Wolkowicz, Henry and Saigal, Romesh and Vandenberghe, Lieven},
  volume =       27
}

@Article{	  alizgold:2003,
  author =       {F. Alizadeh and D. Goldfarb},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      mathprogb,
  pages =        {3--51},
  title =        {Second-order cone programming},
  volume =       95,
  year =         2003
}

@Article{	  altmgond:1999,
  author =       {A. Altman and J. Gondzio},
  date-modified ={2007-09-07 10:48:13 -0700},
  journal =      {Optim. Methods Softw.},
  pages =        {275--302},
  title =        {Regularized Symmetric Indefinite Systems in Interior Point
                  Methods for Linear and Quadratic Optimization},
  volume =       11,
  year =         1999
}

@Article{	  ames2011nuclear,
  title =        {Nuclear norm minimization for the planted clique and biclique
                  problems},
  author =       {Ames, Brendan PW and Vavasis, Stephen A},
  journal =      mathprog,
  volume =       129,
  number =       1,
  pages =        {69--89},
  year =         2011,
  publisher =    {Springer}
}

@Article{	  ande:1996,
  author =       {Andersen, Knud D.},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamopt,
  number =       1,
  pages =        {74--95},
  title =        {An efficient {N}ewton barrier method for minimizing a sum of
                  {E}uclidean norms},
  volume =       6,
  year =         1996
}

@Article{	  andechriconnover:2000,
  author =       {Andersen, Knud D. and Christiansen, Edmund and Conn, Andrew R.
                  and Overton, M. L.},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamscicomp,
  number =       1,
  pages =        {243--262},
  title =        {An efficient primal-dual interior-point method for minimizing
                  a sum of {E}uclidean norms},
  volume =       22,
  year =         2000
}

@Article{	  andeelfv:1997,
  author =       {Lars-Erik Andersson and Tommy Elfving},
  title =        {A Constrained Procrustes Problem},
  publisher =    {SIAM},
  year =         1997,
  journal =      siammatrix,
  volume =       18,
  number =       1,
  pages =        {124-139},
  keywords =     {constrained matrices; convex cones; positive semidefinite;
                  Procrustes},
  url =          {http://link.aip.org/link/?SML/18/124/1},
  doi =          {10.1137/S0895479894277545}
}

@Article{	  anderoosterl:2003,
  author =       {E. D. Anderson and C. Roos and T. Terlaky},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprogb,
  pages =        {249--277},
  title =        {On implementing a primal-dual interior-point method for conic
                  quadratic optimization},
  volume =       95,
  year =         2003
}

@Article{	  andersen:2010,
  year =         2010,
  journal =      {Mathematical Programming Computation},
  volume =       2,
  number =       {3-4},
  doi =          {10.1007/s12532-010-0016-2},
  title =        {Implementation of nonsymmetric interior-point methods for
                  linear optimization over sparse matrix cones},
  url =          {http://dx.doi.org/10.1007/s12532-010-0016-2},
  publisher =    {Springer-Verlag},
  keywords =     {90-08 Mathematical Programming - computational methods; 90C06
                  Mathematical Programming - large-scale; 90C22 Mathematical
                  Programming - semidefinite programing; 90C25 Mathematical
                  Programming - convex programming; 90C51 Mathematical
                  Programming - interior-point methods},
  author =       {Andersen, MartinS. and Dahl, Joachim and Vandenberghe, Lieven},
  pages =        {167-201},
  language =     {English}
}

@Article{	  andrbirgmartschu:2006,
  abstract =     {Two Augmented Lagrangian algorithms for solving KKT systems
                  are introduced. The algorithms differ in the way in which
                  penalty parameters are updated. Possibly infeasible
                  accumulation points are characterized. It is proved that
                  feasible limit points that satisfy the Constant Positive
                  Linear Dependence constraint qualification are KKT solutions.
                  Boundedness of the penalty parameters is proved under suitable
                  assumptions. Numerical experiments are presented.},
  annote =       {Published online.},
  author =       {R. Andreani and E. G. Birgin and J. M. Mart\'{i}nez and M. L.
                  Schuverdt},
  journal =      {Math. Program. B},
  local-url =    {file://localhost/Users/mpf/papers/AndrBirgMartSchu06.pdf},
  month =        {December},
  title =        {Augmented Lagrangian methods under the constant positive
                  linear dependence constraint qualification},
  year =         2008,
  pages =        {5--32},
  volume =       111,
  numbers =      {1--2}
}

@TechReport{	  anit:2000,
  author =       {Mihai Anitescu},
  date-modified ={2007-07-18 14:59:33 -0700},
  institution =  {Argonne National Laboratory},
  number =       {ANL/MCS-P864-1200},
  title =        {On solving mathematical programs with complementarity
                  constraints as nonlinear programs},
  year =         2000
}

@Article{	  anit:2006,
  author =       {M. Anitescu},
  title =        {Optimization-based simulation of nonsmooth rigid multibody
                  dynamics},
  journal =      mathprog,
  year =         2006,
  volume =       105,
  number =       1,
  pages =        {113--143}
}

@Article{	  aravkin2013sparse,
  title =        {Sparse/robust estimation and kalman smoothing with nonsmooth
                  log-concave densities: Modeling, computation, and theory},
  author =       {Aravkin, Aleksandr Y and Burke, James V and Pillonetto,
                  Gianluigi},
  journal =      {J. Mach. Learn. Res.},
  volume =       14,
  number =       1,
  pages =        {2689--2728},
  year =         2013,
  publisher =    {JMLR.org}
}

@Article{	  aravkinleeuwen:2012,
  author =       {Aleksandr Y Aravkin and Tristan van Leeuwen},
  title =        {Estimating nuisance parameters in inverse problems},
  journal =      {Inverse Probl.},
  volume =       28,
  number =       11,
  pages =        115016,
  url =          {http://stacks.iop.org/0266-5611/28/i=11/a=115016},
  year =         2012,
  abstract =     {Many inverse problems include nuisance parameters which, while
                  not of direct interest, are required to recover primary
                  parameters. The structure of these problems allows efficient
                  optimization strategies—a well-known example is variable
                  projection , where nonlinear least-squares problems which are
                  linear in some parameters can be very efficiently optimized.
                  In this paper, we extend the idea of projecting out a subset
                  over the variables to a broad class of maximum likelihood and
                  maximum a posteriori likelihood problems with nuisance
                  parameters, such as variance or degrees of freedom (d.o.f.).
                  As a result, we are able to incorporate nuisance parameter
                  estimation into large-scale constrained and unconstrained
                  inverse problem formulations. We apply the approach to a
                  variety of problems, including estimation of unknown variance
                  parameters in the Gaussian model, d.o.f. parameter estimation
                  in the context of robust inverse problems, and automatic
                  calibration. Using numerical examples, we demonstrate
                  improvement in recovery of primary parameters for several
                  large-scale inverse problems. The proposed approach is
                  compatible with a wide variety of algorithms and formulations,
                  and its implementation requires only minor modifications to
                  existing algorithms.}
}

@incollection{argyriou2014hybrid,
  title =        {Hybrid conditional gradient-smoothing algorithms with
                  applications to sparse and low rank regularization},
  author =       {Argyriou, Andreas and Signoretto, Marco and Suykens, J},
  journal =      {Regularization, Optimization, Kernels, and Support Vector
                  Machines},
  pages =        53,
  chapter =      3,
  booktitle =    {Regularization, Optimization, Kernels, and Support Vector
                  Machines},
  editors =      {Johan A.K. Suykens, Marco Signoretto, Andreas Argyriou},
  year =         2014,
  publisher =    {CRC Press}
}

@Article{	  armandbenois:2013,
  year =         2013,
  journal =      mathprog,
  volume =       137,
  number =       {1-2},
  doi =          {10.1007/s10107-011-0498-3},
  title =        {Uniform boundedness of the inverse of a Jacobian matrix
                  arising in regularized interior-point methods},
  url =          {http://dx.doi.org/10.1007/s10107-011-0498-3},
  publisher =    {Springer-Verlag},
  keywords =     {Constrained optimization; Primal-dual interior-point method;
                  49M37; 65F05; 65F22; 65K05; 90C05; 90C30; 90C51},
  author =       {Armand, Paul and Benoist, Joël},
  pages =        {587-592},
  language =     {English}
}

@InCollection{	  arrosolo:1958,
  address =      {Stanford, CA},
  author =       {Kenneth J. Arrow and Robert M. Solow},
  booktitle =    {Studies in Linear and Nonlinear Programming},
  date-modified ={2007-07-18 14:59:32 -0700},
  editor =       {Kenneth J. Arrow and Leonid Hurwicz and Hirofumi Uzawa},
  pages =        {166--176},
  publisher =    stanford,
  title =        {Gradient methods for constrained maxima, with weakened
                  assumptions},
  year =         1958
}

@Article{	  aus78,
  author =       "A. Auslender",
  editor =       "O. L. Mangazarian and R. R. Meyer and S. M. Robinson",
  title =        "Minimisation sans contraintes de fonctions localement
                  lipschitziennes: Applications \`a la programmation mi-convexe,
                  mi-diff\'erentiable",
  journal =      "Nonlinear Programming",
  year =         1978,
  volume =       3,
  pages =        {429--460},
  publisher =    "Academic press",
  address =      "New York"
}

@Article{	  aut05,
  author =       "A. Auslender and M. Teboulle",
  title =        "Interior projection-like methods for monotone variational
                  inequalities",
  journal =      "Mathematical Programming",
  year =         2005,
  volume =       104,
  page =         {39--68}
}

@Article{	  aut06,
  author =       "A. Auslender and M. Teboulle",
  title =        "Interior Gradient and Proximal Methods for Convex and Conic
                  Optimization",
  journal =      siamopt,
  year =         2006,
  volume =       16,
  page =         {697--725}
}

@Article{	  avelinovicente:2003,
  author =       {C. P. Avelino and L. N. Vicente},
  title =        {Updating the Multipliers Associated with Inequality
                  Constraints in an Augmented Lagrangian Multiplier Method},
  journal =      jota,
  year =         2003,
  volume =       119,
  number =       2,
  pages =        {215--233}
}

@Article{	  avrontoledo:2011,
  author =       {Avron, Haim and Toledo, Sivan},
  title =        {Randomized algorithms for estimating the trace of an implicit
                  symmetric positive semi-definite matrix},
  journal =      {J. ACM},
  issue_date =   {April 2011},
  volume =       58,
  issue =        2,
  month =        {April},
  year =         2011,
  pages =        {8:1--8:34},
  articleno =    8,
  numpages =     34,
  url =          {http://doi.acm.org/10.1145/1944345.1944349},
  doi =          {http://doi.acm.org/10.1145/1944345.1944349},
  acmid =        1944349,
  publisher =    {ACM},
  address =      {New York, NY, USA},
  keywords =     {Trace estimation, implicit linear operators}
}

@Article{	  bach2011learning,
  title =        {Learning with submodular functions: A convex optimization
                  perspective},
  author =       {Bach, Francis},
  journal =      {arXiv preprint arXiv:1111.6453},
  year =         2011
}

@Article{	  bach2012,
  ajournal =     "Statist. Sci.",
  author =       "Bach, Francis and Jenatton, Rodolphe and Mairal, Julien and
                  Obozinski, Guillaume",
  doi =          "10.1214/12-STS394",
  journal =      "Statistical Science",
  month =        11,
  number =       4,
  pages =        "450--468",
  publisher =    "The Institute of Mathematical Statistics",
  title =        "Structured Sparsity through Convex Optimization",
  volume =       27,
  year =         2012
}

@article{bach2012optimization,
  title =        {Optimization with sparsity-inducing penalties},
  author =       {Bach, Francis and Jenatton, Rodolphe and Mairal, Julien and
                  Obozinski, Guillaume},
  journal =      {Foundations and Trends{\textregistered} in Machine Learning},
  volume =       4,
  number =       1,
  pages =        {1--106},
  year =         2012,
  publisher =    {Now Publishers Inc.}
}

@article{bach2015duality,
  title =        {Duality between subgradient and conditional gradient methods},
  author =       {Bach, Francis},
  journal =      siamopt,
  volume =       25,
  number =       1,
  pages =        {115--129},
  year =         2015,
  publisher =    {SIAM}
}

@InCollection{	  bachthibjord:2005,
  address =      {San Mateo, CA},
  author =       {F. R. Bach and R. Thibaux and M. I. Jordan},
  booktitle =    {Advances in Neural Information Processing Systems (NIPS) 17},
  editor =       {L. Saul and Y. Weiss and L. Bottou},
  publisher =    {Morgan Kaufmann},
  title =        {Computing regularization paths for learning multiple kernels},
  year =         2005
}

@Unpublished{	  balabuscgropkausknep:2001,
  author =       {Satish Balay and Kris Buschelman and William D. Gropp and
                  Dinesh Kaushik and Matt Knepley and Lois Curfman McInnes and
                  Barry F. Smith and Hong Zhang},
  note =         {http://www.mcs.anl.gov/petsc},
  title =        {{PETSc} home page},
  year =         2001
}

@TechReport{	  balabuscgropkausknep:2002,
  author =       {Satish Balay and Kris Buschelman and William D. Gropp and
                  Dinesh Kaushik and Matt Knepley and Lois Curfman McInnes and
                  Barry F. Smith and Hong Zhang},
  institution =  {Argonne National Laboratory},
  address =      {Argonne, IL},
  number =       {ANL-95/11},
  title =        {{PETSc} Users Manual Revision 2.1.3},
  year =         2002,
  type =         {Tech. rep.}
}

@InProceedings{	  balagropmcinsmit:1997,
  author =       {Satish Balay and William D. Gropp and Lois Curfman McInnes and
                  Barry F. Smith},
  booktitle =    {Modern Software Tools for Scientific Computing},
  editor =       {E. Arge and A. M. Bruaset and H. P. Langtangen},
  pages =        {163--202},
  publisher =    {Birkh\:{a}user Press},
  address =      {Boston},
  title =        {Efficient Management of Parallelism in Object-Oriented
                  Numerical Software Libraries},
  year =         1997
}

@article{banerjee2005clustering,
  title =        {Clustering with Bregman divergences},
  author =       {Banerjee, Arindam and Merugu, Srujana and Dhillon, Inderjit S
                  and Ghosh, Joydeep},
  journal =      {Journal of machine learning research},
  volume =       6,
  number =       {Oct},
  pages =        {1705--1749},
  year =         2005
}

@Article{	  barltora:1995,
  author =       {J. L. Barlow and G. Toraldo},
  journal =      optimmeth,
  number =       3,
  pages =        {235--245},
  title =        {The effect of diagonal scaling on projected gradient methods
                  for bound constrained quadratic programming problems},
  volume =       5,
  year =         1995
}

@Article{	  barzborw:1988,
  author =       {J. Barzilai and J. M. Borwein},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      imanumerana,
  pages =        {141-148},
  title =        {Two-point step size gradient methods},
  volume =       8,
  year =         1988
}

@book{bauschke2011convex,
  title =        {Convex analysis and monotone operator theory in Hilbert
                  spaces},
  author =       {Bauschke, Heinz H and Combettes, Patrick L},
  volume =       408,
  year =         2011,
  publisher =    {Springer}
}

@InProceedings{	  bay05,
  title =        "Semidefinite programming algorithms for sensor network
                  localization using angle of arrival information",
  author =       "Pratik Biswas and Hamid Aghajan and Yinyu Ye",
  booktitle =    "39th Annual Asiloinar Conference on Signals, Systems, and
                  Computers",
  address =      "Pacific Grove, CA",
  year =         2005
}

@Article{	  bbc03,
  author =       "Heinz H. Bauschke and Jonathan M. Borwein and Patrick L.
                  Combettes",
  title =        "{Bregman} Monotone Optimization Algorithms",
  journal =      siamcontrol,
  year =         2003,
  volume =       42,
  number =       2,
  page =         {596--636}
}

@TechReport{	  bbc09,
  title =        {NESTA: A Fast and Accurate First-order Method for Sparse
                  Recovery},
  author =       {S. Becker and J. Bobin and E. Cand\'es},
  institution =  {California Institute of Technology},
  type =         {Tech. Rep.},
  month =        {April},
  year =         2009
}

@Article{	  bddw08,
  author =       {Richard Baraniuk and Mark Davenport and Ronald DeVore and
                  Michael Wakin },
  title =        {A Simple Proof of the Restricted Isometry Property for Random
                  Matrices},
  journal =      {Constructive Approximation},
  year =         2008,
  volume =       28,
  number =       3,
  pages =        {253--263},
  month =        {December}
}

@InBook{	  beal:1967,
  address =      {Amsterdam},
  author =       {E. M. L. Beale},
  chapter =      7,
  date-modified ={2007-07-18 14:59:33 -0700},
  editor =       {J. Abadie},
  publisher =    northholland,
  title =        {Nonlinear Programming},
  year =         1967
}

@Unpublished{	  beaz:2001,
  author =       {David M. Beazley},
  date-modified ={2007-07-18 14:59:33 -0700},
  note =         {{\tt http://systems.cs.uchicago.edu/ply/}},
  title =        {{PLY} {(Python Lex-Yacc)}},
  year =         2001
}

@article{beck2003mirror,
  title =        {Mirror descent and nonlinear projected subgradient methods for
                  convex optimization},
  author =       {Beck, Amir and Teboulle, Marc},
  journal =      orl,
  volume =       31,
  number =       3,
  pages =        {167--175},
  year =         2003,
  publisher =    {Elsevier}
}

@Article{	  beck2009fast,
  title =        {A fast iterative shrinkage-thresholding algorithm for linear
                  inverse problems},
  author =       {Beck, Amir and Teboulle, Marc},
  journal =      {SIAM Journal on Imaging Sciences},
  volume =       2,
  number =       1,
  pages =        {183--202},
  year =         2009,
  publisher =    {SIAM}
}

@Article{	  beckbobcandgrant:2011,
  author =       {Becker, Stephen and Cand\`es, Emmanuel and Grant, Michael},
  affiliation =  {Applied and Computational Mathematics, California Institute of
                  Technology, Pasadena, CA 91125, USA},
  title =        {Templates for convex cone problems with applications to sparse
                  signal recovery},
  journal =      mathprogc,
  keyword =      {Mathematics and Statistics},
  pages =        {165-218},
  volume =       3,
  issue =        3,
  doi =          {10.1007/s12532-011-0029-5},
  abstract =     {This paper develops a general framework for solving a variety
                  of convex cone problems that frequently arise in signal
                  processing, machine learning, statistics, and other fields.
                  The approach works as follows: first, determine a conic
                  formulation of the problem; second, determine its dual; third,
                  apply smoothing; and fourth, solve using an optimal
                  first-order method. A merit of this approach is its
                  flexibility: for example, all compressed sensing problems can
                  be solved via this approach. These include models with
                  objective functionals such as the total-variation norm, || Wx
                  || 1 where W is arbitrary, or a combination thereof. In
                  addition, the paper introduces a number of technical
                  contributions such as a novel continuation scheme and a novel
                  approach for controlling the step size, and applies results
                  showing that the smooth and unsmoothed problems are sometimes
                  formally equivalent. Combined with our framework, these lead
                  to novel, stable and computationally efficient algorithms. For
                  instance, our general implementation is competitive with
                  state-of-the-art methods for solving intensively studied
                  problems such as the LASSO. Further, numerical experiments
                  show that one can solve the Dantzig selector problem, for
                  which no efficient large-scale solvers exist, in a few hundred
                  iterations. Finally, the paper is accompanied with a software
                  release. This software is not a single, monolithic solver;
                  rather, it is a suite of programs and routines designed to
                  serve as building blocks for constructing complete
                  algorithms.},
  year =         2011
}

@Article{	  beckbobicand:2011,
  title =        {NESTA: A Fast and Accurate First-Order Method for Sparse
                  Recovery},
  publisher =    {SIAM},
  journal =      siamsiims,
  year =         2011,
  doi =          {DOI:10.1137/090756855},
  coden =        {SJISBI},
  volume =       4,
  number =       1,
  pages =        {1-39},
  author =       {Stephen Becker and J\'er\^ome Bobin and Emmanuel J. Cand\`es},
  keywords =     {Nesterov's method; smooth approximations of nonsmooth
                  functions; $\ell_1$ minimization; duality in convex
                  optimization; continuation methods; compressed sensing;
                  total-variation minimization; 90C06; 90C25; 94A08; }
}

@Article{	  beckteboulle:2012,
  title =        {Smoothing and first order methods: A unified framework},
  author =       {Beck, Amir and Teboulle, Marc},
  journal =      siamopt,
  volume =       22,
  number =       2,
  pages =        {557--580},
  year =         2012,
  publisher =    {SIAM}
}

@Article{	  bellavia-2009,
  author =       {S. Bellavia and J. Gondzio and B. Morini},
  title =        {Regularization and Preconditioning of {KKT} Systems Arising in
                  Nonnegative Least-Squares Problems},
  journal =      {Numerical Linear Algebra and Applications},
  year =         2009,
  doi =          {10.1002/nla.610},
  volume =       16,
  number =       1,
  pages =        {39--61}
}

@Book{		  ben-nemi:2001,
  address =      {Philadelphia},
  author =       {A. Ben-Tal and A. Nemirovski},
  date-modified ={2007-07-18 14:59:33 -0700},
  publisher =    siampub,
  series =       {MPS/SIAM Series on Optimization},
  title =        {Lectures on Modern Convex Optimization: {A}nalysis,
                  Algorithms, and Engineering Applications},
  volume =       2,
  year =         2001
}

@InProceedings{	  bennett2007netflix,
  title =        {The netflix prize},
  author =       {Bennett, James and Lanning, Stan},
  booktitle =    {Proceedings of KDD cup and workshop},
  volume =       2007,
  pages =        35,
  year =         2007
}

@InProceedings{	  benscurfmoresar:2004,
  author =       {S. J. Benson and L. Curfman McInnes and J. J. Mor\'{e} and J.
                  Sarich},
  title =        {Scalable Algorithms in Optimization: Computational
                  Experiments},
  year =         2004,
  booktitle =    {AIAA Multidisciplinary Analysis and Optimization},
  address =      {Albany, NY}
}

@TechReport{	  benssenshanvand:2003,
  author =       {Hande Y. Benson and Arun Sen and David F. Shanno and Robert J.
                  Vanderbei},
  institution =  {Operations Research and Financial Engineering, Princeton
                  University},
  number =       {ORFE-03-02},
  title =        {Interior-point algorithms, penalty methods and equilibrium
                  problems},
  year =         2003
}

@Misc{		  bensshan:2007,
  author =       {H. Y. Benson and D. Shanno},
  howpublished = {To appear in {\it Comp. Optim. Appl.}},
  title =        {Interior-point methods for nonconvex nonlinear programming:
                  regularization and warmstarts},
  year =         2007
}

@TechReport{	  bensshanvand:2002,
  author =       {Hande Y. Benson and David F. Shanno and Robert J. Vanderbei},
  institution =  {Operations Research and Financial Engineering, Princeton
                  University},
  number =       {ORFE-02-02},
  title =        {Interior-point methods for nonconvex nonlinear programming:
                  complementarity constraints},
  year =         2002
}

@Article{	  benzgolu:2004,
  abstract =     {In this paper we consider the solution of linear systems of
                  saddle point type by preconditioned Krylov subspace methods. A
                  preconditioning strategy based on the symmetric/
                  skew-symmetric splitting of the coefficient matrix is
                  proposed, and some useful properties of the preconditioned
                  matrix are established. The potential of this approach is
                  illustrated by numerical experiments with matrices from
                  various application areas.},
  author =       {M. Benzi and G. H. Golub},
  journal =      siammatrix,
  number =       1,
  pages =        {20-41},
  title =        {A preconditioner for generalized saddle point problems},
  volume =       26,
  year =         2004
}

@Article{	  benzgolulies:2005,
  author =       {M. Benzi and G. Golub and J. Liesen},
  journal =      actanumerica,
  month =        {April},
  pages =        {1--137},
  title =        {Numerical solution of saddle point problems},
  volume =       14,
  year =         2005
}

@incollection{benzi2008some,
  title =        {Some preconditioning techniques for saddle point problems},
  author =       {Benzi, Michele and Wathen, Andrew J},
  booktitle =    {Model order reduction: theory, research aspects and
                  applications},
  pages =        {195--211},
  year =         2008,
  publisher =    {Springer}
}

@Article{	  berggondzill:2004,
  author =       {Luca Bergamaschi and Jacek Gondzio and Giovanni Zilli},
  journal =      compapplopt,
  month =        {July},
  number =       2,
  pages =        {149-171},
  title =        {Preconditioning Indefinite Systems in Interior Point Methods
                  for Optimization},
  volume =       28,
  year =         2004
}

@book{berkelaar1996optimal,
  title =        {The Optimal and Optimal Partition Approach to Linear and
                  Quadratic Programming},
  author =       {Berkelaar, AB and Roos, C and Terlaky, T},
  year =         1996,
  publisher =    {Technische Universiteit Delft. Faculteit der Technische
                  Wiskunde en Informatica}
}

@Book{		  bermshak:2003,
  title =        {Completely positive matrices},
  author =       {A. Bermanand and N. Shaked-Monderer},
  year =         2003,
  publisher =    {World Scientific}
}

@Article{	  bert:1975,
  author =       {D. P. Bertsekas},
  journal =      mathprog,
  pages =        {87--99},
  title =        {Necessary and sufficient conditions for a penalty method to be
                  exact},
  volume =       9,
  year =         1975
}

@Book{		  bert:1982,
  address =      {New York},
  author =       {D. P. Bertsekas},
  publisher =    academic,
  title =        {Constrained Optimization and {L}agrange Multiplier Methods},
  year =         1982
}

@Book{		  bert:1999,
  address =      {Belmont, MA},
  author =       {D. P. Bertsekas},
  edition =      {2nd},
  publisher =    athena,
  title =        {Nonlinear Programming},
  year =         1999
}

@Book{		  bertnediozda:2003,
  author =       {D. P. Bertsekas and A. Nedic and A. E Ozdaglar},
  title =        {Convex analysis and optimization},
  publisher =    {Athena Scientific},
  year =         2003
}

@Book{		  bertsekas1996neuro,
  title =        {Neuro-dynamic programming},
  author =       {Bertsekas, D.P. and Tsitsiklis, J.N.},
  publisher =    {Athena Scientific},
  year =         1996
}

@Article{bertsekas1997new,
  title =        {A new class of incremental gradient methods for least squares
                  problems},
  author =       {Bertsekas, D.P.},
  journal =      siamopt,
  volume =       7,
  number =       4,
  pages =        {913--926},
  year =         1997,
  publisher =    {Citeseer}
}

@Book{bertsekas2015,
  author =       {Bertsekas, Dimitri P.},
  title =        {Convex optimization algorithms},
  publisher =    {Athena Scientific},
  address =      {Belmont, MA},
  year =         2015
}

@InCollection{bertsekas:2012,
  author =       {D. P. Bertsekas},
  title =        {Incremental gradient, subgradient, and proximal methods for
                  convex optimization: A survey},
  booktitle =    {Optimization for Machine Learning},
  publisher =    {MIT},
  year =         2012,
  chapter =      4,
  pages =        {85--119}
}

@book{bertsekas2009convex,
  title={Convex optimization theory},
  author={Bertsekas, Dimitri P},
  year={2009},
  publisher={Athena Scientific}
}

@Book{berttsit:1997,
  author =       {Dimitris Bertsimas and John N. Tsitsiklis},
  title =        {Introduction to Linear Optimization},
  publisher =    {Athena Scientific},
  year =         1997,
  address =      {Nashua, NH}
}

@book{best1996algorithm,
  title =        {An algorithm for the solution of the parametric quadratic
                  programming problem},
  author =       {Best, Michael J},
  year =         1996,
  publisher =    {Springer}
}

@Article{	  bestbraurittrobi:1981,
  author =       {M. J. Best and J. Br{\"a}uninger and K. Ritter and S. M.
                  Robinson},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      computing,
  pages =        {141--155},
  title =        {A Globally and Quadratically Convergent Algorithm for General
                  Nonlinear Programming Problems},
  volume =       26,
  year =         1981
}

@Article{	  bet03,
  author =       "Amir Beck and Marc Teboulle",
  title =        "Mirror descent and nonlinear projected subgradient methods for
                  convex optimization",
  journal =      "Operations Research Letters",
  year =         2003,
  volume =       31,
  page =         {167--175}
}

@Article{	  bet06,
  author =       "Amir Beck and Marc Teboulle",
  title =        "A Linearly Convergent Dual-Based Gradient Projection Algorithm
                  for Quadratically Constrained Convex Minimization",
  journal =      mathofor,
  year =         2006,
  volume =       31,
  number =       2,
  page =         {398--417},
  doi =          {10.1287/moor.1060.019}
}

@TechReport{	  bet08,
  author =       "Amir Beck and Marc Teboulle",
  title =        "A Fast Iterative Shrinkage-Thresholding Algorithm for Linear
                  Inverse Problems",
  institution =  "Department of Industrial Engineering and Management, Technion",
  address =      "Haifa",
  year =         2008
}

@Article{	  bettsfrank:1994,
  title =        {A sparse nonlinear optimization algorithm},
  author =       {Betts, J.T. and Frank, P.D.},
  journal =      {Journal of Optimization Theory and Applications},
  volume =       82,
  number =       3,
  pages =        {519--541},
  year =         1994,
  publisher =    {Springer}
}

@TechReport{	  bettsfrank:1997,
  author =       {J.T. Betts and W.P. Huffman},
  title =        {Sparse optimal control software {SOCS}},
  type =         {Mathematics and Engineering Analysis Technical Document},
  number =       {MEA-LR-085},
  institution =  {Boeing Information and Support Services, The Boeing Company},
  address =      {PO Box 3707, Seattle, WA 98124-2207},
  month =        {July},
  year =         1997
}

@Article{	  bgd08,
  author =       "Onureena Banerjee and Laurent El Ghaoui and Alexandre
                  {\noopsort{Asprement}}{D'Aspremont}",
  title =        "Model Selection Through Sparse Maximum Likelihood Estimation
                  for Multivariate Gaussian or Binary Data",
  journal =      "J. Mach. Learn. Res.",
  year =         2008,
  volume =       9,
  page =         {485--516}
}

@Article{	  bhg07,
  author =       "Doron Blatt and Alfred O. Hero and Hillel Gauchman",
  title =        "A Convergent Incremental Gradient Method with a Constant Step
                  Size",
  journal =      siamopt,
  year =         2007,
  volume =       18,
  page =         {29--51}
}

@InCollection{	  bigg:1972,
  address =      {London},
  author =       {M. C. Biggs},
  booktitle =    {Numerical Methods for Nonlinear Optimization},
  date-modified ={2007-07-18 14:59:32 -0700},
  editor =       {F. A. Lootsma},
  publisher =    academic,
  title =        {Constrained minimization using recursive equality quadratic
                  programming},
  year =         1972
}

@inproceedings{bioucas2010alternating,
  title =        {Alternating direction algorithms for constrained sparse
                  regression: Application to hyperspectral unmixing},
  author =       {Bioucas-Dias, Jos{\'e} M and Figueiredo, M{\'a}rio AT},
  booktitle =    {Hyperspectral Image and Signal Processing: Evolution in Remote
                  Sensing (WHISPERS), 2010 2nd Workshop on},
  pages =        {1--4},
  year =         2010,
  organization = {IEEE}
}

@Article{	  birgmartrayd:2000,
  author =       {E. G. Birgin and J. M. Mart\'{i}nez and M. Raydan},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      siamopt,
  number =       4,
  pages =        {1196-1211},
  title =        {Nonmonotone spectral projected gradient methods on convex
                  sets},
  volume =       10,
  year =         2000
}

@Article{	  birgmartrayd:2001,
  abstract =     {Fortran 77 software implementing the SPG method is introduced.
                  SPG is a nonmonotone projected gradient algorithm for solving
                  large-scale convex-constrained optimization problems. It
                  combines the classical projected gradient method with the
                  spectral gradient choice of steplength and a nonmonotone
                  line-search strategy. The user provides objective function and
                  gradient values, and projections onto the feasible set. Some
                  recent numerical tests are reported on very large location
                  problems, indicating that SPG is substantially more efficient
                  than existing general-purpose software on problems for which
                  projections can be computed efficiently.},
  address =      {New York, NY, USA},
  author =       {E. G. Birgin and J. M. Mart\'{i}nez and M. Raydan},
  date-added =   {2007-06-11 21:18:11 -0700},
  date-modified ={2007-07-18 14:59:32 -0700},
  doi =          {http://doi.acm.org/10.1145/502800.502803},
  journal =      acmmathsoft,
  local-url =    {file://localhost/Users/mpf/papers/BirgMartRayd01.pdf},
  number =       3,
  pages =        {340--349},
  publisher =    {ACM Press},
  title =        {Algorithm 813: {SPG}---{S}oftware for Convex-Constrained
                  Optimization},
  volume =       27,
  year =         2001
}

@Article{	  birgmartrayd:2003,
  author =       {E. G. Birgin and J. M. Mart\'{i}nez and M. Raydan},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      imanumerana,
  local-url =    {file://localhost/Users/mpf/papers/BirgMartRad03.pdf},
  pages =        {1196-1211},
  title =        {Inexact spectral projected gradient methods on convex sets},
  volume =       23,
  year =         2003
}

@Article{	  biroghat:2005,
  author =       {G. Biros and O. Ghattas},
  date-modified ={2007-07-18 14:59:33 -0700},
  doi =          {10.1137/S106482750241565X},
  journal =      siamscicomp,
  keywords =     {sequential quadratic programming; nonlinear equations;
                  parallel algorithms; adjoint methods; PDE-constrained
                  optimization; optimal control; Lagrange--Newton--Krylov--Schur
                  methods; Navier--Stokes; finite elements; preconditioners;
                  indefinite systems},
  number =       2,
  pages =        {687-713},
  publisher =    {SIAM},
  title =        {Parallel Lagrange--Newton--Krylov--Schur Methods for
                  PDE-Constrained Optimization. Part I: The Krylov--Schur
                  Solver},
  url =          {http://link.aip.org/link/?SCE/27/687/1},
  volume =       27,
  year =         2005
}

@TechReport{	  bisccarlhovlkhadmaue:1998,
  address =      {Argonne, IL},
  author =       {Christian Bischof and Alan Carle and Paul Hovland and Peyvand
                  Khademi and Andrew Mauer},
  date-modified ={2007-07-18 14:59:31 -0700},
  institution =  {Mathematics and Computer Science Division},
  month =        {June},
  number =       192,
  title =        {{ADIFOR} 2.0 {Users' Guide}},
  year =         1998
}

@Article{	  biscrohmaue:1997,
  author =       {Christian Bischof and Lucas Roh and A. Mauer},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      {Software---Practice and Experience},
  month =        {December},
  number =       12,
  pages =        {1427--1456},
  title =        {{ADIC}: An Extensible Automatic Differentiation Tool for
                  {ANSI-C}},
  volume =       27,
  year =         1997
}

@InBook{	  biy03,
  author =       "P. Biswas and Y. Ye",
  chapter =      "A Distributed Method for Solving Semidefinite Programs Arising
                  from Ad Hoc Wireless Sensor Network Localization",
  title =        siammms,
  series =       "Nonconvex Optimization and Its Applications",
  publisher =    "Springer",
  year =         2003,
  volume =       82
}

@InProceedings{	  biy04,
  author =       "Biswas, P. and Ye, Y.",
  title =        "Semidefinite programming for ad hoc wireless sensor network
                  localization",
  year =         2004,
  booktitle =    "The 3rd international symposium on information processing in
                  sensor networks",
  page =         {46--54}
}

@Book{		  bjorck:1996,
  title =        {{Numerical Methods for Least Squares Problems}},
  author =       {Bj{\"o}rck, {\AA}.},
  year =         1996,
  publisher =    {Society for Industrial Mathematics}
}

@Article{	  blatt2008convergent,
  title =        {{A convergent incremental gradient method with a constant step
                  size}},
  author =       {Blatt, D. and Hero, A.O. and Gauchman, H.},
  journal =      siamopt,
  volume =       18,
  number =       1,
  pages =        {29--51},
  year =         2008,
  publisher =    {Citeseer}
}

@Article{	  bltyw06,
  author =       "P. Biswas and Tzu-Chen Liang and Kim-Chuan Toh and Ta-Chung
                  Wang and Yinyu Ye",
  title =        "Semidefinite Programming Approaches for Sensor Network
                  Localization With Noisy Distance Measurements",
  journal =      "Automation Science and Engineering, IEEE Transactions",
  year =         2006,
  volume =       3,
  page =         {360--371}
}

@Article{	  blwy06,
  author =       "Biswas, P. and Liang, T.-C. and Wang, T.-C. and Ye, Y.",
  title =        "Semidefinite programming based algorithms for sensor network
                  localization",
  journal =      "ACM Transactions on Sensor Networks",
  year =         2006,
  volume =       2,
  page =         {188--220}
}

@InCollection{	  boispozoremibarrdong:1997,
  address =      {London},
  author =       {R. Boisvert and R. Pozo and K. Remington and R. Barrett and J.
                  Dongarra},
  booktitle =    {The quality of numerical software: assessment and enhancement},
  editor =       {R. F. Boisvert},
  pages =        {125--137},
  publisher =    {Chapman \& Hall},
  title =        {{Matrix Market}: {A} web resource for test matrix collections},
  year =         1997
}

@Article{	  bongconngoultoin:1995,
  author =       {I. Bongartz and A. R. Conn and N. I. M. Gould and {\mbox{Ph}}.
                  L. Toint},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      acmmathsoft,
  month =        {March},
  number =       1,
  pages =        {123-160},
  title =        {{CUTE}: Constrained and Unconstrained Testing Environment},
  volume =       21,
  year =         1995
}

@Book{		  bonnans2006numerical,
  title =        {Numerical optimization: theoretical and practical aspects},
  author =       {Bonnans, Joseph-Fr{\'e}d{\'e}ric and Gilbert, Jean Charles and
                  Lemar{\'e}chal, Claude and Sagastiz{\'a}bal, Claudia A},
  year =         2006,
  publisher =    {Springer}
}

@article{bonsall1991general,
  title =        {A general atomic decomposition theorem and Banach's closed
                  range theorem},
  author =       {Bonsall, Frank F},
  journal =      {The Quarterly Journal of Mathematics},
  volume =       42,
  number =       1,
  pages =        {9--14},
  year =         1991,
  publisher =    {Oxford University Press}
}

@InProceedings{	  bottou-2010,
  author =       {Bottou, L\'{e}on},
  title =        {Large-Scale Machine Learning with Stochastic Gradient Descent},
  year =         2010,
  booktitle =    {Proceedings of the 19th International Conference on
                  Computational Statistics (COMPSTAT'2010)},
  editor =       {Lechevallier, Yves and Saporta, Gilbert},
  address =      {Paris, France},
  month =        {August},
  publisher =    {Springer},
  pages =        {177--187},
  url =          {http://leon.bottou.org/papers/bottou-2010}
}

@Article{	  boyd2011distributed,
  title =        {Distributed optimization and statistical learning via the
                  alternating direction method of multipliers},
  author =       {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato,
                  Borja and Eckstein, Jonathan},
  journal =      {Foundations and Trends in Machine Learning},
  volume =       3,
  number =       1,
  pages =        {1--122},
  year =         2011,
  publisher =    {Now Publishers Inc.}
}

@Book{		  boyd:2004,
  author =       {Boyd, Stephen and Vandenberghe, Lieven},
  title =        {Convex optimization},
  publisher =    {Cambridge University Press, Cambridge},
  year =         2004,
  pages =        {xiv+716},
  doi =          {10.1017/CBO9780511804441}
}

@Book{		  boydvand:2004,
  address =      {Cambridge, UK},
  author =       {Stephen Boyd and Lieven Vandenberghe},
  date-modified ={2007-07-26 16:36:59 -0700},
  publisher =    cambridgepress,
  title =        {Convex Optimization},
  year =         2004
}

@TechReport{	  bran:1995,
  address =      {Cornell Theory Center, Cornell University},
  author =       {M. A. Branch},
  date-modified ={2007-07-18 14:59:32 -0700},
  institution =  {Advanced Computing Research Institute},
  month =        {September},
  number =       {CTC94TR194},
  title =        {Getting {CUTE} with \textsc{Matlab}},
  year =         1995
}

@InProceedings{	  brau:1977,
  address =      {Berlin, New York},
  author =       {J{\"u}rgen Br{\"a}uninger},
  booktitle =    {Optimization Techniques, proceedings of the 8th {IFIP}
                  Conference, W{\"u}rzburg, Part 2, Lecture Notes in Control and
                  Inform. Sci.},
  date-modified ={2007-07-18 14:59:31 -0700},
  pages =        {33-41},
  publisher =    springer,
  title =        {A Modification of {R}obinson's Algorithm for General Nonlinear
                  Programming Problems Requiring Only Approximate Solutions of
                  Subproblems with Linear Equality Constraints},
  year =         1977
}

@Article{	  brau:1981,
  author =       {J{\"u}rgen Br{\"a}uninger},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      jota,
  month =        {October},
  number =       2,
  pages =        {195-216},
  title =        {A Globally Convergent Version of {R}obinson's Algorithm for
                  General Nonlinear Programming Problems Without Using
                  Derivatives},
  volume =       35,
  year =         1981
}

@Article{	  bre67,
  author =       "L.M. Bregman",
  title =        "The Relaxation Method of Finding the Common Point of Convex
                  Sets and Its Application to the Solution of Problems in Convex
                  Programming ",
  journal =      "USSR Computational Mathematics and Mathematical Physics",
  year =         1967,
  volume =       7,
  page =         {200--217}
}

@Article{	  bren:1972,
  author =       {R. P. Brent},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      {IBM J. Research and Development},
  note =         {email him for ref},
  title =        {On the Davidenko-Branin method for solving simultaneous
                  nonlinear equations},
  year =         1972
}

@Article{	  brenwinowolf:1973,
  author =       {R. P. Brent and S. Winograd and P. Wolfe},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      numermath,
  pages =        {327-341},
  title =        {Optimal iterative processes for rootfinding},
  year =         1973
}

@Article{	  brodgourgree:1973,
  author =       {K. W. Brodlie and A. R. Gourlay and J. Greenstadt},
  journal =      instmathapp,
  pages =        {73--82},
  title =        {Rank-one and rank-two corrections to positive definite
                  matrices expressed in product form},
  volume =       11,
  number =       1,
  year =         1973
}

@Book{		  brookendmeer:1988,
  address =      {Redwood City, CA},
  author =       {A. Brooke and D. Kendrick and A. Meeraus},
  date-modified ={2007-07-18 14:59:32 -0700},
  publisher =    scientific,
  title =        {{GAMS}: A User's Guide},
  year =         1988
}

@Article{	  bt:2000,
  author =       {Dimitri P. Bertsekas and John N. Tsitsiklis},
  title =        {Gradient convergence in gradient methods with errors},
  journal =      siamopt,
  year =         2000,
  volume =       10,
  number =       3,
  pages =        {627-642}
}

@Article{	  bty08,
  author =       "Biswas, P. and Toh, K.-C. and Ye, Y.",
  title =        "A Distributed {SDP} Approach for Large-Scale Noisy Anchor-Free
                  Graph Realization with Applications to Molecular Conformation",
  journal =      siamcomp,
  year =         2008,
  volume =       30,
  number =       2,
  page =         {1251--1277}
}

@Article{	  buck85,
  author =       {A. Buckley and A. {LeNir}},
  title =        {{BBVSCG}—a variable storage algorithm for function
                  minimization},
  journal =      acmmathsoft,
  number =       11,
  year =         1985,
  pages =        {103–-119}
}

@InCollection{	  buckdono:1995,
  address =      {New York},
  author =       {J. Buckheit and D. L. Donoho},
  booktitle =    {Wavelets and Statistics},
  editor =       {A. Anatoniadis},
  publisher =    {Springer-Verlag},
  title =        {{WaveLab} and reproducible research},
  year =         1995
}

@Article{	  buckl83,
  author =       {A. Buckley and A. {LeNir}},
  title =        {{QN-like} variable storage conjugate gradients},
  journal =      mathprog,
  number =       27,
  year =         1983,
  pages =        {155-–175}
}

@Article{	  bure:2009,
  title =        {Optimizing a polyhedral-semidefinite relaxation of completely
                  positive programs},
  author =       {Sam Burer},
  journal =      {Journal Mathematical Programming Computation},
  volume =       2,
  number =       1,
  month =        {March},
  year =         2010,
  doi =          {10.1007/s12532-010-0010-8},
  pages =        {1-19}
}

@Article{	  burer:2002,
  author =       {Burer, Samuel and Monteiro, Renato D. C. and Zhang, Yin},
  title =        {Solving a class of semidefinite programs via nonlinear
                  programming},
  journal =      mathprog,
  volume =       93,
  year =         2002,
  number =       1,
  pages =        {97--122},
  doi =          {10.1007/s101070100279}
}

@Article{	  burer:2005,
  author =       {Burer, Samuel and Monteiro, Renato D. C.},
  title =        {Local minima and convergence in low-rank semidefinite
                  programming},
  journal =      mathprog,
  volume =       103,
  year =         2005,
  number =       3,
  pages =        {427--444},
  doi =          {10.1007/s10107-004-0564-1}
}

@Article{	  burermont:2003,
  author =       {Burer, Samuel and Monteiro, Renato D.C.},
  affiliation =  {Department of Management Sciences, University of Iowa, Iowa
                  City, IA 52242-1000, e-mail: burer@math.gatech.edu US},
  title =        {A nonlinear programming algorithm for solving semidefinite
                  programs via low-rank factorization},
  journal =      mathprog,
  pages =        {329-357},
  volume =       95,
  issue =        2,
  doi =          {10.1007/s10107-002-0352-8},
  abstract =     {In this paper, we present a nonlinear programming algorithm
                  for solving semidefinite programs (SDPs) in standard form. The
                  algorithm's distinguishing feature is a change of variables
                  that replaces the symmetric, positive semidefinite variable X
                  of the SDP with a rectangular variable R according to the
                  factorization X = RR T . The rank of the factorization, i.e.,
                  the number of columns of R , is chosen minimally so as to
                  enhance computational speed while maintaining equivalence with
                  the SDP. Fundamental results concerning the convergence of the
                  algorithm are derived, and encouraging computational results
                  on some large-scale test problems are also presented.},
  year =         2003
}

@Article{	  burk:1991,
  author =       {J. V. Burke},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamcontrol,
  number =       4,
  pages =        {968--998},
  title =        {An exact penalization viewpoint of constrained optimization},
  volume =       29,
  year =         1991
}

@Article{	  burkdeng:2005,
  author =       {J. V. Burke and S. Deng},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      mathprog,
  mrclass =      {90C31 (49J52)},
  mrnumber =     {MR2179237 (2006e:90125)},
  number =       {2-3, Ser. B},
  pages =        {235--261},
  title =        {Weak sharp minima revisited. {II}. {A}pplication to linear
                  regularity and error bounds},
  volume =       104,
  year =         2005
}

@article{burke1991calmness,
  title =        {Calmness and exact penalization},
  author =       {Burke, J. V.},
  journal =      siamcontrol,
  volume =       29,
  number =       2,
  pages =        {493--497},
  year =         1991,
  publisher =    {SIAM}
}

@article{burke1995gauss,
  title =        {A Gauss—Newton method for convex composite optimization},
  author =       {Burke, James V and Ferris, Michael C},
  journal =      mathprog,
  volume =       71,
  number =       2,
  pages =        {179--194},
  year =         1995,
  publisher =    {Springer}
}

@article{burke2001abscissa,
  title =        {Variational analysis of the abscissa mapping for polynomials},
  author =       {Burke, James V and Overton, Michael L},
  journal =      siamcontrol,
  volume =       39,
  number =       6,
  pages =        {1651--1676},
  year =         2001,
  publisher =    {SIAM}
}

@article{burke2001spectral,
  title =        {Variational analysis of non-Lipschitz spectral functions},
  author =       {Burke, James V and Overton, Michael L},
  journal =      mathprog,
  volume =       90,
  number =       2,
  pages =        {317--351},
  year =         2001,
  publisher =    {Springer}
}

@article{burke2003variational,
  title =        {Variational analysis applied to the problem of optical phase
                  retrieval},
  author =       {Burke, James V and Luke, D Russell},
  journal =      siamcontrol,
  volume =       42,
  number =       2,
  pages =        {576--595},
  year =         2003,
  publisher =    {SIAM}
}

@article{burke2005robust,
  title =        {A robust gradient sampling algorithm for nonsmooth, nonconvex
                  optimization},
  author =       {Burke, James V and Lewis, Adrian S and Overton, Michael L},
  journal =      siamopt,
  volume =       15,
  number =       3,
  pages =        {751--779},
  year =         2005,
  publisher =    {SIAM}
}

@Article{	  burkehoheisel:2013,
  author =       {James V. Burke and Tim Hoheisel},
  title =        {Epi-convergent Smoothing with Applications to Convex Composite
                  Functions},
  journal =      siamopt,
  volume =       23,
  number =       3,
  pages =        {1457-1479},
  year =         2013,
  doi =          {10.1137/120889812},
  url =          { http://dx.doi.org/10.1137/120889812 },
  eprint =       { http://dx.doi.org/10.1137/120889812 }
}

@Article{	  burkferr:1993,
  author =       {J. V. Burke and M. C. Ferris},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      siamcontrol,
  number =       5,
  pages =        {1340--1359},
  title =        {Weak sharp minima in mathematical programming},
  volume =       31,
  year =         1993
}

@Article{	  burkhan:1986,
  author =       {J. Burke and {S.-P.} Han},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      mathofor,
  month =        {November},
  number =       4,
  pages =        {632-643},
  title =        {A {G}auss-{N}ewton Approach to Solving Generalized
                  Inequalities},
  volume =       11,
  year =         1986
}

@Article{	  burkmore:1994,
  author =       {James V. Burke and Jorge J. Mor\'{e}},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamopt,
  month =        {August},
  number =       3,
  pages =        {573--595},
  title =        {Exposing constraints},
  volume =       4,
  year =         1994
}

@TechReport{	  buso:1985,
  title =        {Handling degeneracy in a nonlinear L1 algorithm},
  author =       {Busovaca, S.},
  institution =  {Computer Science Department, University of Waterloo},
  type =         {Tech. Rep.},
  number =       {CS-85-34},
  year =         1985
}

@Article{	  byrd:2011,
  author =       {Richard H. Byrd and Gillian M. Chin and Will Neveitt and Jorge
                  Nocedal},
  title =        {On the Use of Stochastic Hessian Information in Optimization
                  Methods for Machine Learning},
  publisher =    {SIAM},
  year =         2011,
  journal =      siamopt,
  volume =       21,
  number =       3,
  pages =        {977-995},
  keywords =     {unconstrained optimization; stochastic optimization; machine
                  learning},
  url =          {http://link.aip.org/link/?SJE/21/977/1},
  doi =          {10.1137/10079923X}
}

@Article{	  byrd:2012,
  author =       {Byrd, Richard H. and Chin, Gillian and Nocedal, Jorge and Wu,
                  Yuchen},
  affiliation =  {Department of Computer Science, University of Colorado,
                  Boulder, CO, USA},
  title =        {Sample size selection in optimization methods for machine
                  learning},
  journal =      mathprog,
  publisher =    {Springer Berlin / Heidelberg},
  keyword =      {Mathematics and Statistics},
  pages =        {127-155},
  volume =       134,
  issue =        1,
  doi =          {10.1007/s10107-012-0572-5},
  abstract =     {This paper presents a methodology for using varying sample
                  sizes in batch-type optimization methods for large-scale
                  machine learning problems. The first part of the paper deals
                  with the delicate issue of dynamic sample selection in the
                  evaluation of the function and gradient. We propose a
                  criterion for increasing the sample size based on variance
                  estimates obtained during the computation of a batch gradient.
                  We establish an $${O(1/\epsilon)}$$ complexity bound on the
                  total cost of a gradient method. The second part of the paper
                  describes a practical Newton method that uses a smaller sample
                  to compute Hessian vector-products than to evaluate the
                  function and the gradient, and that also employs a dynamic
                  sampling technique. The focus of the paper shifts in the third
                  part of the paper to L 1 -regularized problems designed to
                  produce sparse solutions. We propose a Newton-like method that
                  consists of two phases: a (minimalistic) gradient projection
                  phase that identifies zero variables, and subspace phase that
                  applies a subsampled Hessian Newton iteration in the free
                  variables. Numerical tests on speech recognition problems
                  illustrate the performance of the algorithms.},
  year =         2012
}

@Article{	  byrdgoulnocewalt:2004,
  author =       {R. H. Byrd and N. I. M. Gould and J. Nocedal and R. A. Waltz},
  date-modified ={2007-10-22 16:57:18 -0700},
  journal =      mathprog,
  number =       1,
  pages =        {27--48},
  title =        {An algorithm for nonlinear optimization using linear
                  programming and equality constrained subproblems},
  volume =       100,
  year =         2004
}

@TechReport{	  byrdgoulnocewalt:2004b,
  address =      {Northwestern University, Evanston, IL},
  author =       {R. H. Byrd and N. I. M. Gould and J. Nocedal and R. A. Waltz},
  date-modified ={2007-10-19 14:47:06 -0700},
  institution =  {Optimization Technology Center},
  number =       {OTC 5/2002},
  title =        {On the convergence of successive linear programming
                  algorithms},
  type =         {Tech. rep.},
  year =         2004
}

@Article{	  byrdhribnoce:1999,
  author =       {R. Byrd and M. E. Hribar and J. Nocedal},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamopt,
  number =       4,
  pages =        {877-900},
  title =        {An Interior Point Method for Large Scale Nonlinear
                  Programming},
  volume =       9,
  year =         1999
}

@InCollection{	  byrdnocewalt:06,
  author =       {R. H. Byrd and J. Nocedal and R. A. Waltz},
  title =        {{KNITRO}: An Integrated Package for Nonlinear Optimization},
  booktitle =    {Large-Scale Nonlinear Optimization},
  pages =        {35-59},
  publisher =    {Springer-Verlag},
  address =      {New York},
  year =         2006,
  editor =       {G. di Pillo and M. Roma}
}

@Article{	  byrdschnshul:1987,
  author =       {R. H. Byrd and R. B. Schnabel and G. A. Shultz},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      siamnumanal,
  month =        {October},
  number =       5,
  pages =        {1152-1170},
  title =        {A Trust Region Algorithm for Nonlinearly Constrained
                  Optimization},
  volume =       24,
  year =         1987
}

@Article{	  calvlewireicsgal:2004,
  abstract =     {Many numerical methods for the solution of ill-posed problems
                  are based on Tikhonov regularization. Recently, Rojas and
                  Steihaug described a barrier method for computing nonnegative
                  Tikhonov-regularized approximate solutions of linear discrete
                  ill-posed problems. Their method is based on solving a
                  sequence of parameterized eigenvalue problems. This paper
                  describes how the solution of parametrized eigenvalue problems
                  can be avoided by computing bounds that follow from the
                  connection between the Lanczos process, orthogonal polynomials
                  and Gauss quadrature. },
  author =       {Daniela Calvetti and Bryan Lewis and Lothar Reichel and
                  Fiorella Sgallari},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      {Electronic Transactions on Numerical Analysis},
  keywords =     {Ill-posed problem, inverse problem, solution constraint,
                  Lanczos methods, Gauss quadrature},
  pages =        {153--173},
  title =        {Tikhonov regularization with nonnegativity constraint},
  volume =       18,
  year =         2004
}

@Article{	  can08,
  title =        {The restricted isometry property and its implications for
                  compressed sensing},
  author =       {Cand\`es, E.J.},
  journal =      {Comptes rendus-Math{\'e}matique},
  volume =       346,
  number =       {9-10},
  pages =        {589--592},
  year =         2008
}

@InProceedings{	  cand:2006,
  author =       {E. J. Cand\`{e}s},
  booktitle =    {Proceedings of the International Congress of Mathematicians},
  location =     {Madrid, Spain},
  title =        {Compressive sampling},
  year =         2006
}

@Article{	  canddemadonoying:2005,
  author =       {E. J. Cand\`{e}s and L. Demanet and D. L. Donoho and L.-X.
                  Ying},
  title =        {Fast discrete curvelet transforms},
  journal =      siammms,
  volume =       5,
  pages =        {861--899},
  year =         2005
}

@TechReport{	  candes2008,
  author =       "Candes, E. J. and Recht, B.",
  title =        "Exact Matrix Completion via Convex Optimization",
  institution =  "California Institute of Technology",
  address =      "Pasadena",
  month =        "May",
  year =         2008
}

@Article{	  candes2011robust,
  title =        {Robust principal component analysis?},
  author =       {Cand{\`e}s, Emmanuel J and Li, Xiaodong and Ma, Yi and Wright,
                  John},
  journal =      jacm,
  volume =       58,
  number =       3,
  pages =        11,
  year =         2011,
  publisher =    {ACM}
}

@article{candes2013phaselift,
  title={Phaselift: Exact and stable signal recovery from magnitude measurements via convex programming},
  author={Cand\`es, Emmanuel J and Strohmer, Thomas and Voroninski,
                  Vladislav},
  journal={Comm. Pure Appl. Math.},
  volume={66},
  number={8},
  pages={1241--1274},
  year={2013},
  publisher={Wiley Online Library}
}

@Article{	  candes:2013,
  author =       {Cand{\`e}s, Emmanuel J. and Eldar, Yonina C. and Strohmer,
                  Thomas and Voroninski, Vladislav},
  title =        {Phase retrieval via matrix completion},
  journal =      siamsiims,
  volume =       6,
  year =         2013,
  number =       1,
  pages =        {199--225},
  coden =        {SJISBI},
  mrclass =      {94A08 (42A38 90C25)},
  mrnumber =     3032952
}

@Article{	  candes:2014:sqe:2673201.2673259,
  author =       {Cand\`{e}s, Emmanuel J. and Li, Xiaodong},
  title =        {Solving Quadratic Equations via {PhaseLift} When There Are
                  About As Many Equations As Unknowns},
  journal =      {Found. Comput. Math.},
  issue_date =   {October 2014},
  volume =       14,
  number =       5,
  month =        oct,
  year =         2014,
  pages =        {1017--1026},
  numpages =     10,
  url =          {http://dx.doi.org/10.1007/s10208-013-9162-z},
  doi =          {10.1007/s10208-013-9162-z},
  acmid =        2673259,
  publisher =    {Springer-Verlag New York, Inc.},
  address =      {Secaucus, NJ, USA},
  keywords =     {49N30, 60F10, 62H12, 90C25, Deviation inequalities for random
                  matrices, Phase retrieval, PhaseLift, Semidefinite relaxations
                  of nonconvex quadratic programs}
}

@Misc{		  candeslisoltanolkotabi:2014,
  author =       {Emmanuel Cand\`es and Xiaodong Li and Mahdi Soltanolkotabi},
  title =        {Phase Retrieval via Wirtinger Flow: Theory and Algorithms},
  year =         2014,
  eprint =       {arXiv:1407.1065},
  url =          {http://arxiv.org/abs/1407.1065}
}

@InProceedings{	  candesromberg:2006,
  author =       {E. J. Cand\`{e}s and J. Romberg},
  booktitle =    {Computational Imaging III, Proc. SPIE Conf.},
  title =        {Practical Signal Recovery from Random Projections},
  editors =      {Charles A. Bouman, Eric L. Miller},
  volume =       5914,
  pages =        {76--86},
  month =        {March},
  year =         2005
}

@Article{	  candestao:2010,
  author =       {Emmanuel J. Cand\`{e}s and Terence Tao},
  title =        {The power of convex relaxation: near-optimal matrix
                  completion},
  year =         2010,
  journal =      ieeetransinfo,
  month =        {May},
  pages =        {2053-2080},
  doi =          {10.1109/TIT.2010.2044061},
  volume =       56
}

@Article{	  candeswakinboyd:2008,
  author =       {E. J. Cand\'es and M. B. Wakin and S. P. Boyd},
  title =        {Enhancing sparsity by reweighted {L1} minimization},
  journal =      {J. Fourier Anal. Appl.},
  year =         2008,
  volume =       14,
  number =       5,
  pages =        {877--905},
  doi =          {10.1007/s00041-008-9045-x}
}

@Article{	  candplan:2010,
  author =       {Emmanuel J. Cand\`{e}s and Yaniv Plan},
  title =        {Matrix completion with noise},
  journal =      {Proc. IEEE},
  year =         2010,
  pages =        {925-936},
  volume =       98,
  doi =          {10.1109/JPROC.2009.2035722}
}

@Misc{		  candromb:2007,
  author =       {E. J. Cand\`{e}s and J. Romberg},
  date-modified ={2007-07-26 16:37:57 -0700},
  howpublished = {\url{http://www.l1-magic.org/}},
  title =        {{$\ell_1$-magic}},
  year =         2007
}

@Article{	  candtao:2006,
  author =       {E. J. Cand\`{e}s and T. Tao},
  doi =          {10.1109/TIT.2006.885507},
  journal =      ieeetransinfo,
  month =        {December},
  number =       12,
  pages =        {5406--5425},
  title =        {Near-optimal signal recovery from random projections:
                  Universal encoding strategies?},
  volume =       52,
  year =         2006
}

@Article{	  candtao:2009,
  title =        {The power of convex relaxation: Near-optimal matrix
                  completion},
  author =       {Cand{\`e}s, Emmanuel J and Tao, Terence},
  journal =      ieeetransinfo,
  volume =       56,
  number =       5,
  pages =        {2053--2080},
  year =         2010,
  publisher =    {IEEE}
}

@TechReport{	  candwakiboyd:2007tr,
  author =       {Cand\'es, E. J. and Wakin, M. B. and Boyd, S. P.},
  title =        {Enhancing Sparsity by Reweighted {L1} Minimization},
  institution =  {California Institute of Technology},
  year =         2007,
  month =        {October},
  note =         {Available at
                  \url{http://www.acm.caltech.edu/~emmanuel/papers/rwl1-oct2007.pdf}}
}

@Article{	  canr:2009,
  author =       "Emmanuel J. Candes and Ben Recht",
  title =        "Exact Matrix Completion via Convex Optimization",
  volume =       9,
  month =        {December},
  journal =      focm,
  year =         2009,
  pages =        {717-772}
}

@Misc{		  car08,
  author =       {Emmanuel J. Cand\`{e}s and Benjamin Recht},
  title =        {Exact matrix completion via convex optimization},
  url =
                  {http://www.acm.caltech.edu/~emmanuel/papers/NoisyCompletion.pdf},
  howpublished = {To appear in Found. Comput. Math.},
  year =         2008
}

@Article{	  cat05,
  author =       {E. J. Cand\`{e}s and T. Tao},
  journal =      ieeetransinfo,
  month =        {December},
  number =       12,
  pages =        {4203-4215},
  title =        {Decoding by linear programming},
  volume =       51,
  year =         2005
}

@TechReport{	  ccs08,
  author =       "Jian-Feng Cai and Emmanuel J. Cand\'es and Zuowei Shen",
  title =        "A singular value thresholding algorithm for matrix completion",
  type =         "Report",
  institution =  "California Institute of Technology",
  address =      "Pasadena",
  month =        "September",
  url =          {http://www.acm.caltech.edu/~emmanuel/papers/SVT.pdf},
  year =         2008
}

@Article{	  ccs10,
  author =       "Jian-Feng Cai and Emmanuel J. Cand\'es and Zuowei Shen",
  title =        "A Singular Value Thresholding Algorithm for Matrix Completion",
  journal =      siamopt,
  number =       20,
  volume =       4,
  pages =        {1956-1982},
  doi =          {10.1137/080738970},
  year =         2010
}

@Article{	  cds98,
  author =       {S. S. Chen and D. L. Donoho and M. A. Saunders},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamscicomp,
  number =       1,
  pages =        {33-61},
  publisher =    {SIAM},
  title =        {Atomic decomposition by basis pursuit},
  volume =       20,
  year =         1998
}

@Book{		  cez97,
  author =       "Censor, Y. and Zenios, S.",
  title =        "Parallel Optimization: Theory, Algoritluns, and Applications",
  publisher =    "Oxford University Press",
  year =         1997,
  address =      "New York"
}

@Article{	  chaimoscosopapanicolaou:2011,
  author =       {Anwei Chai and Miguel Moscoso and George Papanicolaou},
  title =        {Array imaging using intensity-only measurements},
  journal =      {Inverse Problems},
  volume =       27,
  number =       1,
  pages =        015005,
  url =          {http://stacks.iop.org/0266-5611/27/i=1/a=015005},
  year =         2011,
  abstract =     {We introduce a new approach for narrow band array imaging of
                  localized scatterers from intensity-only measurements by
                  considering the possibility of reconstructing the positions
                  and reflectivities of the scatterers exactly from only partial
                  knowledge of the array data, since we assume that phase
                  information is not available. We reformulate this
                  intensity-only imaging problem as a non-convex optimization
                  problem and show that we can have exact recovery by minimizing
                  the rank of a positive semidefinite matrix associated with the
                  unknown reflectivities. Since this optimization problem is
                  NP-hard and is computationally intractable, we replace the
                  rank of the matrix by its nuclear norm, the sum of its
                  singular values, which is a convex programming problem that
                  can be solved in polynomial time. Numerical experiments
                  explore the robustness of this approach, which recovers sparse
                  reflectivity vectors exactly as solutions of a convex
                  optimization problem.}
}

@Article{	  chamdevoleeluci:1998,
  author =       {Chambolle, A. and De Vore, R.A. and Nam-Yong Lee and Lucier,
                  B.J.},
  date-added =   {2008-01-06 20:42:42 -0800},
  date-modified ={2008-01-08 20:52:36 -0800},
  doi =          {10.1109/83.661182},
  journal =      ieeetransimproc,
  keywords =     {Gaussian noise, data compression, image coding, image
                  representation, minimisation, parameter estimation, transform
                  coding, wavelet transformsGaussian noise, SNR, SureShrink
                  method, accurate error bounds, approximate minimizers, coding
                  error, dyadic level, exact minimizers, experimental results,
                  i.i.d. noise, image compression, mean zero noise, near-optimal
                  shrinkage parameters, noise removal, nonlinear wavelet image
                  processing, parameter estimation, shrinkage parameters,
                  signal-to-noise ratio, variational problems, visual
                  perception, wavelet based image processing algorithms, wavelet
                  representation, wavelet shrinkage},
  month =        {March},
  number =       3,
  pages =        {319-335},
  title =        {Nonlinear wavelet image processing: variational problems,
                  compression, and noise removal through wavelet shrinkage},
  volume =       7,
  year =         1998
}

@Article{	  chandrasekaran2012convex,
  year =         2012,
  journal =      {Found. Comput. Math.},
  volume =       12,
  number =       6,
  title =        {The Convex Geometry of Linear Inverse Problems},
  publisher =    {Springer-Verlag},
  keywords =     {Convex optimization; Semidefinite programming; Atomic norms;
                  Real algebraic geometry; Gaussian width; Symmetry; 52A41;
                  90C25; 90C22; 60D05; 41A45},
  author =       {Chandrasekaran, Venkat and Recht, Benjamin and Parrilo,
                  PabloA. and Willsky, Alan S.},
  pages =        {805-849},
  language =     {English}
}

@Article{	  chanmorabaramitt:2008,
  author =       {W. L. Chan and M. L. Moravec and R. G. Baraniuk and D. M.
                  Mittleman},
  journal =      {Opt. Lett.},
  keywords =     {Ultrafast measurements; Terahertz imaging},
  number =       9,
  pages =        {974--976},
  publisher =    {OSA},
  title =        {Terahertz imaging with compressed sensing and phase retrieval},
  volume =       33,
  year =         2008,
  url =          {http://www.opticsinfobase.org/abstract.cfm?URI=ol-33-9-974}
}

@InProceedings{	  chartrandyin:2008,
  author =       {Chartrand, R. and Wotao Yin},
  booktitle =    {Acoustics, Speech and Signal Processing, 2008. ICASSP 2008.
                  IEEE International Conference on},
  title =        {Iteratively reweighted algorithms for compressive sensing},
  year =         2008,
  month =        {31 2008-april 4},
  pages =        {3869 -3872},
  keywords =     {compressive sensing theory;iteratively reweighted
                  algorithm;reweighted least-squares algorithm;signal
                  reconstruction;iterative methods;least squares
                  approximations;signal reconstruction;},
  doi =          {10.1109/ICASSP.2008.4518498}
}

@Article{	  chasanparwil11,
  author =       {V. Chandrasekaran and S. Sanghavi and P. P. Parrilo and A. S.
                  Willsky},
  title =        {Rank-Sparsity Incoherence for Matrix Decomposition},
  journal =      siamopt,
  year =         2011,
  number =       2,
  volume =       21,
  pages =        {572-596},
  doi =          {10.1137/090761793},
  abstract =     {Suppose we are given a matrix that is formed by adding an
                  unknown sparse matrix to an unknown low-rank matrix. Our goal
                  is to decompose the given matrix into its sparse and low-rank
                  components. Such a problem arises in a number of applications
                  in model and system identification, and is NP-hard in general.
                  In this paper we consider a convex optimization formulation to
                  splitting the specified matrix into its components, by
                  minimizing a linear combination of the $\ell_1$ norm and the
                  nuclear norm of the components. We develop a notion of
                  rank-sparsity incoherence, expressed as an uncertainty
                  principle between the sparsity pattern of a matrix and its row
                  and column spaces, and use it to characterize both fundamental
                  identifiability as well as (deterministic) sufficient
                  conditions for exact recovery. Our analysis is geometric in
                  nature, with the tangent spaces to the algebraic varieties of
                  sparse and low-rank matrices playing a prominent role. When
                  the sparse and low-rank matrices are drawn from certain
                  natural random ensembles, we show that the sufficient
                  conditions for exact recovery are satisfied with high
                  probability. We conclude with simulation results on synthetic
                  matrix decomposition problems.}
}

@Article{	  chendonosaun:2001,
  author =       {S. S. Chen and D. L. Donoho and M. A. Saunders},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamreview,
  number =       1,
  pages =        {129--159},
  title =        {Atomic decomposition by basis pursuit},
  volume =       43,
  year =         2001
}

@Article{	  chenhuo:2006,
  author =       {J. Chen and X. Huo},
  title =        {Theoretical Results on Sparse Represenations of
                  Multiple-Measurement Vectors},
  journal =      ieeetranssigproc,
  volume =       54,
  issue =        12,
  year =         2006,
  pages =        {4634--4643}
}

@TechReport{	  chinflet:2001,
  address =      {UK},
  author =       {C.M. Chin and R. Fletcher},
  institution =  {Department of Mathematics, University of Dundee},
  number =       {NA/199},
  title =        {On the Global Convergence of an {SLP}-Filter Algorithm that
                  takes {EQP} steps},
  type =         {Numerical Analysis Report},
  year =         2001
}

@Article{	  chinflet:2003,
  author =       {C.M. Chin and R. Fletcher},
  journal =      mathprog,
  number =       1,
  pages =        {161--177},
  title =        {On the Global Convergence of an {SLP}-Filter Algorithm that
                  takes {EQP} steps},
  volume =       96,
  year =         2003
}

@Article{	  cht93,
  author =       {Chen, G. and Teboulle, M.},
  title =        {Convergence analysis of a proximal-like minimization algorithm
                  using {B}regman functions},
  journal =      siamopt,
  year =         1993,
  pages =        {538--543}
}

@Article{	  cjsy06,
  author =       "Carter, Michael W. and Jin, Holly H. and Saunders, Michael A.
                  and Ye, Yinyu",
  title =        "Spaseloc: {A}n adaptive subproblem algorithm for scalable
                  wireless sensor network localization",
  journal =      siamopt,
  year =         2006,
  volume =       17,
  number =       4,
  page =         {1102--1128}
}

@Article{	  colehulb:1989,
  author =       {T. F. Coleman and L. A. Hulbert},
  journal =      {Math. Program., Series~B},
  number =       3,
  pages =        {373--406},
  title =        {A direct active set algorithm for large sparse quadratic
                  programs with simple bounds},
  volume =       45,
  year =         1989
}

@Article{	  coleli:1996,
  abstract =     {We propose a new algorithm, a reflective Newton method, for
                  the minimization of a quadratic function of many variables
                  subject to upper and lower bounds on some of the variables.
                  The method applies to a general (indefinite) quadratic
                  function for which a local minimum subject to bounds is
                  required and is particularly suitable for the large-scale
                  problem. Our new method exhibits strong convergence properties
                  and global and second-order convergence and appears to have
                  significant practical potential. Strictly feasible points are
                  generated. We provide experimental results on moderately large
                  and sparse problems based on both sparse Cholesky and
                  preconditioned conjugate gradient linear solvers.},
  author =       {T. F. Coleman and Y. Li},
  journal =      siamopt,
  number =       4,
  pages =        {1040--1058},
  title =        {A Reflective {N}ewton Method for Minimizing a Quadratic
                  Function Subject to Bounds on Some of the Variables},
  volume =       6,
  year =         1996
}

@Article{	  comwaj2005,
  author =       {Patrick L. Combettes and Val\'erie R. Wajs},
  title =        {Signal recovery by proximal forward-backward splitting},
  journal =      siammms,
  year =         2005,
  volume =       4,
  number =       4,
  pages =        {1168-1200}
}

@article{cond_grad,
  AUTHOR =       {Harchaoui, Z. and Juditsky, A. and Nemirovski, A.},
  TITLE =        {Conditional gradient algorithms for norm-regularized smooth
                  convex optimization},
  JOURNAL =      {Math. Program.},
  FJOURNAL =     {Mathematical Programming. A Publication of the Mathematical
                  Optimization Society},
  VOLUME =       152,
  YEAR =         2015,
  NUMBER =       {1-2, Ser. A},
  PAGES =        {75--112},
  ISSN =         {0025-5610},
  MRCLASS =      {90C25 (68T05 94A12)},
  MRNUMBER =     3369477,
  DOI =          {10.1007/s10107-014-0778-9},
  URL =          {http://dx.doi.org/10.1007/s10107-014-0778-9},
}

@Article{	  conngoulsarttoin:1996,
  author =       {A. R. Conn and N. I. M. Gould and A. Sartenaer and
                  {\mbox{Ph}}. L. Toint},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamopt,
  month =        {August},
  number =       3,
  pages =        {674-703},
  title =        {Convergence properties of an augmented {L}agrangian algorithm
                  for optimization with a combination of general equality and
                  linear constraints},
  volume =       6,
  year =         1996
}

@Article{	  conngoultoin:1988,
  author =       {A. R. Conn and N. I. M. Gould and \mbox{Ph}. L. Toint},
  abstract =     {We describe the results of a series of tests upon a class of
                  new methods of trust region type for solving the simple bound
                  constrained minimization problem. The results are encouraging
                  and lead us to believe that the method will prove useful in
                  solving large problems.},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      mathcomp,
  pages =        {399--430},
  summary =      {The results of tests on the trust-region methods proposed by
                  \citebb{ConnGoulToin88a} for solving the bound constrained
                  minimization problem are discussed.},
  title =        {Testing a class of methods for solving minimization problems
                  with simple bounds on the variables},
  volume =       50,
  year =         1988
}

@Article{	  conngoultoin:1991,
  author =       {A. R. Conn and N. I. M. Gould and {\mbox{Ph}}. L. Toint},
  journal =      siamnumanal,
  month =        {April},
  number =       2,
  pages =        {545--572},
  title =        {A Globally Convergent Augmented {L}agrangian Algorithm for
                  Optimization with General Constraints and Simple Bounds},
  volume =       28,
  year =         1991
}

@Book{		  conngoultoin:1992,
  address =      {Berlin},
  author =       {A. R. Conn and N. I. M. Gould and {\mbox{Ph}}. L. Toint},
  date-modified ={2007-10-22 16:04:53 -0700},
  publisher =    springer,
  series =       {Springer Series in Computational Mathematics},
  title =        {{\sf LANCELOT}: a {F}ortran package for Large-scale Nonlinear
                  Optimization ({R}elease {A})},
  year =         1992
}

@InProceedings{	  conngoultoin:1992a,
  author =       {A. R. Conn and N. I. M. Gould and {\mbox{Ph}}. L. Toint},
  booktitle =    {Numerical Analysis 1991, Pitman Res. Notes Math. Ser.},
  date-modified ={2007-10-13 18:35:11 -0700},
  editor =       {D. F. Griffiths and G. A. Watson},
  pages =        {49--68},
  publisher =    {Longman Scientific {\&} Technical, Harlow, UK},
  title =        {On the number of inner iterations per outer iteration of a
                  globally convergent algorithm for optimization with general
                  nonlinear equality constraints and simple bounds},
  year =         1992
}

@Article{	  conngoultoin:1997,
  abstract =     {This paper considers the number of inner iterations required
                  per outeriteration for the algorithm proposed by Conn et
                  al.{$[$}9{$]$}. We show that asymptotically, under suitable
                  reasonable assumptions, a single inner iteration suffices.},
  author =       {A. R. Conn and N. Gould and {\mbox{Ph}}. L. Toint},
  date-added =   {2007-10-13 18:38:05 -0700},
  date-modified ={2007-10-22 16:05:40 -0700},
  journal =      {Computational Optimization and Applications},
  m3 =           {10.1023/A:1008667728545},
  number =       1,
  pages =        {41--69},
  title =        {On the Number of Inner Iterations Per Outer Iteration of a
                  Globally Convergent Algorithm for Optimization with General
                  Nonlinear Inequality Constraints and Simple Bounds},
  ty =           {JOUR},
  url =          {http://dx.doi.org/10.1023/A:1008667728545},
  volume =       7,
  year =         1997
}

@Book{		  conngoultoin:2000,
  address =      {Philadelphia},
  author =       {A. R. Conn and N. I. M. Gould and {\mbox{Ph}}. L. Toint},
  date-modified ={2007-07-18 14:59:34 -0700},
  publisher =    siampub,
  series =       {{MPS-SIAM} Series on Optimization},
  title =        {Trust-Region Methods},
  year =         2000
}

@TechReport{	  connsinc:1975,
  author =       {A. R. Conn and J. W. Sinclair},
  title =        {Quadratic programming via a nondifferentiable penalty
                  function},
  institution =  {Faculty of Mathematics, University of Waterloo, Waterloo},
  year =         1975,
  type =         {Tech. Rep.},
  number =       {CORR 75/15}
}

@Book{		  cormleisrivestei:2001,
  address =      {Cambridge, Massachussetts},
  author =       {Thomas H. Cormen and Charles E. Leiserson and Ronald L. Rivest
                  and Clifford Stein},
  date-modified ={2007-07-18 14:59:33 -0700},
  edition =      {Second},
  month =        {September},
  publisher =    {MIT Press},
  title =        {Introduction to Algorithms},
  year =         2001
}

@Article{	  correa1993convergence,
  title =        {Convergence of some algorithms for convex minimization},
  author =       {Correa, Rafael and Lemar{\'e}chal, Claude},
  journal =      mathprog,
  volume =       62,
  number =       {1-3},
  pages =        {261--275},
  year =         1993,
  publisher =    {Springer}
}

@Article{	  cottraoengakreu:2005,
  author =       {S. F. Cotter and B. D. Rao and K. Engan and K. Kreutz-Delgado},
  title =        {Sparse Solutions to Linear Inverse Problems with Multiple
                  Measurement Vectors},
  journal =      ieeetranssigproc,
  volume =       53,
  issue =        7,
  year =         2005,
  pages =        {2477--2488}
}

@Article{	  cour:1943,
  author =       {Richard Courant},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      bullams,
  pages =        {1--23},
  title =        {Variational methods for the solution of problems with
                  equilibrium and variation},
  volume =       49,
  year =         1943
}

@Book{		  covethom:1991,
  address =      {New York},
  author =       {Thomas Cover and Joy Thomas},
  date-modified ={2007-07-18 14:59:32 -0700},
  publisher =    {Wiley},
  title =        {Elements of Information Theory},
  year =         1991
}

@Misc{		  cplex:2007,
  howpublished = {Mathematical programming system, \url{http://www.cplex.com}},
  key =          {CPLEX},
  title =        {{ILOG CPLEX}},
  year =         2007
}

@article{cristofari2017two,
  title =        {A Two-Stage Active-Set Algorithm for Bound-Constrained
                  Optimization},
  author =       {Cristofari, Andrea and De Santis, Marianna and Lucidi, Stefano
                  and Rinaldi, Francesco},
  journal =      jota,
  volume =       172,
  number =       2,
  pages =        {369--401},
  year =         2017,
  publisher =    {Springer}
}

@Article{	  crt06a,
  abstract =     {This paper considers the model problem of reconstructing an
                  object from incomplete frequency samples. Consider a
                  discrete-time signal f/spl isin/C/sup N/ and a randomly chosen
                  set of frequencies /spl Omega/. Is it possible to reconstruct
                  f from the partial knowledge of its Fourier coefficients on
                  the set /spl Omega/? A typical result of this paper is as
                  follows. Suppose that f is a superposition of |T| spikes
                  f(t)=/spl sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl
                  delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl
                  middot/(log N)/sup -1/ /spl middot/ |/spl Omega/| for some
                  constant C/sub M/>0. We do not know the locations of the
                  spikes nor their amplitudes. Then with probability at least
                  1-O(N/sup -M/), f can be reconstructed exactly as the solution
                  to the /spl lscr//sub 1/ minimization problem. In short, exact
                  recovery may be obtained by solving a convex optimization
                  problem. We give numerical values for C/sub M/ which depend on
                  the desired probability of success. Our result may be
                  interpreted as a novel kind of nonlinear sampling theorem. In
                  effect, it says that any signal made out of |T| spikes may be
                  recovered by convex programming from almost every set of
                  frequencies of size O(|T|/spl middot/logN). Moreover, this is
                  nearly optimal in the sense that any method succeeding with
                  probability 1-O(N/sup -M/) would in general require a number
                  of frequency samples at least proportional to |T|/spl
                  middot/logN. The methodology extends to a variety of other
                  situations and higher dimensions. For example, we show how one
                  can reconstruct a piecewise constant (one- or two-dimensional)
                  object from incomplete frequency samples - provided that the
                  number of jumps (discontinuities) obeys the condition above -
                  by minimizing other convex functionals such as the total
                  variation of f.},
  author =       {E. J. Cand\`{e}s and J. Romberg and T. Tao},
  journal =      ieeetransinfo,
  month =        12,
  number =       2,
  pages =        {489-509},
  title =        {Robust uncertainty principles: exact signal reconstruction
                  from highly incomplete frequency information},
  volume =       52,
  year =         2006
}

@Article{	  crt06b,
  author =       {E. J. Cand\`{e}s and J. Romberg and T. Tao},
  journal =      {Comm. Pure Appl. Math.},
  number =       8,
  pages =        {1207-1223},
  title =        {Stable Signal Recovery from Incomplete and Inaccurate
                  Measurements},
  volume =       59,
  year =         2006
}

@Article{	  curtisnocedal:2008,
  journal =      {IMA Journal of Numerical Analysis},
  year =         2008,
  volume =       28,
  pages =        {749−769},
  doi =          {10.1093/imanum/drn003},
  title =        {Flexible penalty functions for nonlinear constrained
                  optimization},
  author =       {Frank E. Curtis and Jorge Nocedal}
}

@Misc{		  curvelet,
  author =       {E. J. Cand\`{e}s and L. Demanet and D. L. Donoho and L.-X.
                  Ying},
  howpublished = {\url{http://www.curvelet.org/}},
  title =        {{CurveLab}},
  year =         2007
}

@TechReport{	  dag08,
  author =       {M. E. Davies and R. Gribonval},
  title =        {Restricted isometry constants where $\ell^p$ sparse recovery
                  can fail for $0<p\le1$},
  institution =  {Institut de Recherche en Informatique et Syst\'emes
                  Al\'eatoires},
  year =         2008,
  type =         {Publication interne},
  number =       1899,
  month =        {July}
}

@Article{	  daiflet:2005,
  author =       {Y.-H. Dai and R. Fletcher},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      numermath,
  pages =        {21-47},
  title =        {Projected {B}arzilai-{B}orwein methods for large-scale
                  box-constrained quadratic programming},
  volume =       100,
  year =         2005
}

@Article{	  daihageschitzhan:2006,
  author =       {Y. Dai and W. W. Hager and K. Schittkowski and H. Zhang},
  date-added =   {2008-01-10 11:07:30 -0800},
  date-modified ={2008-01-10 11:08:16 -0800},
  title =        {The cyclic {Barzilai-Borwein} method for unconstrained
                  optimization},
  journal =      imanumerana,
  year =         2006,
  volume =       7,
  pages =        {604--627}
}

@Article{	  dani:1973,
  author =       {James W. Daniel},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      numermath,
  pages =        {381-387},
  title =        {{N}ewton's {M}ethod for Nonlinear Inequalities},
  volume =       21,
  year =         1973
}

@Book{		  dantzig:1998,
  abstract =     {In real-world problems related to finance, business, and
                  management, mathematicians and economists frequently encounter
                  optimization problems. In this classic book, George Dantzig
                  looks at a wealth of examples and develops linear programming
                  methods for their solutions. He begins by introducing the
                  basic theory of linear inequalities and describes the powerful
                  simplex method used to solve them. Treatments of the price
                  concept, the transportation problem, and matrix methods are
                  also given, and key mathematical concepts such as the
                  properties of convex sets and linear vector spaces are
                  covered. George Dantzig is properly acclaimed as the "father
                  of linear programming." Linear programming is a mathematical
                  technique used to optimize a situation. It can be used to
                  minimize traffic congestion or to maximize the scheduling of
                  airline flights. He formulated its basic theoretical model and
                  discovered its underlying computational algorithm, the
                  "simplex method," in a pathbreaking memorandum published by
                  the United States Air Force in early 1948. {\it Linear
                  Programming and Extensions} provides an extraordinary account
                  of the subsequent development of his subject, including
                  research in mathematical theory, computation, economic
                  analysis, and applications to industrial problems. Dantzig
                  first achieved success as a statistics graduate student at the
                  University of California, Berkeley. One day he arrived for a
                  class after it had begun, and assumed the two problems on the
                  board were assigned for homework. When he handed in the
                  solutions, he apologized to his professor, Jerzy Neyman, for
                  their being late but explained that he had found the problems
                  harder than usual. About six weeks later, Neyman excitedly
                  told Dantzig, "I've just written an introduction to one of
                  your papers. Read it so I can send it out right away for
                  publication." Dantzig had no idea what he was talking about.
                  He later learned that the "homework" problems had in fact been
                  two famous unsolved problems in statistics.},
  author =       {Dantzig, George B.},
  isbn =         0691059136,
  keywords =     {linear, programming},
  month =        {August},
  publisher =    {Princeton University Press},
  title =        {Linear Programming and Extensions},
  year =         1998
}

@Article{	  dasdenn:1997,
  author =       {I. Das and J. E. Dennis},
  date-added =   {2007-12-31 17:27:34 -0800},
  date-modified ={2007-12-31 17:28:48 -0800},
  journal =      {Struct. Optim.},
  pages =        {63--69},
  title =        {A closer look at drawbacks of minimizing weighted sums of
                  objectives for {Pareto} set generation in multicriteria
                  optimization problems},
  volume =       14,
  year =         1997
}

@Article{	  daubdevofornsina:2009,
  author =       {Daubechies, Ingrid and DeVore, Ronald and Fornasier, Massimo
                  and Güntürk, C. Si̇nan},
  title =        {Iteratively reweighted least squares minimization for sparse
                  recovery},
  journal =      {Communications on Pure and Applied Mathematics},
  volume =       63,
  number =       1,
  publisher =    {Wiley Subscription Services, Inc., A Wiley Company},
  url =          {http://dx.doi.org/10.1002/cpa.20303},
  doi =          {10.1002/cpa.20303},
  pages =        {1--38},
  year =         2010,
  abstract =     {Abstract Under certain conditions (known as the restricted
                  isometry property, or RIP) on the m × N matrix Φ (where m <
                  N), vectors x ∈ ℝN that are sparse (i.e., have most of their
                  entries equal to 0) can be recovered exactly from y := Φx even
                  though Φ−1(y) is typically an (N − m)—dimensional hyperplane;
                  in addition, x is then equal to the element in Φ−1(y) of
                  minimal �1-norm. This minimal element can be identified via
                  linear programming algorithms. We study an alternative method
                  of determining x, as the limit of an iteratively reweighted
                  least squares (IRLS) algorithm. The main step of this IRLS
                  finds, for a given weight vector w, the element in Φ−1(y) with
                  smallest �2(w)-norm. If x(n) is the solution at iteration step
                  n, then the new weight w(n) is defined by w i(n) := [|x i(n)|2
                  + ε n2]−1/2, i = 1, …, N, for a decreasing sequence of
                  adaptively defined εn; this updated weight is then used to
                  obtain x(n + 1) and the process is repeated. We prove that
                  when Φ satisfies the RIP conditions, the sequence x(n)
                  converges for all y, regardless of whether Φ−1(y) contains a
                  sparse vector. If there is a sparse vector in Φ−1(y), then the
                  limit is this sparse vector, and when x(n) is sufficiently
                  close to the limit, the remaining steps of the algorithm
                  converge exponentially fast (linear convergence in the
                  terminology of numerical optimization). The same algorithm
                  with the “heavier” weight w i(n) = [|x i(n)|2 + ε n2]−1+τ/2, i
                  = 1, …, N, where 0 < τ < 1, can recover sparse solutions as
                  well; more importantly, we show its local convergence is
                  superlinear and approaches a quadratic rate for τ approaching
                  0. © 2009 Wiley Periodicals, Inc.}
}

@Article{	  daubfornlori:2007,
  author =       {I. Daubechies and M. Fornasier and I. Loris},
  title =        {Accelereated projected gradient method for linear inverse
                  problems with sparsity constraints},
  journal =      {J. Fourier Anal. Appl.},
  year =         2007,
  note =         {To appear}
}

@TechReport{	  davies2008,
  author =       "Davies, M. E. and Gribonval, R.",
  title =        "Restricted isometry constants where $\ell-p$ sparse recovery
                  can fail for $0 < p \le 1$",
  institution =  "IRISA",
  number =       1899,
  address =      "Rennes",
  month =        "May",
  year =         2008
}

@Article{	  davis2011university,
  title =        {The University of Florida sparse matrix collection},
  author =       {Davis, Timothy A and Hu, Yifan},
  journal =      acmmathsoft,
  volume =       38,
  number =       1,
  pages =        1,
  year =         2011,
  publisher =    {ACM}
}

@Article{	  daw80,
  author =       "Dasarathy, B. and White, L. J.",
  title =        "A maxmin location problem",
  journal =      "Oper. Res.",
  year =         1980,
  volume =       28,
  number =       6,
  page =         {1385--1401}
}

@Article{	  dax:1992,
  author =       {A. Dax},
  date-modified ={2007-07-18 14:59:33 -0700},
  doi =          {10.1137/0802029},
  journal =      siamopt,
  keywords =     {lp least norm problems; regularization; optimality conditions;
                  behavior of regularized solutions; duality relations},
  number =       4,
  pages =        {602-618},
  publisher =    {SIAM},
  title =        {On Regularized Least Norm Problems},
  url =          {http://link.aip.org/link/?SJE/2/602/1},
  volume =       2,
  year =         1992
}

@Article{	  dbg08,
  author =       "{\noopsort{Asprement}}{D'Aspremont}, A. and Onureena Banerjee
                  and Laurent El Ghaoui",
  title =        "First-order methods for sparse covariance selection",
  journal =      siammatrix,
  year =         2008,
  volume =       30,
  number =       1,
  pages =        "56--66"
}

@Article{	  ddd04,
  author =       {I. Daubechies and M. Defrise and C. De Mol},
  issue =        11,
  journal =      {Comm. Pure Appl. Math.},
  pages =        {1413--1457},
  title =        {An iterative thresholding algorithm for linear inverse
                  problems with a sparsity constraint},
  volume =       57,
  year =         2004
}

@article{deKlerk1997213,
  title =        "Initialization in semidefinite programming via a self-dual
                  skew-symmetric embedding ",
  journal =      "Operations Research Letters ",
  volume =       20,
  number =       5,
  pages =        "213 - 221",
  year =         1997,
  doi =          "http://dx.doi.org/10.1016/S0167-6377(97)00011-4",
  url =
                  "http://www.sciencedirect.com/science/article/pii/S0167637797000114",
  author =       "E. de Klerk and C. Roos and T. Terlaky",
  keywords =     "Semidefinite programming",
  keywords =     "Duality",
  keywords =     "Self-dual embedding",
  keywords =     "Central path",
  keywords =     "Initialization ",
  abstract =     "The formulation of interior point algorithms for semidefinite
                  programming has become an active research area, following the
                  success of the methods for large-scale linear programming.
                  Many interior point methods for linear programming have now
                  been extended to the more general semidefinite case, but the
                  initialization problem remained unsolved. In this paper we
                  show that the initialization strategy of embedding the problem
                  in a self-dual skew-symmetric problem can also be extended to
                  the semidefinite case. This method also provides a solution
                  for the initialization of quadratic programs and it is
                  applicable to more general convex problems with conic
                  formulation. "
}

@Article{	  debr:1952,
  author =       {Gerard Debreu},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      {Econometrica},
  month =        {April},
  number =       2,
  pages =        {295--300},
  title =        {Definite and semidefinite quadratic forms},
  volume =       20,
  year =         1952
}

@Article{	  delgil:05,
  author =       {F. Delbos and J. Gilbert},
  title =        {Global linear convergence of an augmented {L}agrangian
                  algorithm for solving convex quadratic optimization problems},
  journal =      {J. Convex Anal.},
  volume =       12,
  pages =        {45--69},
  year =         2005
}

@Article{	  dembeisestei:1982,
  author =       {Ron S. Dembo and Stanley C. Eisenstat and Trond Steihaug},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamnumanal,
  number =       2,
  pages =        {400--408},
  title =        {Inexact {N}ewton methods},
  volume =       19,
  year =         1982
}

@Article{	  dennel-awill:1999,
  author =       {J. E. Dennis and Majmoud {El-Alem} and Karen Williamson},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      siamopt,
  number =       2,
  pages =        {291-315},
  title =        {A trust-region approach to nonlinear systems of equalities and
                  inequalities},
  volume =       9,
  year =         1999
}

@Book{		  dennschn:1996,
  address =      {Philadelphia},
  author =       {J. E. Dennis and R. B. Schnabel},
  date-modified ={2007-07-18 14:59:33 -0700},
  note =         {Originally published: Prentice-Hall, New Jersey, 1983},
  publisher =    siampub,
  series =       {Classics in Applied Mathematics},
  title =        {Numerical Methods for Unconstrained Optimization and Nonlinear
                  Equations},
  year =         1996
}

@Article{	  det06,
  author =       {D. L. Donoho and M. Elad and V. Temlyakov},
  journal =      ieeetransinfo,
  number =       1,
  pages =        {6-18},
  title =        {Stable Recovery of Sparse Overcomplete Representations in the
                  Presence of Noise},
  volume =       52,
  year =         2006
}

@Book{		  devrgyorlugo:1996,
  address =      {New York},
  author =       {L. Devroye and L. Gyorfi and G. Lugosi},
  date-modified ={2007-07-18 14:59:31 -0700},
  publisher =    springer,
  title =        {A Probabilistic Theory of Pattern Recognition},
  year =         1996
}

@inproceedings{ding2006r,
  title =        {{R 1-PCA}: Rotational invariant L1-norm principal component
                  analysis for robust subspace factorization},
  author =       {Ding, Chris and Zhou, Ding and He, Xiaofeng and Zha, Hongyuan},
  booktitle =    {Inter. Conf. Mach. Learning (ICML 2006)},
  pages =        {281--288},
  year =         2006,
  organization = {ACM}
}

@TechReport{	  dinigomesant:1998,
  abstract =     {In this work, we focus our attention on the quadratic
                  subproblem of trust-region algorithms for large-scale
                  bound-constrained minimization. An approach that combines a
                  mild active set strategy with gradient projection techniques
                  is employed in the solution of large-scale bound-constrained
                  quadratic problems. To fill in some gaps that have appeared in
                  previous work, we propose, test and analyze heuristics which
                  dynamically choose the parameters in charge of the decision of
                  leaving or not the current face of the feasible set. The
                  numerical analysis is based on problems from CUTE collection
                  and randomly generated convex problems with controlled
                  conditioning and degeneracy. The practical consequences of an
                  appropriate decision of such parameters are shown to be
                  crucial, particularly when dual degenerate and ill-conditioned
                  problems are solved.},
  address =      {Campinas, Brasil},
  author =       {M. A. Diniz{-}Ehrhardt and M. A. Gomes{-}Ruggiero and S. A.
                  Santos},
  date-modified ={2007-07-18 14:59:33 -0700},
  institution =  {Department of Applied Mathematics, IMECC-UNICAMP},
  number =       {52/98},
  title =        {Numerical analysis of leaving-face parameters in
                  bound-constrained quadratic minimization},
  year =         1998
}

@TechReport{	  dkqw08,
  author =       "Ding, Y. and Krislock, N. and Qian, J. and Wolkowicz, H.",
  title =        "Sensor Network Localization, Euclidean Distance Matrix
                  Completions, and Graph Realization",
  institution =  "Department of Combinatorics and Optimization, University of
                  Waterloo",
  address =      "Waterloo",
  month =        "February",
  year =         2008
}

@Article{	  doe03,
  abstract =     {Given a dictionary D = {dk} of vectors dk, we seek to
                  represent a signal S as a linear combination S = {sum}k
                  {gamma}(k)dk, with scalar coefficients {gamma}(k). In
                  particular, we aim for the sparsest representation possible.
                  In general, this requires a combinatorial optimization
                  process. Previous work considered the special case where D is
                  an overcomplete system consisting of exactly two orthobases
                  and has shown that, under a condition of mutual incoherence of
                  the two bases, and assuming that S has a sufficiently sparse
                  representation, this representation is unique and can be found
                  by solving a convex optimization problem: specifically,
                  minimizing the {ell}1 norm of the coefficients{gamma} . In
                  this article, we obtain parallel results in a more general
                  setting, where the dictionary D can arise from two or several
                  bases, frames, or even less structured systems. We sketch
                  three applications: separating linear features from planar
                  ones in 3D data, noncooperative multiuser encoding, and
                  identification of over-complete independent component models.
                  },
  author =       {D. L. Donoho and M. Elad},
  doi =          {10.1073/pnas.0437847100},
  eprint =       {http://www.pnas.org/cgi/reprint/100/5/2197.pdf},
  journal =      procnas,
  number =       5,
  pages =        {2197-2202},
  title =        {Optimally sparse representation in general (nonorthogonal)
                  dictionaries via $\ell_1$ minimization},
  url =          {http://www.pnas.org/cgi/content/abstract/100/5/2197},
  volume =       100,
  year =         2003
}

@Article{	  doh01,
  abstract =     {Suppose a discrete-time signal $S(t)$, $0 \leq t < N$, is a
                  superposition of atoms taken from a combined time-frequency
                  dictionary made of spike sequences $1_{t=\tau}$ and sinusoids
                  $\exp\{2\pi iw t/N\}/\sqrt{N}$. Can one recover, from
                  knowledge of $S$ alone, the precise collection of atoms going
                  to make up $S$? Because every discrete-time signal can be
                  represented as a superposition of spikes alone, or as a
                  superposition of sinusoids alone, there is no unique way of
                  writing S as a sum of spikes and sinusoids in general. We
                  prove that if $S$ is representable as a highly sparse
                  superposition of atoms from this time-frequency dictionary,
                  then there is only one such highly sparse representation of
                  $S$, and it can be obtained by solving the convex optimization
                  problem of minimizing the $\ell^1$ norm of the coefficients
                  among all decompositions. Here ``highly sparse'' means that
                  $N_t+N_w < \sqrt{N}/2$ where $N_t$ is the number of time
                  atoms, $N_w$ is the number of frequency atoms, and $N$ is the
                  length of the discrete-time signal. Underlying this result is
                  a general $\ell^1$ uncertainty principle which says that if
                  two bases are mutually incoherent, no nonzero signal can have
                  a sparse representation in both bases simultaneously. For the
                  above setting, the bases are sinusoids and spikes, and mutual
                  incoherence is measured in terms of the largest inner product
                  between different basis elements. The uncertainty principle
                  holds for a variety of interesting basis pairs, not just
                  sinusoids and spikes. The results have idealized applications
                  to band-limited approximation with gross errors, to
                  error-correcting encryption, and to separation of
                  uncoordinated sources. Related phenomena hold for functions of
                  a real variable, with basis pairs such as sinusoids and
                  wavelets, and for functions of two variables, with basis pairs
                  such as wavelets and ridgelets. In these settings, if a
                  function f is representable by a sufficiently sparse
                  superposition of terms taken from both bases, then there is
                  only one such sparse representation; it may be obtained by
                  minimum $\ell^1$ norm atomic decomposition. The condition
                  ``sufficiently sparse'' becomes a multiscale condition; for
                  example, that the number of wavelets at level $j$ plus the
                  number of sinusoids in the $j$th dyadic frequency band are
                  together less than a constant times $2^{j/2}$. },
  author =       {David L. Donoho and Xiaoming Huo},
  journal =      ieeetransinfo,
  keywords =     {Basis pursuit, combinatorial optimization, convex
                  optimization, error-correcting encryption, harmonic analysis,
                  Logan's phenomenon, matching pursuit, multiple-basis signal
                  representation, overcomplete representation, ridgelet
                  analysis, uncertainty principle, wavelet analysis},
  month =        {November},
  number =       7,
  pages =        {2845--2862},
  title =        {Uncertainty Principles and Ideal Atomic Decomposition},
  url =          {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=959265},
  volume =       47,
  year =         2001
}

@Article{	  doi:10.1137/0329022,
  author =       {Osman G\"uler},
  title =        {On the Convergence of the Proximal Point Algorithm for Convex
                  Minimization},
  journal =      {SIAM Journal on Control and Optimization},
  volume =       29,
  number =       2,
  pages =        {403-419},
  year =         1991,
  doi =          {10.1137/0329022},
  url =          { http://dx.doi.org/10.1137/0329022 },
  eprint =       { http://dx.doi.org/10.1137/0329022 }
}

@Article{	  doi:10.1137/040612592,
  author =       {Erdougan, E. and Iyengar, G.},
  title =        {An Active Set Method for Single-Cone Second-Order Cone
                  Programs},
  journal =      siamopt,
  volume =       17,
  number =       2,
  pages =        {459-484},
  year =         2006,
  doi =          {10.1137/040612592},
  url =          { http://dx.doi.org/10.1137/040612592 },
  eprint =       { http://dx.doi.org/10.1137/040612592 }
}

@Article{	  doi:10.1137/0802007,
  author =       {Michael L. Overton},
  title =        {Large-Scale Optimization of Eigenvalues},
  journal =      siamopt,
  volume =       2,
  number =       1,
  pages =        {88-120},
  year =         1992,
  doi =          {10.1137/0802007},
  url =          { http://dx.doi.org/10.1137/0802007 },
  eprint =       { http://dx.doi.org/10.1137/0802007 }
}

@Article{	  doi:10.1137/0802032,
  author =       {Osman G\"uler},
  title =        {New Proximal Point Algorithms for Convex Minimization},
  journal =      {SIAM Journal on Optimization},
  volume =       2,
  number =       4,
  pages =        {649-664},
  year =         1992,
  doi =          {10.1137/0802032},
  url =          { http://dx.doi.org/10.1137/0802032 },
  eprint =       { http://dx.doi.org/10.1137/0802032 }
}

@Article{	  doi:10.1137/12088728x,
  author =       {Alexandre d'Aspremont and Noureddine El Karoui},
  title =        {A Stochastic Smoothing Algorithm for Semidefinite Programming},
  journal =      siamopt,
  volume =       24,
  number =       3,
  pages =        {1138-1177},
  year =         2014,
  doi =          {10.1137/12088728X},
  url =          { http://dx.doi.org/10.1137/12088728X },
  eprint =       { http://dx.doi.org/10.1137/12088728X }
}

@Article{	  doi:10.1137/s1052623403428208,
  author =       {Zhang, H. and Hager, W.},
  title =        {A Nonmonotone Line Search Technique and Its Application to
                  Unconstrained Optimization},
  journal =      siamopt,
  volume =       14,
  number =       4,
  pages =        {1043-1056},
  year =         2004,
  doi =          {10.1137/S1052623403428208}
}

@Article{	  doj94,
  author =       {D. L. Donoho and I. M. Johnstone},
  journal =      {Biometrika},
  number =       3,
  pages =        {425--455},
  title =        {Ideal spatial adaptation by wavelet shrinkage},
  url =          {http://citeseer.ist.psu.edu/donoho93ideal.html},
  volume =       81,
  year =         1994
}

@Article{	  doj95,
  author =       "Donoho, D. L. and Johnstone, I. M.",
  title =        "Adapting to unknown smoothness via wavelet shrinkage",
  journal =      "Journal of the American Statistical Association",
  year =         1995,
  volume =       90,
  number =       432,
  page =         {1200--1224}
}

@Article{	  dolafourmoremuns:2002,
  author =       {Elizabeth D. Dolan and Robert Fourer and Jorge J. Mor\'{e} and
                  Todd S. Munson},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      {{SIAM} {N}ews},
  month =        {July/August},
  number =       6,
  title =        {Optimization on the {NEOS} server},
  volume =       35,
  year =         2002
}

@TechReport{	  dolamore:2000,
  address =      {Argonne, IL},
  author =       {Elizabeth D. Dolan and Jorge J. Mor\'{e}},
  date-modified ={2007-07-18 14:59:32 -0700},
  institution =  {Mathematics and Computer Science Division, Argonne National
                  Laboratory},
  note =         {Revised January 2001},
  number =       {ANL/MCS-246},
  title =        {Benchmarking Optimization Software with {COPS}},
  year =         2000
}

@TechReport{	  dolamore:2001,
  address =      {Argonne, IL},
  author =       {Elizabeth D. Dolan and Jorge J. Mor\'{e}},
  institution =  {Mathematics and Computer Science Division, Argonne National
                  Laboratory},
  number =       {ANL/MCS-P861-1200},
  title =        {Benchmarking Optimization Software with Performance Profiles},
  year =         2001
}

@Article{	  dolamore:2002,
  author =       {Elizabeth D. Dolan and Jorge J. Mor\'{e}},
  journal =      mathprog,
  number =       2,
  pages =        {201-213},
  title =        {Benchmarking Optimization Software with Performance Profiles},
  volume =       91,
  year =         2002
}

@Article{	  dollgoulschiwath:2006,
  abstract =     {We consider conjugate-gradient like methods for solving block
                  symmetric indefinite linear systems that arise from
                  saddle-point problems or, in particular, regularizations
                  thereof. Such methods require preconditioners that preserve
                  certain sub-blocks from the original systems but allow
                  considerable flexibility for the remaining blocks. We
                  construct a number of families of implicit factorizations that
                  are capable of reproducing the required sub-blocks and (some)
                  of the remainder. These generalize known implicit
                  factorizations for the unregularized case. Improved eigenvalue
                  clustering is possible if additionally some of the noncrucial
                  blocks are reproduced. Numerical experiments confirm that
                  these implicit-factorization preconditioners can be very
                  effective in practice. },
  author =       {H. S. Dollar and N. Gould and W. Schilders and A. J. Wathen},
  doi =          {10.1137/05063427X},
  journal =      siammath,
  keywords =     {regularized saddle-point systems; implicit-factorization
                  preconditioners},
  number =       1,
  pages =        {170-189},
  publisher =    {SIAM},
  title =        {Implicit-Factorization Preconditioning and Iterative Solvers
                  for Regularized Saddle-Point Systems},
  url =          {http://link.aip.org/link/?SML/28/170/1},
  volume =       28,
  year =         2006
}

@TechReport{	  don06a,
  author =       "Donoho, D. L.",
  title =        "For Most Large Underdetermined Systems of Linear Equations the
                  Minimal l1-norm Near-Solution Approximates the Sparsest
                  near-Solution",
  institution =  "Department of Statistics, Stanford University, Stanford",
  year =         2006
}

@Article{	  don06b,
  author =       "Donoho, D. L.",
  title =        "For Most Large Underdetermined Systems of Linear Equations,
                  the Minimal l1-norm Solution is also the Sparsest Solution",
  journal =      "Communications on Pure and Applied Mathematics",
  year =         2006,
  volume =       59,
  page =         {797--929}
}

@Article{	  don06c,
  author =       "Donoho, D. L., Elad, M., and Temlyakov, V. N.",
  title =        "Stable recovery of sparse overcomplete representations in the
                  presence of noise",
  journal =      "Information Theory, IEEE Transactions",
  year =         2006,
  volume =       52,
  page =         {6--18}
}

@Article{	  dono:2006b,
  author =       {D. L. Donoho},
  journal =      ieeetransinfo,
  month =        {April},
  number =       4,
  pages =        {1289--1306},
  title =        {Compressed sensing},
  volume =       52,
  year =         2006
}

@Article{	  donoho1994,
  author =       "Donoho, D. L. and Johnstone, I. M.",
  title =        "Ideal spatial adaptation by wavelet shrinkage",
  journal =      "Biometrika",
  year =         1994,
  volume =       81,
  page =         {425--455}
}

@Article{	  donoho2001,
  author =       "Donoho. D. L. and Huo, X.",
  title =        "Uncertainty principles and ideal atomic decomposition",
  journal =      "Information Theory, IEEE Transactions",
  year =         2001,
  volume =       47,
  page =         {2845--2862}
}

@Proceedings{	  donoho2003,
  author =       "Donoho, D. L. and Elad, M.",
  title =        "Optimally sparse representation in general (nonorthogonal)
                  dictionaries via $\ell-1$ minimization",
  year =         2003,
  organization = "Nat. Acad. Sci.",
  volume =       100,
  page =         {2197--2202}
}

@Article{	  donotann:2005b,
  author =       {David L. Dohono and Jared Tanner},
  title =        {Neighborliness of randomly-projected simplices in high
                  dimensions},
  journal =      procnas,
  volume =       102,
  number =       27,
  year =         2005,
  pages =        {9452--9457},
  url =          {http://www.pnas.org/cgi/content/abstract/102/27/9452},
  eprint =       {http://www.pnas.org/cgi/reprint/102/27/9452},
  keywords =     {Neighborly polytopes, convex hull of Gaussian sample,
                  underdetermined systems of linear equations, uniformly
                  distributed random projections, phase transitions},
  abstract =     {Let $A$ be a $d \times n$ matrix and $T = T^{n-1}$ be the
                  standard simplex in $R^n$. Suppose that $d$ and $n$ are both
                  large and comparable: $d \approx \delta n$, $\delta \in
                  (0,1)$. We count the faces of the projected simplex $AT$ when
                  the projector $A$ is chosen uniformly at random from the
                  Grassmann manifold of $d$-dimensional orthoprojectors of
                  $R^n$. We derive $\rho_N(\delta)> 0$ with the property that,
                  for any $\rho < \rho_N(\delta)$, with overwhelming probability
                  for large $d$, the number of $k$-dimensional faces of $P = AT$
                  is exactly the same as for $T$, for $0 \leq k \leq \rho d$.
                  This implies that $P$ is $\lfloor\rho d\rfloor$-neighborly,
                  and its skeleton $\mathrm{Skel}_{\lfloor\rho d\rfloor}(P)$ is
                  combinatorially equivalent to $\mathrm{Skel}_{\lfloor\rho
                  d\rfloor}(T)$. We also study a weaker notion of neighborliness
                  where the numbers of $k$-dimensional faces $f_k(P) \geq
                  f_k(T)(1-\varepsilon)$. Vershik and Sporyshev previously
                  showed existence of a threshold $\rho_{VS}(\delta) > 0$ at
                  which phase transition occurs in $k/d$. We compute and display
                  $\rho_{VS}$ and compare with $\rho_N$. Corollaries are as
                  follows. (1) The convex hull of $n$ Gaussian samples in $R^d$,
                  with $n$ large and proportional to $d$, has the same
                  $k$-skeleton as the $(n - 1)$ simplex, for $k < \rho_N
                  (d/n)d(1 + o_P(1))$. (2) There is a ``phase transition'' in
                  the ability of linear programming to find the sparsest
                  nonnegative solution to systems of underdetermined linear
                  equations. For most systems having a solution with fewer than
                  $\rho_{VS}(d/n)d(1+o(1))$ nonzeros, linear programming will
                  find that solution.}
}

@Unpublished{	  donotsai:2006,
  author =       {David L. Donoho and Yaakov Tsaig},
  month =        {October},
  note =         {\url{http://www.stanford.edu/~tsaig/research.html}},
  title =        {Fast solution of {L1}-norm minimization problems when the
                  solution may be sparse},
  year =         2006
}

@Article{	  dost:1991,
  abstract =     {An upper bound for the difference of the exact solution of the
                  problem of minimization of a quadratic functional on the
                  subspace and its penalty approximation is given. The paper
                  supplies a numerical example.},
  author =       {Z. Dost\'{a}l},
  journal =      {Kybernetika},
  number =       2,
  pages =        {151--154},
  title =        {On the penalty approximation of quadratic programming problem},
  volume =       27,
  year =         1991
}

@Article{	  dost:1996,
  abstract =     {We review our recent results on the solution of quadratic
                  programming problems with simple bounds by means of the
                  conjugate gradient method with inexact solution of auxiliary
                  subproblems and projections. Precision of the solution of
                  auxiliary problems is controlled by the product of a positive
                  constant Gamma with the norm of violation of the Kuhn-Tucker
                  contact conditions. The resulting algorithm converges for any
                  positive Gamma and reaches the solution in a finite number of
                  steps provided the problem is nondegenerate. A lower bound on
                  Gamma is given so that the finite termination property is
                  preserved even for degenerate problems. The algorithm may be
                  implemented with projections so that it can drop and add many
                  constraints whenever the active set is changed. Applications
                  to the solution of inner obstacle problems and contact
                  problems of elasticity are reported.},
  author =       {Z. Dost\'{a}l},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      {Zeitschrift f\"{u}r Angewandte Mathematik und Mechanik},
  number =       {S3},
  pages =        {413--414},
  title =        {Box constrained quadratic programming with controlled
                  precision of auxiliary problems and applications},
  volume =       76,
  year =         1996
}

@Article{	  dost:1997,
  abstract =     {Two new closely related concepts are introduced that depend on
                  a positive constant Gamma . An iteration is proportional if
                  the norm of violation of the Kuhn-Tucker conditions at active
                  variables does not excessively exceed the norm of the part of
                  the gradient that corresponds to free variables, while a
                  progressive direction determines a descent direction that
                  enables the released variables to move far enough from the
                  boundary in a step called proportioning. An algorithm that
                  uses the conjugate gradient method to explore the face of the
                  region defined by the current iterate until a disproportional
                  iteration is generated is proposed. It then changes the face
                  by means of the progressive direction. It is proved that for
                  strictly convex problems, the proportioning is a spacer
                  iteration so that the algorithm converges to the solution. If
                  the solution is nondegenerate then the algorithm finds the
                  solution in a finite number of steps. Moreover, a simple lower
                  bound on Gamma is given to ensure finite termination even for
                  problems with degenerate solutions. The theory covers a class
                  of algorithms, allowing many constraints to be added or
                  dropped at a time and accepting approximate solutions of
                  auxiliary problems. Preliminary numerical results are
                  promising.},
  author =       {Z. Dost\'{a}l},
  journal =      siamopt,
  number =       3,
  pages =        {871--887},
  title =        {Box constrained quadratic programming with proportioning and
                  projections},
  volume =       7,
  year =         1997
}

@InProceedings{	  dostfriesant:1998,
  address =      {Dordrecht, The Netherlands},
  author =       {Z. Dost\'{a}l and A. Friedlander and S. A. Santos},
  booktitle =    {High Performance Algorithms and Software in Nonlinear
                  Optimization},
  date-modified ={2007-07-18 14:59:31 -0700},
  editor =       {R. De Leone and A. Murli and P. M. Pardalos and G. Toraldo},
  pages =        {161--173},
  publisher =    {Kluwer Academic},
  title =        {Adaptive precision control in quadratic programming with
                  simple bounds and/or equality constraints},
  year =         1998
}

@Article{	  dostfriesant:1999,
  abstract =     {In this paper we introduce an augmented Lagrangian type
                  algorithm for strictly convex quadratic programming problems
                  with equality constraints. The new feature of the proposed
                  algorithm is the adaptive precision control of the solution of
                  auxiliary problems in the inner loop of the basic algorithm.
                  Global convergence and boundedness of the penalty parameter
                  are proved and an error estimate is given that does not have
                  any term that accounts for the inexact solution of the
                  auxiliary problems. Numerical experiments illustrate
                  efficiency of the algorithm presented.},
  author =       {Z. Dost\'{a}l and A. Friedlander and S. A. Santos},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      compapplopt,
  local-url =    {file://localhost/Users/mpf/papers/DostFrieSant99.pdf},
  number =       1,
  pages =        {37--53},
  title =        {Augmented {L}agrangians with adaptive precision control for
                  quadratic programming with equality constraints},
  volume =       14,
  year =         1999
}

@Article{	  dostfriesant:2003,
  author =       {Z. Dost\'{a}l and A. Friedlander and S. A. Santos},
  journal =      siamopt,
  local-url =    {file://localhost/Users/mpf/papers/DostFrieSant03.pdf},
  number =       4,
  pages =        {1120--1140},
  title =        {Augmented {L}agrangians with adaptive precision control for
                  quadratic programming with simple bounds and equality
                  constraints},
  volume =       13,
  year =         2003
}

@Article{	  dot05,
  abstract =     {Consider an underdetermined system of linear equations y = Ax
                  with known y and d x n matrix A. We seek the nonnegative x
                  with the fewest nonzeros satisfying y = Ax. In general, this
                  problem is NP-hard. However, for many matrices A there is a
                  threshold phenomenon: if the sparsest solution is sufficiently
                  sparse, it can be found by linear programming. We explain this
                  by the theory of convex polytopes. Let aj denote the jth
                  column of A, 1 [&le;] j [&le;] n, let a0 = 0 and P denote the
                  convex hull of the aj. We say the polytope P is outwardly
                  k-neighborly if every subset of k vertices not including 0
                  spans a face of P. We show that outward k-neighborliness is
                  equivalent to the statement that, whenever y = Ax has a
                  nonnegative solution with at most k nonzeros, it is the
                  nonnegative solution to y = Ax having minimal sum. We also
                  consider weak neighborliness, where the overwhelming majority
                  of k-sets of ajs not containing 0 span a face of P. This
                  implies that most nonnegative vectors x with k nonzeros are
                  uniquely recoverable from y = Ax by linear programming.
                  Numerous corollaries follow by invoking neighborliness
                  results. For example, for most large n by 2n underdetermined
                  systems having a solution with fewer nonzeros than roughly
                  half the number of equations, the sparsest solution can be
                  found by linear programming. },
  author =       {D. L. Donoho and J. Tanner},
  date-modified ={2007-07-18 14:59:34 -0700},
  eprint =       {http://www.pnas.org/cgi/reprint/102/27/9446.pdf},
  journal =      procnas,
  number =       27,
  pages =        {9446-9451},
  title =        {Sparse nonnegative solution of underdetermined linear
                  equations by linear programming},
  url =          {http://www.pnas.org/cgi/content/abstract/102/27/9446},
  volume =       102,
  year =         2005
}

@InProceedings{	  dpe01,
  author =       "Doherty, L. and Pister, K. S. J. and El Ghaoui, L.",
  title =        "Convex position estimation in wireless sensor networks",
  year =         2001,
  booktitle =    "20th INFOCOM",
  volume =       3,
  page =         {1655--1663}
}

@Article{	  drud:1994,
  author =       {A. S. Drud},
  journal =      {{ORSA} J. Computing},
  pages =        {207--216},
  title =        {A large scale {GRG} code},
  volume =       6,
  year =         1994
}

@article{drusvyatskiy2014noisy,
  title =        {Noisy Euclidean distance realization: robust facial reduction
                  and the Pareto frontier},
  author =       {Drusvyatskiy, Dmitriy and Krislock, Nathan and Voronin,
                  Yuen-Lam and Wolkowicz, Henry},
  journal =      {arXiv preprint arXiv:1410.6852},
  year =         2014
}

@Misc{		  dst07,
  author =       {David L. Donoho and V. C. Stodden and Yaakov Tsaig},
  howpublished = {\url{http://sparselab.stanford.edu/}},
  title =        {Sparselab},
  year =         2007
}

@article{donoho2012sparse,
  title={Sparse solution of underdetermined systems of linear equations by stagewise orthogonal matching pursuit},
  author={Donoho, David L and Tsaig, Yaakov and Drori, Iddo and Starck, Jean-Luc},
  journal=ieeetransinfo,
  volume={58},
  number={2},
  pages={1094--1121},
  year={2012},
  publisher={IEEE}
}

@Article{	  duange:2006,
  author =       {P.-C Du and Ruth H. Angeletti},
  title =        {Automatic deconvolution of isotope-resolved mass spectra using
                  variable selection and quantized peptide mass distribution},
  journal =      {Analytical Chemistry},
  volume =       78,
  number =       10,
  month =        {May},
  year =         2006,
  pages =        {3385--3392}
}

@article{duchi2012dual,
  title =        {Dual averaging for distributed optimization: Convergence
                  analysis and network scaling},
  author =       {Duchi, John C and Agarwal, Alekh and Wainwright, Martin J},
  journal =      ieeetransac,
  volume =       57,
  number =       3,
  pages =        {592--606},
  year =         2012,
  publisher =    {IEEE}
}

@InProceedings{	  duchshalsingchan:2008,
  author =       {J. Duchi and S. Shalev-Shwartz and Y. Singer and T. Chandra},
  title =        {Efficient projections onto the $\ell_1$-ball for learning in
                  high dimensions},
  booktitle =    {Proceedings of the 25th International Conference on Machine
                  Learning},
  year =         2008,
  pages =        {272--279}
}

@Article{	  duff:2004,
  author =       {Iain S. Duff},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      acmmathsoft,
  number =       2,
  pages =        {118--144},
  title =        {{MA57}---a code for the solution of sparse symmetric definite
                  and indefinite systems},
  volume =       30,
  year =         2004
}

@article{dunn1978conditional,
  title =        {Conditional gradient algorithms with open loop step size
                  rules},
  author =       {Dunn, Joseph C and Harshbarger, S},
  journal =      jmaa,
  volume =       62,
  number =       2,
  pages =        {432--444},
  year =         1978,
  publisher =    {Elsevier}
}

@InCollection{	  dunn:1994,
  author =       {J. C. Dunn},
  booktitle =    {Large Scale Optimization: State of the Art},
  date-added =   {2007-07-04 23:43:57 -0700},
  date-modified ={2007-07-18 14:59:32 -0700},
  editor =       {W. W. Hager, D. W. Hearn, and P. M. Pardalos},
  pages =        {95-114},
  publisher =    {Kluwer},
  title =        {Gradient-Related Constrained Minimization Algorithms in
                  Function Spaces: Convergence Properties and Computational
                  Implications},
  year =         1994
}

@Article{	  eck93,
  author =       "Jonathan Eckstein",
  title =        "Nonlinear Proximal Point Algorithms Using {Bregman} Functions,
                  with Applications to Convex Programming",
  journal =      mathofor,
  year =         1993,
  volume =       18,
  number =       1,
  page =         {202--226}
}

@Article{	  efrohastjohntibs:2004,
  author =       {B. Efron and T. Hastie and I. Johnstone and R. Tibshirani},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      {Ann. Statist.},
  local-url =    {file://localhost/Users/mpf/papers/EfroHastJohnTibs04.pdf},
  number =       2,
  pages =        {407-499},
  title =        {Least angle regression},
  volume =       32,
  year =         2004
}

@InProceedings{	  egwymab04,
  author =       "Eren, T. and Goldenberg, D. K. and Whiteley, W. and Yang, Y.
                  R. and Morse, A. S. and Anderson, B. D. O. and Belhumeur,
                  P.N.",
  title =        "Rigidity, computation, and randomization in network
                  localization",
  year =         2004,
  booktitle =    "23rd INFOCOM",
  volume =       4,
  page =         {2673--2684}
}

@Article{	  el--tapit.tsy.zh:1996,
  author =       {A.~S. {El--Bakry} and R.~A. Tapia and T.~Tsuchiya and
                  Y.~Zhang},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      {Journal of Optimization Theory and Applications},
  month =        {June},
  pages =        {507--541},
  part =         3,
  title =        {On the formulation and theory of {Newton} interior-point
                  method for nonlinear programming},
  volume =       89,
  year =         1996
}

@Article{	  eladmilarubi:2007,
  author =       {M. Elad and P. Milanfar and R. Rubinstein},
  title =        {Analysis Versus Synthesis in Signal Priors},
  journal =      {Inverse Probl.},
  volume =       23,
  number =       3,
  pages =        {947-968},
  month =        {June},
  year =         2007
}

@Article{	  eldamish:2008,
  author =       {Yonina C. Eldar and Moshe Mishali},
  title =        {Robust Recovery of Signals From a Union of Subspaces},
  journal =      ieeetransinfo,
  doi =          {10.1109/TIT.2009.2030471 },
  volume =       55,
  year =         2009,
  abstract =     {Traditional sampling theories consider the problem of
                  reconstructing an unknown signal x from a series of samples. A
                  prevalent assumption which often guarantees recovery from the
                  given measurements is that x lies in a known subspace.
                  Recently, there has been growing interest in nonlinear but
                  structured signal models, in which x lies in a union of
                  subspaces. In this paper, we develop a general framework for
                  robust and efficient recovery of such signals from a given set
                  of samples. More specifically, we treat the case in which x
                  lies in a sum of k subspaces, chosen from a larger set of m
                  possibilities. The samples are modeled as inner products with
                  an arbitrary set of sampling functions. To derive an efficient
                  and robust recovery algorithm, we show that our problem can be
                  formulated as that of recovering a block-sparse vector whose
                  nonzero elements appear in fixed blocks. We then propose a
                  mixed lscr2/lscr1 program for block sparse recovery. Our main
                  result is an equivalence condition under which the proposed
                  convex algorithm is guaranteed to recover the original signal.
                  This result relies on the notion of block restricted isometry
                  property (RIP), which is a generalization of the standard RIP
                  used extensively in the context of compressed sensing. Based
                  on RIP, we also prove stability of our approach in the
                  presence of noise and modeling errors. A special case of our
                  framework is that of recovering multiple measurement vectors
                  (MMV) that share a joint sparsity pattern. Adapting our
                  results to this context leads to new MMV recovery methods as
                  well as equivalence conditions under which the entire set can
                  be determined efficiently. }
}

@Article{	  eldamish:2009,
  author =       {Yonina C. Eldar and Moshe Mishali},
  title =        {Robust Recovery of Signals From a Union of Subspaces},
  year =         2009,
  doi =          {10.1109/TIT.2009.2030471},
  volume =       55,
  journal =      ieeetransinfo,
  pages =        {5302-5316}
}

@Article{	  elde:1990,
  abstract =     {We study a linear, discrete ill-posed problem, by which we
                  mean a very ill-conditioned linear least squares problem. In
                  particular we consider the case when one is primarily
                  interested in computing a functional defined on the solution
                  rather than the solution itself. In order to alleviate the
                  ill-conditioning we require the norm of the solution to be
                  smaller than a given constant. Thus we are lead to minimizing
                  a linear functional subject to two quadratic constraints. We
                  study existence and uniqueness for this problem and show that
                  it is essentially equivalent to a least squares problem with a
                  linear and a quadratic constraint, which is easier to handle
                  computationally. Efficient algorithms are suggested for this
                  problem. },
  address =      {Lawrence, KS, USA},
  author =       {Lars Eld\'{e}n},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      bit,
  keywords =     {ill-posed, least squares, constraint, functional, algorithm},
  number =       3,
  pages =        {466--483},
  publisher =    {BIT Computer Science and Numerical Mathematics},
  title =        {Algorithms for the Computation of functionals defined on the
                  solution of a discrete ill-posed problem},
  volume =       30,
  year =         1990
}

@Article{	  eldehansroja:2005,
  abstract =     {The minimization of linear functionals defined on the
                  solutions of discrete ill-posed problems arises, e.g., in the
                  computation of confidence intervals for these solutions. In
                  1990, Eld\'{e}n proposed an algorithm for this minimization
                  problem based on a parametric programming reformulation
                  involving the solution of a sequence of trust-region problems,
                  and using matrix factorizations. In this paper, we describe
                  MLFIP, a largescale version of this algorithm where a
                  limited-memory trust-region solver is used on the subproblems.
                  We illustrate the use of our algorithm in connection with an
                  inverse heat conduction problem. },
  author =       {Lars Eld\'{e}n and Per Christian Hansen and Marielba Rojas},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      bit,
  keywords =     {Discrete ill-posed problems, confidence intervals, large-scale
                  algorithms, trust regions},
  number =       2,
  pages =        {329--340},
  title =        {Minimization of linear functionals defined on solutions of
                  large-scale discrete-ill posed problems},
  volume =       45,
  year =         2005
}

@Article{	  erwaymarcia:2011,
  title =        {A backward stability analysis of diagonal pivoting methods for
                  solving unsymmetric tridiagonal systems without interchanges},
  author =       {Erway, J.B. and Marcia, R.F.},
  journal =      {Numerical Linear Algebra with Applications},
  volume =       18,
  number =       1,
  pages =        {41--54},
  year =         2011,
  publisher =    {Wiley Online Library}
}

@Article{	  erwaymarcia:2012,
  title =        {Limited-memory {BFGS} systems with diagonal updates},
  author =       {Erway, J.B. and Marcia, R.F.},
  journal =      {Linear Algebra and its Applications},
  year =         2012,
  pages =        {333--334},
  publisher =    {Elsevier}
}

@PhDThesis{	  esser:2010,
  author =       {John Ernest Esser},
  title =        {Primal Dual Algorithms for Convex Models and Applications to
                  Image Restoration, Registration and Nonlocal Inpainting},
  school =       {University of California, Los Angeles},
  year =         2010
}

@InProceedings{	  evp04,
  author =       "Evgeniou, T. and Pontil, M.",
  title =        "Regularized multi-task learning",
  year =         2004,
  booktitle =    "10th ACM SIGKDD international conference on Knowledge
                  discovery and data mining",
  page =         {109--117}
}

@Book{		  fap03,
  author =       "Facchinei, F. and Pang, J.-S.",
  title =        "Finite-Dimensional Variational Inequalities and
                  Complementarity Problems",
  volume =       "I and II",
  publisher =    "Springer",
  year =         2003,
  address =      "New York"
}

@PhDThesis{	  fazel:2002,
  title =        {{Matrix rank minimization with applications}},
  author =       {Fazel, M.},
  school =       {Elec. Eng. Dept, Stanford University},
  year =         2002
}

@Article{	  fem91,
  author =       {Ferris, M. C. and Mangasarian, O. L.},
  journal =      {Appl. Math. Optim.},
  number =       3,
  pages =        {263--273},
  title =        {Finite perturbation of convex programs},
  volume =       23,
  year =         1991
}

@Article{	  fem94,
  author =       "Ferris, M. C. and Mangasarian, O. L.",
  title =        "Parallel variable distribution",
  journal =      siamopt,
  year =         1994,
  volume =       4,
  page =         {815--832}
}

@Article{	  fep97,
  author =       {M. C. Ferris and J. S. Pang},
  journal =      siamreview,
  number =       4,
  pages =        {669-713},
  title =        {Engineering and Economic Applications of Complementarity
                  Problems},
  volume =       39,
  year =         1997
}

@article{ferreau2014qpoases,
  title =        {{qpOASES}: A parametric active-set algorithm for quadratic
                  programming},
  author =       {Ferreau, Hans Joachim and Kirches, Christian and Potschka,
                  Andreas and Bock, Hans Georg and Diehl, Moritz},
  journal =      mathprogc,
  volume =       6,
  number =       4,
  pages =        {327--363},
  year =         2014,
  publisher =    {Springer}
}

@Article{	  fesssutt:2003,
  author =       {Jeffrey A. Fessler and Bradley P. Sutton},
  date-modified ={2007-09-18 22:12:17 -0700},
  journal =      {{IEEE} Trans. Sig. Proc.},
  number =       2,
  pages =        {560-574},
  title =        {Nonuniform fast Fourier transforms using min-max
                  interpolation},
  url =          {\url{http://www.dsp.rice.edu/software/rwt.shtml}},
  volume =       51,
  year =         2003
}

@Misc{		  fevo:2007,
  author =       {C. F\'{e}votte},
  date-added =   {2007-09-18 21:01:54 -0700},
  date-modified ={2007-09-18 21:01:54 -0700},
  title =        {{Audio Source Separation Demo Webpage}},
  url =          {http://www.tsi.enst.fr/~fevotte/bass_demo.html},
  year =         2007
}

@InProceedings{	  fhb01,
  author =       "Fazel, M. and Hindi, H. and Boyd, S. P.",
  title =        "A Rank Minimization Heuristic with Application to Minimum
                  Order System Approximation",
  year =         2001,
  address =      "Arlington",
  booktitle =    "American Control Conference",
  page =         {4734--4739}
}

@Article{	  fhht07,
  author =       {Friedman, J. and Hastie, T. and H\"{o}fling, H. and
                  Tihshirani, R.},
  title =        "Pathwise coordinate optimization",
  journal =      "Ann. Appl. Stat.",
  year =         2007,
  volume =       1,
  page =         {302--332}
}

@Article{	  fht07,
  author =       "Friedman, J. and Hastie, T. and Tibshirani, R.",
  title =        "Sparse inverse covariance estimation with the graphical lasso",
  journal =      "Biostatistics",
  year =         2007,
  page =         {1--10}
}

@TechReport{	  fht08,
  author =       "Friedman, J. and Hastie, T. and Tihshirani, R.",
  title =        "Regularization paths for generalized linear models via
                  coordinate descent",
  institution =  "Department of Statistics, Stanford University, Stanford",
  type =         {Report},
  year =         2008,
  month =        "July"
}

@Article{	  fiacliu:1993,
  author =       {Anthony V. Fiacco and Jiming Liu},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      {Ann. Oper. Res.},
  pages =        {61-80},
  title =        {Degeneracy in {NLP} and the Development of Results Motivated
                  by its Presence},
  volume =       46,
  year =         1993
}

@Book{		  fiacmcco:1968,
  address =      {New York},
  author =       {Anthony V. Fiacco and Garth P. McCormick},
  date-modified ={2007-07-18 14:59:33 -0700},
  publisher =    {Wiley},
  title =        {Nonlinear Programming: Sequential Unconstrained Minimization
                  Techniques},
  year =         1968
}

@Article{	  fignow:2003,
  author =       {M\'ario A. T. Figueiredo and Robert D. Nowak},
  title =        {An {EM} algorithm for wavelet-based image restoration},
  journal =      ieeetransimproc,
  year =         2003,
  volume =       12,
  number =       8,
  pages =        {906-916},
  month =        {August}
}

@Article{	  figunowawrig:2007,
  title =        {{Gradient Projection for Sparse Reconstruction: Application to
                  Compressed Sensing and Other Inverse Problems}},
  author =       {Figueiredo, M. and Nowak, R. and Wright, S. J.},
  journal =      {Sel. Top. in Signal Process., IEEE J.},
  volume =       1,
  number =       4,
  pages =        {586--597},
  year =         2007
}

@InProceedings{	  fle94,
  author =       "Fletcher, R.",
  title =        "An overview of unconstrained optimization",
  booktitle =    "Algorithms for Continuous Optimization",
  editor =       "E. Spedicato",
  organization = "Kluwer Academic",
  address =      "Dordrecht",
  year =         1994,
  page =         {109--143}
}

@Article{	  flet:1971,
  abstract =     {An effective algorithm is presented for quadratic programming
                  which is of general applicability, but which is not dependent
                  upon the availability of a linear programming code for its
                  implementation. It is an algorithm of exchange type, the
                  exchanges being chosen so as to avoid the accumulation of
                  error to as large an extent as possible.},
  author =       {R. Fletcher},
  journal =      {J. Institute Math. Appl.},
  pages =        {76--91},
  title =        {A general quadratic programming algorithm},
  volume =       7,
  year =         1971
}

@InCollection{	  flet:1974,
  address =      {London},
  author =       {R. Fletcher},
  booktitle =    {Numerical Methods for Constrained Optimization},
  date-modified ={2007-07-18 14:59:33 -0700},
  editor =       {P. E. Gill and W. Murray},
  pages =        {219--239},
  publisher =    academic,
  title =        {Methods Related to Lagrangian Functions},
  year =         1974
}

@InProceedings{	  flet:1985,
  address =      {Philadelphia},
  author =       {R. Fletcher},
  booktitle =    {Numerical Optimization. 1984},
  editor =       {P. T. Boggs and R. H. Byrd and R. B. Schnabel},
  pages =        {26-40},
  publisher =    siampub,
  title =        {An $\ell_1$ penalty method for nonlinear constraints},
  year =         1985
}

@Book{		  flet:1987,
  address =      {Chichester, UK},
  author =       {R. Fletcher},
  date-modified ={2007-11-09 15:14:02 -0800},
  edition =      {Second},
  publisher =    {Wiley},
  title =        {Practical Methods of Optimization},
  year =         1987
}

@InProceedings{	  flet:1987b,
  author =       {R. Fletcher},
  title =        {Recent developments in linear and quadratic programming},
  editor =       {Iserles, A. and Powell, M. J. D.},
  booktitle =    {State of the Art in Numerical Analysis. Proceedings of the
                  Joint IMA/SIAM Conference},
  publisher =    {Oxford University Press, Oxford, England},
  year =         1987,
  pages =        {213--243},
  abstract =     {Describes recent developments in linear programming, including
                  the ellipsoid algorithm, the Karmarkar algorithm, new
                  strategies for updating LU factors in the simplex method, and
                  methods with guaranteed termination in the presence of
                  degeneracy and round-off errors. Various new algorithms for
                  quadratic programming are discussed, and the choice of matrix
                  factorizations and their updates is considered. The use of
                  $\ell_1$ penalty functions in linear and quadratic programming
                  is also mentioned briefly.}
}

@TechReport{	  flet:1991,
  address =      {Dundee, Scotland},
  author =       {R. Fletcher},
  date-modified ={2007-07-18 14:59:34 -0700},
  institution =  {University of Dundee},
  number =       {NA-135},
  title =        {Resolving degeneracy in quadratic programming},
  year =         1991
}

@Article{	  flet:1993,
  abstract =     {A technique for the resolution of degeneracy in an active set
                  method for quadratic programming is described. The approach
                  generalises Fletcher's method (1988) which applies to the LP
                  case. The method is described in terms of a linear
                  complementarity problem tableau, which is seen to provide
                  useful insights. It is shown that the degeneracy procedure
                  only needs to operate when the degenerate constraints are
                  linearly dependent on those in the active set. No significant
                  overheads are incurred by the degeneracy procedure. It is
                  readily implemented in a null space format, and no
                  complications in the matrix algebra are introduced. The
                  guarantees of termination provided by Fletcher's method,
                  extending in particular to the case where round-off error is
                  present, are preserved in the QP case. It is argued that the
                  technique gives stronger guarantees than are available with
                  other popular methods such as Wolfe's method (1963) or the
                  method of Goldfarb and Idnani (1983).},
  author =       {R. Fletcher},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      {Ann. Oper. Res.},
  number =       {1--4},
  pages =        {307--334},
  title =        {Resolving degeneracy in quadratic programming},
  volume =       {46--47},
  year =         1993
}

@InCollection{	  fletcher:1970,
  author =       {R. Fletcher},
  title =        {A class of methods for nonlinear programming with termination
                  and convergence properties},
  booktitle =    {Integer and nonlinear programming},
  editors =      {J. Abadie},
  publisher =    {North-Holland},
  address =      {Amsterdam},
  pages =        {157--173},
  year =         1970
}

@InCollection{	  fletcher:1973,
  author =       {R. Fletcher},
  title =        {A Class of Methods for Non-Linear Programming {III}: Rates of
                  Convergence},
  booktitle =    {Numerical Methods for Nonlinear Optimization},
  editors =      {F. A. Lootsma},
  publisher =    {Academic Press},
  address =      {NY},
  pages =        {371--393},
  year =         1973
}

@Article{	  fletcher:1973b,
  author =       {R. Fletcher},
  title =        {An exact penalty function for nonlinear programming with
                  inequalities},
  journal =      mathprog,
  year =         1973,
  volume =       5,
  pages =        {129--150}
}

@InCollection{	  fletcher:1975,
  author =       {R. Fletcher},
  title =        {An ideal penalty function for constrained optimization},
  booktitle =    {Nonlinear Prog.},
  pages =        {121-163},
  publisher =    {Academic Press},
  year =         1975,
  editor =       {O. Mangasarian and R. Meyer and S. Robinson},
  volume =       2
}

@TechReport{	  fletleyf:1997,
  address =      {Scotland},
  author =       {R. Fletcher and S. Leyffer},
  date-modified ={2007-07-18 14:59:33 -0700},
  institution =  {Dept. of Mathematics, University of Dundee},
  number =       {Numerical Analysis Report NA/171},
  title =        {Nonlinear programming without a penalty function},
  year =         1997
}

@TechReport{	  fletleyf:1998,
  author =       {R. Fletcher and S. Leyffer},
  institution =  {University of Dundee},
  month =        {March},
  number =       {NA-181},
  title =        {User manual for {FilterSQP}},
  year =         1999
}

@TechReport{	  fletleyf:2002,
  author =       {R. Fletcher and S. Leyffer},
  date-modified ={2007-07-18 14:59:33 -0700},
  institution =  {University of Dundee},
  month =        {August},
  number =       {NA-210},
  title =        {Numerical experience with solving {MPECs} as {NLPs}},
  year =         2002
}

@Article{	  fletleyf:2002a,
  abstract =     {In this paper the solution of nonlinear programming problems
                  by a Sequential Quadratic Programming (SQP) trust--region
                  algorithm is considered. The aim of the present work is to
                  promote global convergence without the need to use a penalty
                  function. Instead, a new concept of a ``filter'' is introduced
                  which allows a step to be accepted if it reduces either the
                  objective function or the constraint violation function.
                  Numerical tests on a wide range of test problems are very
                  encouraging and the new algorithm compares favourably with
                  LANCELOT and an implementation of S$l_1$QP.},
  author =       {R. Fletcher and S. Leyffer},
  journal =      mathprog,
  month =        {January},
  number =       2,
  pages =        {239--269},
  summary =      {A Sequential Quadratic Programming (SQP) trust-region
                  algorithm for nonlinear programming is considered, which is
                  globally convergent without the need to use a penalty
                  function. Instead, the concept of a ``filter'' is introduced
                  which allows a step to be accepted if it reduces either the
                  objective function or the constraint violation function.
                  Numerical tests on a wide range of test problems are very
                  encouraging and the new algorithm compares favourably with
                  {\sf LANCELOT} and an implementation of S$l_1$QP.},
  title =        {Nonlinear programming without a penalty function},
  volume =       91,
  year =         2002
}

@TechReport{	  fletleyfralpscho:2002,
  author =       {R. Fletcher and S. Leyffer and Danny Ralph and Stefan
                  Scholtes},
  date-modified ={2007-07-18 14:59:33 -0700},
  institution =  {University of Dundee},
  month =        {May},
  number =       {NA-209},
  title =        {Local convergence of {SQP} methods for Mathematical Programs
                  with Equilibrium Constraints},
  year =         2002
}

@TechReport{	  fletleyftoin:1998,
  address =      {Dundee DD1 4HN, Scotland, UK},
  author =       {R. Fletcher and S. Leyffer and \mbox{Ph}. Toint},
  date-modified ={2007-07-18 14:59:33 -0700},
  institution =  {Department of Mathematics, University of Dundee},
  month =        {August},
  note =         {Revised October 1999},
  number =       {NA/183},
  title =        {On the global convergence of an {SLP}-filter algorithm},
  type =         {Numerical Analysis Report},
  year =         1998
}

@Article{	  fletleyftoin:2002,
  author =       {R. Fletcher and S. Leyffer and Ph. Toint},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      siamopt,
  number =       13,
  pages =        {44--59},
  title =        {On the Global Convergence of a Filter-{SQP} Algorithm},
  year =         2002
}

@Article{	  fletmaza:1989,
  author =       {R. Fletcher and E. \mbox{Sainz} de la Maza},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprog,
  number =       3,
  pages =        {235--256},
  title =        {Nonlinear programming and non-smooth optimization by succssive
                  linear programming},
  volume =       43,
  year =         1989
}

@TechReport{	  flieheermolz:2006,
  author =       {J. Fliege and C. Heermann and D. Molz},
  date-added =   {2007-10-12 18:17:53 -0700},
  date-modified ={2007-10-19 18:39:05 -0700},
  institution =  {School of Mathematics, Univ. of Birmingham},
  number =       {2006/34},
  title =        {An adaptive primal-dual warm-start technique for quadratic
                  multiobjective optimization},
  type =         {Tech. rep.},
  year =         2006
}

@Misc{		  fornrauh:2007,
  title =        {Recovery algorithms for vector valued data with joint sparsity
                  constraints},
  author =       {Fornasier, M. and Rauhut, H.},
  journal =      {Arxiv preprint math/0608124},
  year =         2006,
  note =         {To appear in {\it SIAM J. Numer. Anal.}}
}

@Article{	  fors:2002,
  author =       {Forsgren, Anders},
  coden =        {ANMAEL},
  date-modified ={2007-07-18 14:59:32 -0700},
  fjournal =     appnummath,
  journal =      {Appl. Numer. Math.},
  mrclass =      {90C55 (65F05 65K05 90C51)},
  mrnumber =     {MR1936104 (2003i:90120)},
  number =       {1-2},
  pages =        {91--107},
  title =        {Inertia-controlling factorizations for optimization
                  algorithms},
  volume =       43,
  year =         2002
}

@Article{	  forsgill:1998,
  author =       {A. Forsgren and P. E. Gill},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      siamopt,
  pages =        {1132--1152},
  title =        {Primal-dual interior methods for nonconvex nonlinear
                  programming},
  volume =       8,
  year =         1998
}

@Article{	  forsgillgrif:2007,
  author =       {A. Forsgren and P. E. Gill and J. D. Griffin},
  date-added =   {2007-10-13 12:06:04 -0700},
  date-modified ={2007-10-19 14:39:56 -0700},
  doi =          {10.1137/060650210},
  journal =      siamopt,
  keywords =     {large-scale nonlinear programming; nonconvex optimization;
                  interior methods; augmented systems; KKT systems; iterative
                  methods; conjugate-gradient method; constraint
                  preconditioning},
  number =       2,
  pages =        {666-690},
  publisher =    {SIAM},
  title =        {Iterative Solution of Augmented Systems Arising in Interior
                  Methods},
  url =          {http://link.aip.org/link/?SJE/18/666/1},
  volume =       18,
  year =         2007
}

@Article{	  forsgillmurr:1995,
  author =       {Anders Forsgren and P. E. Gill and W. Murray},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamscicomp,
  number =       1,
  pages =        {139--150},
  title =        {Computing Modified {Newton} Directions Using a Partial
                  {Cholesky} Factorization},
  volume =       16,
  year =         1995
}

@Article{	  forsgillwrig:2002,
  author =       {Anders Forsgren and P. E. Gill and Margaret H. Wright},
  date-modified ={2007-07-18 14:59:33 -0700},
  doi =          {10.1137/S0036144502414942},
  journal =      siamreview,
  keywords =     {nonlinear programming; constrained minimization; nonlinear
                  constraints; primal-dual methods; interior methods; penalty
                  methods; barrier methods},
  number =       4,
  pages =        {525-597},
  publisher =    {SIAM},
  title =        {Interior Methods for Nonlinear Optimization},
  url =          {http://link.aip.org/link/?SIR/44/525/1},
  volume =       44,
  year =         2002
}

@Book{		  foucart2013mathematical,
  title =        {A mathematical introduction to compressive sensing},
  author =       {Foucart, Simon and Rauhut, Holger},
  year =         2013,
  publisher =    {Springer}
}

@Article{	  fountoulakis2013second,
  title =        {A second-order method for strongly convex$\backslash$ ell
                  \_1-regularization problems},
  author =       {Fountoulakis, Kimon and Gondzio, Jacek},
  journal =      mathprog,
  pages =        {1--31},
  year =         2013,
  publisher =    {Springer}
}

@Book{		  fourgaykern:1993,
  address =      {San Francisco},
  author =       {R. Fourer and D. M. Gay and B. W. Kernighan},
  date-modified ={2007-07-18 14:59:32 -0700},
  publisher =    scientific,
  title =        {{AMPL}: A Modeling Language for Mathematical Programming},
  year =         1993
}

@Book{		  fourgaykern:2003,
  address =      {Pacific Grove, CA},
  author =       {R. Fourer and D. M. Gay and B. W. Kernighan},
  date-modified ={2007-07-18 14:59:32 -0700},
  edition =      {2nd},
  publisher =    {Duxbury/Brooks/Cole},
  title =        {{AMPL}: A Modeling Language for Mathematical Programming},
  year =         2003
}

@article{frank1956algorithm,
  title =        {An algorithm for quadratic programming},
  author =       {Frank, Marguerite and Wolfe, Philip},
  journal =      {Naval Research Logistics (NRL)},
  volume =       3,
  number =       {1-2},
  pages =        {95--110},
  year =         1956,
  publisher =    {Wiley Online Library}
}

@Article{	  freund1987dual,
  author =       {Freund, Robert M.},
  title =        {Dual gauge programs, with applications to quadratic
                  programming and the minimum-norm problem},
  journal =      mathprog,
  volume =       38,
  year =         1987,
  number =       1,
  pages =        {47--67},
  mrclass =      {90C20 (65K05)},
  mrnumber =     {899008 (88k:90146)},
  mrreviewer =   {Kunio Oshima}
}

@article{freund1999short,
  title =        {A short introduction to boosting},
  author =       {Freund, Yoav and Schapire, Robert and Abe, Naoki},
  journal =      {J. Jpn. Soc. Artif. Intell.},
  volume =       14,
  number =       {771-780},
  pages =        1612,
  year =         1999,
  publisher =    {JAPANESE SOC ARTIFICIAL INTELL}
}

@Article{	  friemart:1994,
  author =       {A. Friedlander and J. M. Mart\'{\i}nez},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      siamopt,
  number =       1,
  pages =        {177--192},
  title =        {On the Maximization of a Concave Quadratic Function with Box
                  Constraints},
  volume =       4,
  year =         1994
}

@Article{	  fuc04,
  author =       {Jean-Jacques Fuchs},
  journal =      ieeetransinfo,
  month =        {June},
  number =       6,
  pages =        {1341--1344},
  title =        {On Sparse Representations in Arbitrary Redundant Bases},
  url =          {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1302316},
  volume =       50,
  year =         2004
}

@Article{	  fuc05,
  author =       {Jean-Jacques Fuchs},
  title =        "Recovery of exact sparse representations in the presence of
                  bounded noise",
  journal =      ieeetransinfo,
  year =         2005,
  volume =       51,
  page =         {3601--3608}
}

@Article{	  fuk98,
  author =       "Fukushima, M.",
  title =        "Parallel variable transformation in unconstrained
                  optimization",
  journal =      siamopt,
  year =         1998,
  volume =       8,
  page =         {658--672}
}

@InProceedings{	  fukupang:1999,
  address =      {Berlin, Heidelberg, and New York},
  author =       {M. Fukushima and J. S. Pang},
  booktitle =    {Ill-Posed Variational Problems and Regularization Techniques},
  date-modified ={2007-07-18 14:59:32 -0700},
  editor =       {M. Thera and R. Tichatschke},
  pages =        {99-110},
  publisher =    springer,
  title =        {Convergence of smoothing continuation method for mathematical
                  programs with complementarity constraints},
  year =         1999
}

@Article{	  fukutsen:2002,
  author =       {M. Fukushima and P. Tseng},
  journal =      siamopt,
  pages =        {724--739},
  title =        {An implementable active-set algorithm for computing a
                  {B}-stationary point of the mathematical program with linear
                  complementarity constraints},
  volume =       12,
  year =         2002
}

@Article{	  fum81,
  author =       "Fukushima, M. and Mine, H.",
  title =        "A generalized proximal point algorithm for certain non-convex
                  minimization problems",
  journal =      "International Journal of Systems Science",
  year =         1981,
  volume =       12,
  page =         {989--1000}
}

@article{gafni1984two,
  title =        {Two-metric projection methods for constrained optimization},
  author =       {Gafni, Eli M and Bertsekas, Dimitri P},
  journal =      siamcontrol,
  volume =       22,
  number =       6,
  pages =        {936--964},
  year =         1984,
  publisher =    {SIAM}
}

@inproceedings{garber2015faster,
  title =        {Faster Rates for the Frank-Wolfe Method over Strongly-Convex
                  Sets.},
  author =       {Garber, Dan and Hazan, Elad},
  booktitle =    {ICML},
  pages =        {541--549},
  year =         2015
}

@inproceedings{garber2016linear,
  title =        {Linear-memory and decomposition-invariant linearly convergent
                  conditional gradient algorithm for structured polytopes},
  author =       {Garber, Dan and Meshi, Ofer},
  booktitle =    {Advances in Neural Information Processing Systems},
  pages =        {1001--1009},
  year =         2016
}

@Article{	  garcrest:1981,
  author =       {U. Garc\'{\i}a-Palomares and A. Restuccia},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      mathprog,
  pages =        {290-300},
  title =        {A Global Quadratic Algorithm for Solving a System of Mixed
                  Equalities and Inequalities},
  volume =       21,
  year =         1981
}

@Article{	  garcrest:1983,
  author =       {U. Garc\'{\i}a-Palomares and A. Restuccia},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      jota,
  month =        {November},
  number =       3,
  pages =        {405-415},
  title =        {Application of the {A}rmijo stepsize rule to the solution of a
                  nonlinear system of equalities and inequalities},
  volume =       41,
  year =         1983
}

@MastersThesis{	  garr:2008,
  address =      {Vancouver},
  author =       {M. F. Garrido},
  month =        {August},
  school =       {Dept. Computer Science, University of British Columbia},
  title =        {An all-at-once approach for computing nonnegative tensor
                  factorizations},
  year =         2008
}

@InCollection{	  gay:1996,
  address =      {Philadelphia},
  author =       {David M. Gay},
  booktitle =    {Computational Differentiation: Techniques, Applications, and
                  Tools},
  date-modified ={2007-07-18 14:59:33 -0700},
  editor =       {M. Berz and C. Bischof and G. Corliss and A. Griewank},
  pages =        {173--184},
  publisher =    siampub,
  title =        {More {AD} of Nonlinear {AMPL} Models: Computing {H}essian
                  Information and Exploiting Partial Separability},
  year =         1996
}

@TechReport{	  gay:1997,
  address =      {Murray Hill, NJ},
  author =       {David M. Gay},
  date-modified ={2007-07-18 14:59:32 -0700},
  institution =  {Computing Sciences Research Center, Bell Laboratories},
  month =        {April},
  number =       {97-4-06},
  title =        {Hooking Your Solver to {AMPL}},
  year =         1997
}

@TechReport{	  ghmsw86,
  address =      {Stanford, CA},
  author =       {P.E. Gill and S.J. Hammarling and W.Murray and M.A. Saunders
                  and M.H. Wright},
  institution =  {Stanford University},
  number =       {SOL86-1},
  title =        {User's Guide for {LSSOL} ({Version} 1.0): {A} {Fortran}
                  package for constrained linear least-squares and convex
                  quadratic programming},
  year =         1986
}

@Article{	  gilbl89,
  author =       {Jean Charles Gilbert and Claude Lemar\`echal},
  title =        {Some numerical experiments with variable-storage
                  quasi-{Newton} algorithms},
  journal =      mathprog,
  year =         1989,
  number =       45,
  pages =        {407--435}
}

@Article{	  gillkroy:2004,
  author =       {P. E. Gill and Julia Kroyan},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      siamopt,
  number =       4,
  pages =        {1-20},
  title =        {Trust-search methods for unconstrained optimization},
  volume =       12,
  year =         2004
}

@Article{	  gillmurr:1974,
  author =       {P. E. Gill and W. Murray},
  journal =      mathprog,
  pages =        {311--350},
  title =        {Newton-type methods for unconstrained and linearly constrained
                  optimization},
  volume =       29,
  year =         1974
}

@InCollection{	  gillmurrpick:1977,
  address =      {Wilkinson House, Jordan Hill Road, Oxford, England},
  author =       {P. E. Gill and W. Murray and Susan M. Picken},
  booktitle =    {The {NAG} {Fortran} Library Manual {Mark 6}},
  chapter =      {E04},
  date-modified ={2007-07-18 14:59:32 -0700},
  editor =       {{Numerical Algorithms Group Limited}},
  note =         {Withdrawn March 13, 1988},
  pages =        {170--220},
  publisher =    {Numerical Algorithms Group Limited},
  title =        {{E04UAF}, {E04VAF}, {E04VBF}, {E04WAF}, constrained
                  optimization using sequential augmented {Lagrangian} methods},
  year =         1977
}

@Article{	  gillmurrponcsaun:1992,
  address =      {Philadelphia, PA, USA},
  author =       {P. E. Gill and W. Murray and D. B. Poncele\'{o}n and M. A.
                  Saunders},
  doi =          {http://dx.doi.org/10.1137/0613022},
  journal =      siammatrix,
  number =       1,
  pages =        {292--311},
  publisher =    {SIAM},
  title =        {Preconditioners for indefinite systems arising in
                  optimization},
  volume =       13,
  year =         1992
}

@TechReport{	  gillmurrsaun:1995,
  address =      {Stanford University, Stanford},
  author =       {P. E. Gill and W. Murray and M. A. Saunders},
  institution =  {Department of Operations Research},
  number =       {SOL 95-4},
  title =        {User's Guide for {QPOPT} 1.0: A {F}ortran package for
                  quadratic programming},
  type =         {Tech. rep.},
  year =         1995
}

@TechReport{	  gillmurrsaun:1997,
  address =      {Department of Operations Research, Stanford University,
                  Stanford, CA},
  author =       {P. E. Gill and W. Murray and M. A. Saunders},
  institution =  {Systems Optimization Laboratory},
  month =        {May},
  number =       {98-1},
  title =        {User's Guide for {SNOPT 5.3}: A {Fortran} Package for
                  Large-scale Nonlinear Programming},
  type =         {Tech. rep.},
  year =         1997
}

@TechReport{	  gillmurrsaun:1997a,
  address =      {University of California, San Diego},
  author =       {P. E. Gill and W. Murray and M. A. Saunders},
  date-modified ={2007-07-18 14:59:34 -0700},
  institution =  {Department of Mathematics},
  number =       {Report NA 97-4},
  title =        {User's Guide for {SQOPT} 5.3: a {F}ortran Package for
                  Large-Scale Linear and Quadratic Programming},
  type =         {Technical Report},
  year =         1997
}

@TechReport{	  gillmurrsaun:1997b,
  address =      {Department of Operations Research, Stanford University,
                  Stanford, CA},
  author =       {P. E. Gill and W. Murray and M. A. Saunders},
  date-modified ={2007-07-18 14:59:34 -0700},
  institution =  {Systems Optimization Laboratory, Stanford University},
  month =        {August},
  number =       {97-3},
  title =        {{SNOPT}: An {SQP} Algorithm for Large-Scale Constrained
                  Optimization},
  year =         1997
}

@Article{	  gillmurrsaun:2002,
  author =       {P. E. Gill and W. Murray and M. A. Saunders},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      siamopt,
  number =       4,
  pages =        {979--1006},
  title =        {{SNOPT}: An {SQP} algorithm for large-scale constrained
                  optimization},
  volume =       12,
  year =         2002
}

@Article{	  gillmurrsaun:2005,
  author =       {P. E. Gill and W. Murray and M. A. Saunders},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      siamreview,
  number =       1,
  pages =        {99--131},
  title =        {{SNOPT}: An {SQP} algorithm for large-scale constrained
                  optimization},
  volume =       47,
  year =         2005
}

@Article{	  gillmurrsaunwrig:1989,
  title =        {A practical anti-cycling procedure for linearly constrained
                  optimization},
  author =       {Gill, P.E. and Murray, W. and Saunders, M.A. and Wright, M.H.},
  journal =      mathprog,
  volume =       45,
  number =       1,
  pages =        {437--474},
  year =         1989
}

@InProceedings{	  gillmurrsaunwrig:1990,
  author =       {P. E. Gill and W. Murray and M. A. Saunders and Margaret H.
                  Wright},
  booktitle =    {Reliable Numerical Computation},
  date-modified ={2007-07-18 14:59:31 -0700},
  editor =       {M. G. Cox and S. J. Hammarling},
  pages =        {113--138},
  publisher =    oxfordpress,
  title =        {A {Schur}-Complement Method for Sparse Quadratic Programming},
  year =         1990
}

@Article{	  gillmurrsaunwrig:1991,
  abstract =     {Active-set quadratic programming (QP) methods use a working
                  set to define the search direction and multiplier estimates.
                  In the method proposed by Fletcher in 1971, and in several
                  subsequent mathematically equivalent methods, the working set
                  is chosen to control the inertia of the reduced Hessian, which
                  is never permitted to have more than one nonpositive
                  eigenvalue. (Such methods will be called inertia-controlling.)
                  This paper presents an overview of a generic
                  inertia-controlling QP method, including the equations
                  satisfied by the search direction when the reduced Hessian is
                  positive definite, singular and indefinite. Recurrence
                  relations are derived that define the search direction and
                  Lagrange multiplier vector through equations related to the
                  Karush-Kuhn-Tucker system. Discussion is included of
                  connections with inertia-controlling methods that maintain an
                  explicit factorization of the reduced Hessian matrix.},
  author =       {P. E. Gill and W. Murray and M. A. Saunders and M. H. Wright},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamreview,
  number =       1,
  pages =        {1--36},
  title =        {Inertia-controlling methods for general quadratic programming},
  volume =       33,
  year =         1991
}

@InCollection{	  gillmurrsaunwrig:1992,
  author =       {P. E. Gill and W. Murray and M. A. Saunders and Margaret H.
                  Wright},
  booktitle =    {Advances in Optimization and Parallel Computing},
  editor =       {P. M. Pardalos},
  pages =        {101-128},
  publisher =    {Elsevier},
  title =        {Some Theoreical Properties of an augmented {L}agrangian Merit
                  Function},
  year =         1992
}

@Book{		  gillmurrwrig:1981,
  address =      {London},
  author =       {P. E. Gill and W. Murray and Margaret H. Wright},
  date-modified ={2007-07-18 14:59:33 -0700},
  pages =        {xvi+401},
  publisher =    academic,
  title =        {Practical Optimization},
  year =         1981
}

@Article{	  gillsaunshin:1996,
  author =       {P. E. Gill and M. A. Saunders and Joseph R. Shinnerl},
  date-modified ={2007-09-06 10:22:11 -0700},
  journal =      siammatrix,
  local-url =    {file://localhost/Users/mpf/papers/GillSaunShinn96.pdf},
  month =        {January},
  number =       1,
  pages =        {35--46},
  title =        {On the stability of {C}holesky factorization for symmetric
                  quasidefinite systems},
  volume =       17,
  year =         1996
}

@TechReport{	  gillwong:2010,
  title =        {Sequential quadratic programming methods},
  author =       {Philip E. Gill and Elizabeth Wong},
  type =         {Technical Report},
  number =       {NA-10-03},
  month =        {August},
  year =         2010,
  institution =  {UCSD Department of Mathematics}
}

@InProceedings{	  gleich-2011-skew-nuclear,
  author =       {Gleich, David F. and Lim, Lek-Heng},
  title =        {Rank aggregation via nuclear norm minimization},
  booktitle =    {Proceedings of the 17th ACM SIGKDD international conference on
                  Knowledge discovery and data mining},
  year =         2011,
  series =       {KDD '11},
  pages =        {60--68},
  address =      {New York, NY, USA},
  publisher =    {ACM},
  abstract =     {The process of rank aggregation is intimately intertwined with
                  the structure of skew-symmetric matrices. We apply recent
                  advances in the theory and algorithms of matrix completion to
                  skew-symmetric matrices. This combination of ideas produces a
                  new method for ranking a set of items. The essence of our idea
                  is that a rank aggregation describes a partially filled
                  skew-symmetric matrix. We extend an algorithm for matrix
                  completion to handle skew-symmetric data and use that to
                  extract ranks for each item. Our algorithm applies to both
                  pairwise comparison and rating data. Because it is based on
                  matrix completion, it is robust to both noise and incomplete
                  data. We show a formal recovery result for the noiseless case
                  and present a detailed study of the algorithm on synthetic
                  data and Netflix ratings.},
  acmid =        2020425,
  doi =          {10.1145/2020408.2020425},
  file =         {:Gleich 2011 - rank aggregation.pdf},
  isbn =         {978-1-4503-0813-7},
  keywords =     {self, nuclear norm, rank aggregation, skew symmetric},
  location =     {San Diego, California, USA},
  numpages =     9,
  owner =        {David F. Gleich},
  timestamp =    {2010.01.30}
}

@Article{	  gloptipoly:2009,
  author =       {D. Henrion and J. B. Lasserre and J. Loefberg},
  title =        {{GloptiPoly} 3: moments, optimization and semidefinite
                  programming},
  journal =      optimmeth,
  volume =       24,
  number =       {4-5},
  pages =        {761-779},
  year =         2009,
  url =          {http://homepages.laas.fr/henrion/software/gloptipoly/}
}

@InProceedings{	  gms03,
  author =       "Gilbert, A. C. and Muthukrishnan, S. and Strauss, M .J.",
  title =        "Approximation of functions over redundant dictionaries using
                  coherence",
  booktitle =    "14th Annual ACM-SIAM Symposium on Discrete Algorithms",
  organization = "ACM",
  address =      "New York",
  year =         2003,
  page =         {243--252}
}

@Article{	  goemans:1995,
  author =       {Goemans, Michel X. and Williamson, David P.},
  title =        {Improved approximation algorithms for maximum cut and
                  satisfiability problems using semidefinite programming},
  journal =      {J. ACM},
  issue_date =   {Nov. 1995},
  volume =       42,
  number =       6,
  month =        nov,
  year =         1995,
  pages =        {1115--1145},
  numpages =     31,
  doi =          {10.1145/227683.227684},
  acmid =        227684,
  publisher =    {ACM},
  address =      {New York, NY, USA},
  keywords =     {Approximation algorithms, convex optimization, randomized
                  algorithms, satisfiability}
}

@TechReport{	  gok08,
  author =       "Gonzaga, C. C. and Karas, E. W.",
  title =        "Optimal steepest descent algorithms for unconstrained convex
                  problems: fine timing Nesterov's method",
  institution =  "Departnient of Mathematics, Federal University of Santa
                  Catarina",
  address =      "Florian\'opolis",
  year =         2008,
  month =        "August"
}

@Article{	  golugrei:2003,
  author =       {Gene H. Golub and Chen Greif},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      siamscicomp,
  number =       6,
  pages =        {2076--2092},
  title =        {On solving block-structured indefinite linear systems},
  volume =       24,
  year =         2003
}

@Article{	  golugreivara:2006,
  author =       {G.H. Golub and C. Greif and J.M. Varah},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siammatrix,
  number =       3,
  pages =        {779-792},
  title =        {An Algebraic Analysis of a Block Diagonal Preconditioner for
                  Saddle Point Systems},
  volume =       27,
  year =         2006
}

@Article{	  goluhansolea:1999,
  author =       {G. H. Golub and P. C Hansen and D. P. O'Leary},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      siammatrix,
  number =       1,
  pages =        {185-194},
  title =        {Tikhonov Regularization and Total Least Squares},
  volume =       21,
  year =         1999
}

@Book{		  goluloan:1989,
  address =      {Baltimore},
  author =       {G. H. Golub and C. F. Van Loan},
  date-modified ={2007-07-18 14:59:33 -0700},
  edition =      {second},
  publisher =    {Johns Hopkins University Press},
  title =        {Matrix Computations},
  year =         1989
}

@Article{	  golumatt:1991,
  abstract =     {We consider the following problem: Compute a vector $x$ such
                  that $\Vert Ax-b\Vert_2 = \min$, subject to the constraint
                  $\Vert x\Vert_2 = \alpha$. A new approach to this problem
                  based on Gauss quadrature is given. The method is especially
                  well suited when the dimensions of $A$ are large and the
                  matrix is sparse. It is also possible to extend this technique
                  to a constrainted quadratic form: For a symmetric matrix $A$
                  we consider the minimization of $x^TAx - 2b^Tx$ subject to the
                  constraint $\Vert x\Vert_2 = \alpha$. Some numerical examples
                  are given. },
  author =       {Gene H. Golub and Urs von Matt},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      {Numer. Math.},
  pages =        {561--580},
  title =        {Quadratically constrained least squares and quadratic
                  problems},
  volume =       59,
  year =         1991
}

@Article{	  goluvonm:1991,
  abstract =     {We consider the following problem: Compute a vector $x$ such
                  that $\Vert Ax-b\Vert_2 = \min$, subject to the constraint
                  $\Vert x\Vert_2 = \alpha$. A new approach to this problem
                  based on Gauss quadrature is given. The method is especially
                  well suited when the dimensions of $A$ are large and the
                  matrix is sparse. It is also possible to extend this technique
                  to a constrainted quadratic form: For a symmetric matrix $A$
                  we consider the minimization of $x^TAx - 2b^Tx$ subject to the
                  constraint $\Vert x\Vert_2 = \alpha$. Some numerical examples
                  are given. },
  author =       {Gene H. Golub and Urs von Matt},
  date-added =   {2007-12-13 11:48:35 -0800},
  date-modified ={2007-12-13 11:48:35 -0800},
  journal =      {Numer. Math.},
  pages =        {561--580},
  title =        {Quadratically constrained least squares and quadratic
                  problems},
  volume =       59,
  year =         1991
}

@TechReport{	  gondgrot:2006,
  author =       {J. Gondzio and A. Grothey},
  date-added =   {2007-10-12 18:19:15 -0700},
  date-modified ={2007-10-12 18:20:31 -0700},
  institution =  {School of Mathematics, University of Edinburgh},
  number =       {MS-06-005},
  title =        {A new unblocking technique to warmstart interior-point methods
                  based on sensitivity analysis},
  type =         {Tech. rep.},
  year =         2006
}

@TechReport{	  gonz:2003,
  address =      {Santa Catarina, Brazil},
  author =       {C. C. Gonzaga},
  date-modified ={2007-07-26 16:41:38 -0700},
  institution =  {Dept.~of Mathematics, Federal University of Santa Catarina},
  month =        {April},
  title =        {Generation of degenerate linear programming problems},
  year =         2003
}

@Article{	  gotsgushef:2003,
  author =       {C. Gotsman and X. Gu and A. Sheffer},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      {ACM Transactions on Graphics},
  number =       3,
  pages =        {358--363},
  title =        {Fundamentals of Spherical Parameterization for {3D} Meshes},
  volume =       22,
  year =         2003
}

@Article{	  goul:1989,
  author =       {N. I. M. Gould},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      siamnumanal,
  pages =        {107--128},
  title =        {On the convergence of a sequential penalty function method for
                  constrained minimization},
  volume =       26,
  year =         1989
}

@Article{	  gouldtoint:2010,
  author =       {N. I. M. Gould and Ph. L. Toint},
  title =        {Nonlinear programming without a penalty function or a filter},
  journal =      mathprog,
  volume =       122,
  number =       1,
  year =         2010,
  page =         {155--196},
  note =         {Erratum: Math.\@ Prog.\@ B, 131(1-2) (2011) pp.403-404}
}

@Article{	  gouleytoi:2004,
  author =       {N. I. M. Gould and S. Leyffer and \mbox{Ph.} L. Toint},
  title =        {A multidimensional filter algorithm for nonlinear equations
                  and nonlinear least-squares},
  journal =      siamopt,
  year =         2004,
  volume =       15,
  number =       1,
  pages =        {17--38}
}

@Article{	  goulhribnoce:2001,
  author =       {Nicholas I. M. Gould and Mary E. Hribar and Jorge Nocedal},
  doi =          {10.1137/S1064827598345667},
  journal =      siamcomp,
  keywords =     {nonlinear optimization; conjugate gradient method; quadratic
                  programming; preconditioning; iterative refinement},
  number =       4,
  pages =        {1376-1395},
  publisher =    {SIAM},
  title =        {On the Solution of Equality Constrained Quadratic Programming
                  Problems Arising in Optimization},
  url =          {http://link.aip.org/link/?SCE/23/1376/1},
  volume =       23,
  year =         2001
}

@Article{	  goulluciromatoin:1999,
  author =       {Nicholas I. M. Gould and Stefano Lucidi and Massimo Roma and
                  Philippe L. Toint},
  doi =          {10.1137/S1052623497322735},
  journal =      siamopt,
  keywords =     {trust-region subproblem; Lanczos method; conjugate gradients;
                  preconditioning},
  local-url =    {file://localhost/Users/mpf/papers/GoulLuciToin99.pdf},
  number =       2,
  pages =        {504-525},
  publisher =    {SIAM},
  title =        {Solving the Trust-Region Subproblem using the Lanczos Method},
  url =          {http://link.aip.org/link/?SJE/9/504/1},
  volume =       9,
  year =         1999
}

@Article{	  goulorbatoin:2003,
  author =       {N. I. M. Gould and D. Orban and {\mbox{Ph}}. L. Toint},
  date-modified ={2007-09-14 15:58:13 -0700},
  journal =      acmmathsoft,
  local-url =    {file://localhost/Users/mpf/papers/CUTEr.ps},
  month =        dec,
  number =       4,
  pages =        {373--394},
  title =        {{CUTEr} and {SifDec}: A Constrained and Unconstrained Testing
                  Environment, revisited},
  url =          {http://doi.acm.org/10.1145/962437.962439},
  volume =       29,
  year =         2003
}

@Article{	  goulorbatoin:2004,
  author =       {N.I.M. Gould and D. Orban and {Ph}.L. Toint},
  title =        {{GALAHAD}, a library of thread-safe {Fortran} 90 packages for
                  large-scale nonlinear optimization},
  journal =      acmmathsoft,
  volume =       29,
  number =       4,
  pages =        {353-372},
  year =         2004
}

@InCollection{	  goultoin:2000,
  author =       {N. I. M. Gould and \mbox{Ph}. L. Toint},
  title =        {{SQP} methods for large-scale nonlinear programming},
  booktitle =    {System Modelling and Optimization, Methods, Theory and
                  Applications},
  pages =        {149-178},
  publisher =    {Kluwer Academic},
  address =      {Boston},
  year =         2000,
  editor =       {M. J. D. Powell and S. Scholtes}
}

@InCollection{	  goultoin:2002a,
  author =       {N. I. M. Gould and \mbox{Ph}. L. Toint},
  title =        {Numerical methods for large-scale non-convex quadratic
                  programming},
  booktitle =    {Trends in Industrial and Applied Mathematics},
  pages =        {149-179},
  publisher =    {Kluwer Academic},
  address =      {Deordrecht, The Netherlands},
  year =         2002,
  editor =       {A. H. Siddiqi and M. Kocvara}
}

@Article{	  goultoin:2002b,
  abstract =     {We consider a working-set method for solving large-scale
                  quadratic programming problems for which there is no
                  requirement that the objective function be convex. The methods
                  are iterative at two levels, one level relating to the
                  selection of the current working set, and the second due to
                  the method used to solve the equality-constrained problem for
                  this working set. A preconditioned conjugate gradient method
                  is used for this inner iteration, with the preconditioner
                  chosen especially to ensure feasibility of the iterates. The
                  preconditioner is updated at the conclusion of each outer
                  iteration to ensure that this feasibility requirement
                  persists. The well-known equivalence between the
                  conjugate-gradient and Lanczos methods is exploited when
                  finding directions of negative curvature. Details of an
                  implementation---the Fortran 90 package {\tt QPA} in the
                  forthcoming {\sf GALAHAD} library---are given.},
  author =       {Nicholas I. M. Gould and {\mbox{Ph}}. L. Toint},
  title =        {An iterative working-set method for large-scale nonconvex
                  quadratic programming},
  journal =      appnummath,
  year =         2002,
  volume =       43,
  pages =        {109-128}
}

@Article{	  goy05,
  author =       "Goldfarb, D. and Yin, W.",
  title =        "Second-order cone programming methods for total
                  variation-based image restoration",
  journal =      siamcomp,
  year =         2005,
  volume =       27,
  page =         {622--645}
}

@InCollection{	  granboyd:2008,
  author =       {M. Grant and S. Boyd},
  editor =       {V. Blondel, S. Boyd, and H. Kimura},
  title =        {Lecture Notes in Control and Information Sciences},
  chapter =      {Graph implementations for nonsmooth convex programs},
  publisher =    {Springer},
  year =         2008,
  pages =        {95--110}
}

@Misc{		  grant2008cvx,
  author =       {M. Grant and S. Boyd},
  title =        {{CVX: Matlab} software for disciplined convex programming (web
                  page and software)},
  howpublished = {\url{http://stanford.edu/~boyd/cvx}},
  month =        2,
  year =         2009
}

@Article{	  greirees:2007,
  abstract =     {We explore a preconditioning technique applied to the problem
                  of solving linear systems arising from primal-dual interior
                  point algorithms in linear and quadratic programming. The
                  preconditioner has the attractive property of improved
                  eigenvalue clustering with increased illconditioning of the
                  (1,1) block of the saddle point matrix. It fits well into the
                  optimization framework since the interior point iterates yield
                  increasingly ill-conditioned linear systems as the solution is
                  approached. We analyze the spectral characteristics of the
                  preconditioner, utilizing projections onto the null space of
                  the constraint matrix, and demonstrate performance on problems
                  from the NETLIB and CUTEr test suites. The numerical
                  experiments include results based on inexact inner
                  iterations.},
  author =       {C. Greif and T. Rees},
  journal =      siamcomp,
  number =       5,
  pages =        {1992-2007},
  title =        {A Preconditioner for Linear Systems Arising from Interior
                  Point Optimization Methods},
  url =          {http://www.cs.ubc.ca/~greif/Papers/rg2006.pdf},
  volume =       29,
  year =         2007
}

@Article{	  gribonval2003,
  author =       "Gribonval, R. and Nielsen. M.",
  title =        "Sparse representations in unions of bases",
  journal =      "Information Theory, IEEE Transactions",
  year =         2003,
  volume =       49,
  page =         {3320--3325}
}

@Article{	  grifstew:1961,
  author =       {R. E. Griffith and R. A. Stewart},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      managesci,
  pages =        {379-392},
  title =        {A Nonlinear Programming Technique for the Optimization of
                  Continuous Processing Systems},
  volume =       7,
  year =         1961
}

@Article{	  grippo1994class,
  title =        {A class of unconstrained minimization methods for neural
                  network training},
  author =       {Grippo, L.},
  journal =      optimmeth,
  volume =       4,
  number =       2,
  pages =        {135--150},
  year =         1994,
  publisher =    {Taylor \& Francis}
}

@Article{	  gripscia:1999,
  author =       {L. Grippo and M. Sciandrone},
  title =        {On the Convergence of the Block Nonlinear Gauss-Seidel Method
                  under Convex Constraints},
  journal =      {Operations Research Letter 26},
  year =         1999,
  pages =        {127-136}
}

@Article{	  grn03,
  abstract =     {The purpose of this correspondence is to generalize a result
                  by Donoho and Huo and Elad and Bruckstein on sparse
                  representations of signals in a union of two orthonormal bases
                  for $\mathbb{R}^N$. We consider general (redundant)
                  dictionaries for $\mathbb{R}^N$, and derive sufficient
                  conditions for having unique sparse representations of signals
                  in such dictionaries. The special case where the dictionary is
                  given by the union of $L \geq 2$ orthonormal bases for
                  $\mathbb{R}^N$ is studied in more detail. In particular, it is
                  proved that the result of Donoho and Huo, concerning the
                  replacement of the $\ell^0$ optimization problem with a linear
                  programming problem when searching for sparse representations,
                  has an analog for dictionaries that may be highly redundant.},
  author =       {R{\'e}mi Gribonval and Morten Nielsen},
  journal =      ieeetransinfo,
  keywords =     {Dictionaries, Grassmannian frames, linear programming,
                  mutually incoherent bases, nonlinear approximation, sparse
                  representations},
  month =        {December},
  number =       12,
  pages =        {3320--3325},
  title =        {Sparse Representations in Unions of Bases},
  url =
                  {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1255564&isnumber=28084},
  volume =       49,
  year =         2003
}

@TechReport{	  grodwolk:2005,
  abstract =     {We present a new method for regularization of ill-conditioned
                  problems, such as those that arise in image restoration or
                  mathematical processing of medical data. The method extends
                  the traditional trust-region subproblem, TRS, approach that
                  makes use of the L-curve maximum curvature criterion, a
                  strategy recently proposed to find a good regularization
                  parameter. We use derivative information, and properties of an
                  algorithm for solving the TRS, to efficiently move along
                  points on the L-curve and reach the point of maximum
                  curvature. We do not find a complete characterization of the
                  L-curve. A MATLAB code for the algorithm is tested and a
                  comparison to the conjugate gradient least squares, CGLS,
                  approach is given and analyzed. },
  address =      {Waterloo, Canada},
  author =       {Oleg Grodzevich and Henry Wolkowicz},
  date-modified ={2007-07-18 14:59:34 -0700},
  institution =  {Department of Combinatorics \& Optimization, University of
                  Waterloo},
  keywords =     {Regularization, trust region subproblem, ill-conditioned
                  problems, L-curve, image restoration},
  month =        {May},
  number =       {Research Report CORR 2005-11},
  title =        {Regularization using a parameterized trust region subproblem},
  year =         2005
}

@Article{	  guddwackzule:1984,
  author =       {J\"{u}rgen Guddat and Hansj\"{o}rg Wacker and W. Zulehner},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprogstudy,
  pages =        {79-96},
  title =        {On Imbedding and Parametric Optimization---A Concept of a
                  Globally Convergent Algorithm for Nonlinear Optimization
                  Problems},
  volume =       21,
  year =         1984
}

@Article{	  haber:2012,
  author =       {E. Haber and M. Chung and F. J. Herrmann},
  journal =      siamopt,
  number =       3,
  volume =       22,
  pages =        {739--757},
  title =        {An effective method for parameter estimation with {PDE}
                  constraints with multiple right-hand sides},
  year =         2012
}

@Article{	  hage:1987,
  author =       {W. W. Hager},
  journal =      jota,
  mrclass =      {90C30 (49D07 49D29)},
  mrnumber =     {89j:90220},
  number =       1,
  pages =        {37--71},
  title =        {Dual techniques for constrained optimization},
  volume =       55,
  year =         1987
}

@Article{	  haleyinzhang:2009,
  authors =      {Elaine T. Hale, Wotao Yin, Yin Zhang},
  journal =      {J. Comp. Math.},
  volume =       28,
  number =       2,
  year =         2010,
  pages =        {170–194},
  doi =          {doi:10.4208/jcm.2009.10-m1007},
  title =        {Fixed-point continuation applied to compressed sensing:
                  implementation and numerical experiments}
}

@Book{		  hampel,
  author =       {Frank R. Hampel and Elvezio M. Ronchetti and Peter J.
                  Rousseeuw and Werner A. Stahel},
  publisher =    {Wiley},
  title =        {Robust Statistics: The Approach Based on Influence Functions},
  edition =      {2nd},
  year =         1986
}

@Article{	  hanmang:1979,
  author =       {S.-P. Han and O. L. Mangasarian},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      mathprog,
  pages =        {251--269},
  title =        {Exact penalty functions in nonlinear programming},
  volume =       17,
  year =         1979
}

@Article{	  hans:1992,
  abstract =     {When discrete ill-posed problems are analyzed and solved by
                  various numerical regularization techniques, a very convenient
                  way to display information about the regularized solution is
                  to plot the norm or seminorm of the solution versus the norm
                  of the residual vector. In particular, the graph associated
                  with Tikhonov regularization plays a central role. The main
                  purpose of this paper is to advocate the use of this graph in
                  the numerical treatment of discrete ill-posed problems. The
                  graph is characterized quantitatively, and several important
                  relations between regularized solutions and the graph are
                  derived. It is also demonstrated that several methods for
                  choosing the regularization parameter are related to locating
                  a characteristic L-shaped ``corner'' of the graph. },
  author =       {Per Christian Hansen},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamreview,
  keywords =     {discrete ill-posed problems, least squares, generalized SVD,
                  regularization},
  pages =        {561--580},
  title =        {Analysis of discrete ill-posed problems by means of the
                  {L}-curve},
  volume =       34,
  year =         1992
}

@Book{		  hans:1998,
  address =      {Philadelphia},
  author =       {P. C. Hansen},
  date-modified ={2007-07-18 14:59:34 -0700},
  publisher =    siampub,
  title =        {Rank-Deficient and Discrete Ill-Posed Problems},
  year =         1998
}

@Article{	  hansolea:1993,
  abstract =     {Regularization algorithms are often used to produce reasonable
                  solutions to ill-posed problems. The L-curve is a plot---for
                  all valid regularization parameters---of the size of the
                  regularized solution versus the size of the corresponding
                  residual. Two main results are established. First a unifying
                  characterization of various regularization methods is given
                  and it is shown that the measurement of ``size'' is dependent
                  on the particular regularization method chosen. For example,
                  the 2-norm is appropriate for Tikhonov regularization, but a
                  1-norm in the coordinate system of the singular value
                  decomposition (SVD) is relevant to truncated SVD
                  regularization. Second, a new method is proposed for choosing
                  the regularization parameter based on the L-curve, and it is
                  shown how this method can be implemented efficiently. The
                  method is compared to generalized cross validation and this
                  new method is shown to be more robust in the presence of
                  correlated errors. },
  author =       {Per Christian Hansen and Dianne Prost O'Leary},
  date-modified ={2008-01-01 21:28:50 -0800},
  journal =      siamscicomp,
  keywords =     {ill-posed problems, regularization, L-curve, parameter choice,
                  generalized cross validation, discrepancy principle},
  local-url =    {file://localhost/Users/mpf/papers/HansOlea93.pdf},
  month =        {November},
  number =       6,
  pages =        {1487--1503},
  title =        {The use of the {L}-curve in the regularization of discrete
                  ill-posed problems},
  volume =       14,
  year =         1993
}

@article{hare2004identifying,
  title =        {Identifying active constraints via partial smoothness and
                  prox-regularity},
  author =       {Hare, WL and Lewis, Adrian S},
  journal =      jconvexanal,
  volume =       11,
  number =       2,
  pages =        {251--266},
  year =         2004,
  publisher =    {HELDERMANN VERLAG LANGER GRABEN 17, 32657 LEMGO, GERMANY}
}

@incollection{hare2011identifying,
  title =        {Identifying active manifolds in regularization problems},
  author =       {Hare, W. L.},
  booktitle =    {Fixed-Point Algorithms for Inverse Problems in Science and
                  Engineering},
  pages =        {261--271},
  year =         2011,
  publisher =    {Springer}
}

@Article{	  hare:2009,
  title =        {A proximal method for identifying active manifolds},
  author =       {Hare, WL},
  journal =      compapplopt,
  volume =       43,
  number =       2,
  pages =        {295--306},
  year =         2009,
  publisher =    {Springer}
}

@Article{	  harrison:93,
  author =       {Robert W. Harrison},
  journal =      {J. Opt. Soc. Am. A},
  number =       5,
  pages =        {1046--1055},
  publisher =    {OSA},
  title =        {Phase problem in crystallography},
  volume =       10,
  month =        5,
  year =         1993,
  abstract =     {Phase recovery from unphased data is the central problem in
                  the interpretation of crystal diffraction data. There are a
                  number of experimental methods for determining phases, and for
                  small molecules computational methods work very well. The
                  problem of developing robust computational methods for large
                  molecules is not yet solved. Most of the approaches for large
                  molecules are variants of the Grechburg--Saxton algorithm
                  \[Optik35, 237--246 (1972)\]; with sufficiently good initial
                  phase estimates these converge, but in general they fail with
                  phase stagnation similar to that seen in image processing
                  \[DaintyJ. C.FienupJ. R., in Image Recovery: Theory and
                  Application, StarkH., ed. (Academic, Orlando, Fla., 1987);
                  FienupJ. R.WackermanC. C., J. Opt. Soc. Am. A3, 1897--1907
                  (1986)\].}
}

@Book{		  hasttibsfrie:2001,
  author =       {T. Hastie and R. Tibshirani and J. Friedman},
  title =        {The Elements of Statistical Learning. Data mining, inference,
                  and prediction},
  publisher =    {Springer},
  year =         2001
}

@incollection{hazan2008sparse,
  title =        {Sparse approximate solutions to semidefinite programs},
  author =       {Hazan, Elad},
  booktitle =    {LATIN 2008: Theoretical Informatics},
  pages =        {306--316},
  year =         2008,
  publisher =    {Springer},
  address =      {Berline}
}

@InProceedings{	  hazankale:2012,
  title =        {Projection-free Online Learning},
  author =       {Hazan, Elad and Kale, Satyen},
  booktitle =    {Proceedings of the 29th International Conference on Machine
                  Learning (ICML-12)},
  pages =        {521--528},
  year =         2012
}

@Article{	  hazapolashas:2005,
  author =       {Tamir Hazan and Simon Polak and Amnon Shashua},
  date-added =   {2007-09-13 22:03:22 -0700},
  date-modified ={2007-10-22 16:32:33 -0700},
  doi =          {http://doi.ieeecomputersociety.org/10.1109/ICCV.2005.228},
  journal =      {International Conference on Computer Vision},
  pages =        {50-57},
  publisher =    {IEEE Computer Society},
  title =        {Sparse Image Coding Using a 3D Non-Negative Tensor
                  Factorization},
  volume =       1,
  year =         2005
}

@InProceedings{	  heilschn:2005,
  author =       {M. Heiler and C. Schnorr},
  booktitle =    {Tenth IEEE International Conference on Computer Vision},
  date-added =   {2007-09-27 11:25:06 -0700},
  date-modified ={2007-10-06 22:28:10 -0700},
  month =        {October},
  pages =        {1667-1674},
  title =        {Learning non-negative sparse image codes by convex
                  programming},
  volume =       2,
  year =         2005
}

@Article{	  helmberg2000spectral,
  title =        {A spectral bundle method for semidefinite programming},
  author =       {Helmberg, Christoph and Rendl, Franz},
  journal =      siamopt,
  volume =       10,
  number =       3,
  pages =        {673--696},
  year =         2000,
  publisher =    {SIAM}
}

@Article{	  helmberg2014spectral,
  title =        {The spectral bundle method with second-order information},
  author =       {Helmberg, Christoph and Overton, Michael L and Rendl, Franz},
  journal =      optimmeth,
  volume =       29,
  number =       4,
  pages =        {855--876},
  year =         2014,
  publisher =    {Taylor \& Francis}
}

@InProceedings{	  hennherr:2005,
  author =       {G. Hennenfent and F. J. Herrmann},
  booktitle =    {SEG International Exposition and 75th Annual Meeting},
  title =        {Sparseness-constrained data continuation with frames:
                  Applications to missing traces and aliased signals in {2/3-D}},
  url =
                  {http://slim.eos.ubc.ca/Publications/Public/Conferences/SEG/hennenfent05seg.pdf},
  year =         2005
}

@Article{	  hennherr:2007a,
  author =       {G. Hennenfent and F. J. Herrmann},
  title =        {Simply denoise: Wavefield reconstruction via jittered
                  undersampling},
  publisher =    {SEG},
  month =        {May-June},
  year =         2008,
  journal =      geophysics,
  volume =       73,
  number =       3,
  pages =        {V19-V28},
  keywords =     {Fourier transforms; geophysical techniques; seismic waves;
                  seismology},
  url =          {http://link.aip.org/link/?GPY/73/V19/1},
  doi =          {10.1190/1.2841038}
}

@InProceedings{	  hennherr:2007b,
  author =       {G. Hennenfent and F. J. Herrmann},
  booktitle =    {SEG International Exposition and 77th Annual Meeting},
  date-added =   {2007-09-18 20:14:13 -0700},
  date-modified ={2007-09-18 20:14:13 -0700},
  title =        {Random sampling: new insights into the reconstruction of
                  coarsely-sampled wavefields},
  url =
                  {http://slim.eos.ubc.ca/Publications/Public/Conferences/SEG/2007/hennenfent07seg.pdf},
  year =         2007
}

@InProceedings{	  hennherr:2007c,
  author =       {G. Hennenfent and F. J. Herrmann},
  booktitle =    {EAGE 69th Conference \& Exhibition},
  date-added =   {2007-09-18 20:14:13 -0700},
  date-modified ={2007-09-18 20:14:13 -0700},
  title =        {Irregular sampling: from aliasing to noise},
  url =
                  {http://slim.eos.ubc.ca/Publications/Private/Conferences/EAGE/2007/hennenfent07eage.pdf},
  year =         2007
}

@Article{	  herrhenn:2008,
  title =        {Non-parametric seismic data recovery with curvelet frames},
  author =       {F. J. Herrmann and Gilles Hennenfent},
  journal =      {Geophys. J. Int.},
  year =         2008,
  volume =       173,
  month =        {April},
  pages =        {233-248},
  url =          {http://slim.eos.ubc.ca/Publications/Public/Journals/CRSI.pdf},
  abstract =     {Seismic data recovery from data with missing traces on
                  otherwise regular acquisition grids forms a crucial step in
                  the seismic processing flow. For instance, unsuccessful
                  recovery leads to imaging artifacts and to erroneous
                  predictions for the multiples, adversely affecting the
                  performance of multiple elimination. A non-parametric
                  transform-based recovery method is presented that exploits the
                  compression of seismic data volumes by recently developed
                  curvelet frames. The elements of this transform are
                  multidimensional and directional and locally resemble
                  wavefronts present in the data, which leads to a compressible
                  representation for seismic data. This compression enables us
                  to formulate a new curvelet-based seismic data recovery
                  algorithm through sparsity-promoting inversion. The concept of
                  sparsity- promoting inversion is in itself not new to
                  geophysics. However, the recent insights from the field of
                  compressed sensing are new since they clearly identify the
                  three main ingredients that go into a successful formulation
                  of a recovery problem, namely a sparsifying transform, a
                  sampling strategy that subdues coherent aliases and a
                  sparsity-promoting program that recovers the largest entries
                  of the curvelet-domain vector while explaining the
                  measurements. These concepts are illustrated with a stylized
                  experiment that stresses the importance of the degree of
                  compression by the sparsifying transform. With these findings,
                  a curvelet- based recovery algorithms is developed, which
                  recovers seismic wavefields from seismic data volumes with
                  large percentages of traces missing. During this construction,
                  we benefit from the main three ingredients of compressive
                  sampling, namely the curvelet compression of seismic data, the
                  existence of a favorable sampling scheme and the formulation
                  of a large- scale sparsity-promoting solver based on a cooling
                  method. The recovery performs well on synthetic as well as
                  real data and performs better by virtue of the sparsifying
                  property of curvelets. Our results are applicable to other
                  areas such as global seismology.}
}

@Article{	  hest:1969,
  author =       {M. R. Hestenes},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      jota,
  number =       5,
  pages =        {303--320},
  title =        {Multiplier and Gradient Methods},
  volume =       4,
  year =         1969
}

@TechReport{	  hgp08,
  author =       "Hoda, S. and Gilpin, A. and Pefla, J.",
  title =        "Smoothing techniques for computing Nash equilibria of
                  sequential games",
  institution =  "Carnegie Mellon University",
  address =      "Pittsburg",
  year =         2008,
  month =        "March"
}

@Book{		  high:1998,
  address =      {Philadelphia},
  author =       {N. J. Higham},
  date-modified ={2007-07-18 14:59:32 -0700},
  edition =      {Second},
  isbn =         {0-89871-420-6},
  pages =        {xvi+302},
  publisher =    siampub,
  title =        {Handbook of Writing for the Mathematical Sciences},
  year =         1998
}

@Book{		  hiriart-urruty01,
  author =       {Hiriart-Urruty, J.-B. and Lemar\'echal, C.},
  title =        {Fundamentals of Convex Analysis},
  publisher =    {Springer},
  year =         2001,
  keywords =     {Convex Analysis},
  address =      {New York, NY}
}

@Book{		  hockschi:1981,
  address =      {Berlin and New York},
  author =       {W. Hock and K. Schittkowski},
  date-modified ={2007-07-18 14:59:34 -0700},
  publisher =    springer,
  series =       {Lecture Notes in Economics and Mathematical Systems 187},
  title =        {Test Examples for Nonlinear Programming Codes},
  year =         1981
}

@article{holloway1974extension,
  title =        {An extension of the Frank and Wolfe method of feasible
                  directions},
  author =       {Holloway, Charles A},
  journal =      mathprog,
  volume =       6,
  number =       1,
  pages =        {14--27},
  year =         1974,
  publisher =    {Springer}
}

@Article{	  horn:1979,
  author =       {J. Horning},
  journal =      {ACM SIGSOFT Software Engineering Notes},
  note =         {Cited in \cite{trop84}},
  number =       4,
  pages =        6,
  title =        {Note on Program Reliability},
  volume =       4,
  year =         1979
}

@Book{		  hornjohn:1985,
  author =       {R. A. Horn and Charles R. Johnson},
  date-modified ={2007-07-18 14:59:33 -0700},
  isbn =         {0-521-30586-1},
  pages =        {xiii+561},
  publisher =    cambridgepress,
  title =        {Matrix Analysis},
  year =         1985
}

@Book{		  hornjohn:1991,
  author =       {R. A. Horn and Charles R. Johnson},
  isbn =         {0-521-30587-X},
  pages =        {viii+607},
  publisher =    cambridgepress,
  title =        {Topics in Matrix Analysis},
  year =         1991
}

@Book{		  hosl00,
  title =        {Applied logistic regression},
  author =       {Hosmer, D.W. and Lemeshow, S.},
  year =         2000,
  publisher =    {Wiley-Interscience}
}

@Article{	  huralp:2004,
  author =       {X. Hu and D. Ralph},
  journal =      jota,
  title =        {Convergence of a penalty method for mathematical programs with
                  complementarity constraints},
  volume =       {forthcoming},
  year =         2004
}

@Article{	  hutchinson:1990,
  author =       {Hutchinson, M.F.},
  title =        {A stochastic estimator of the trace of the influence matrix
                  for laplacian smoothing splines},
  journal =      {Comm. Statist. Simulation Comput.},
  volume =       19,
  number =       2,
  pages =        {433-450},
  year =         1990,
  doi =          {10.1080/03610919008812866},
  url =          {http://www.tandfonline.com/doi/abs/10.1080/03610919008812866},
  eprint =       {http://www.tandfonline.com/doi/pdf/10.1080/03610919008812866},
  abstract =     { An unbiased stochastic estimator of tr(I-A), where A is the
                  influence matrix associated with the calculation of Laplacian
                  smoothing splines, is described. The estimator is similar to
                  one recently developed by Girard but satisfies a minimum
                  variance criterion and does not require the simulation of a
                  standard normal variable. It uses instead simulations of the
                  discrete random variable which takes the values 1, -1 each
                  with probability 1/2. Bounds on the variance of the estimator,
                  similar to those established by Girard, are obtained using
                  elementary methods. The estimator can be used to approximately
                  minimize generalised cross validation (GCV) when using
                  discretized iterative methods for fitting Laplacian smoothing
                  splines to very large data sets. Simulated examples show that
                  the estimated trace values, using either the estimator
                  presented here or the estimator of Girard, perform almost as
                  well as the exact values when applied to the minimization of
                  GCV for n as small as a few hundred, where n is the number of
                  data points. }
}

@TechReport{	  hyz07,
  address =      {Rice University, Houston, TX},
  author =       {Elaine Hale and Wotao Yin and Yin Zhang},
  institution =  {Department of Computational and Applied Mathematics},
  number =       {TR07-07},
  title =        {A Fixed-Point Continuation Method for $\ell1$-Regularized
                  Minimization with Applications to Compressed Sensing},
  year =         2007
}

@Article{	  ishuscho:1986,
  author =       {V. S. Ishutkin and K. Sch\"{o}nefeld},
  journal =      computing,
  pages =        {151-169},
  title =        {On the Globalization of {Wilson}-type Optimization Methods by
                  Means of Generalized Reduced Gradient Methods},
  volume =       37,
  year =         1986
}

@Article{	  izmailovsolodov:2011,
  year =         2011,
  journal =      mathprog,
  volume =       126,
  number =       2,
  doi =          {10.1007/s10107-009-0279-4},
  title =        {On attraction of linearly constrained Lagrangian methods and
                  of stabilized and quasi-{Newton} {SQP} methods to critical
                  multipliers},
  url =          {http://dx.doi.org/10.1007/s10107-009-0279-4},
  publisher =    {Springer-Verlag},
  keywords =     {Constrained optimization; Degenerate constraints; Second-order
                  sufficiency; Newton method; SQP; MINOS; SNOPT; 90C30; 90C33;
                  90C55; 65K05},
  author =       {Izmailov, A.F. and Solodov, M.V.},
  pages =        {231-257},
  language =     {English}
}

@inproceedings{jacob2009group,
  title =        {Group lasso with overlap and graph lasso},
  author =       {Jacob, Laurent and Obozinski, Guillaume and Vert,
                  Jean-Philippe},
  booktitle =    {Inter. Conf. Mach. Learning (ICML 2009)},
  pages =        {433--440},
  year =         2009,
  organization = {ACM}
}

@inproceedings{jaggi2010simple,
  title =        {A simple algorithm for nuclear norm regularized problems},
  author =       {Jaggi, Martin and Sulovsk, Marek and others},
  booktitle =    {Inter. Conf. Mach. Learning (ICML 2010)},
  pages =        {471--478},
  year =         2010
}


@InProceedings{	  jenatton2010proximal,
  title =        {Proximal methods for sparse hierarchical dictionary learning},
  author =       {Jenatton, Rodolphe and Mairal, Julien and Bach, Francis R and
                  Obozinski, Guillaume R},
  booktitle =    {Proceedings of the 27th International Conference on Machine
                  Learning (ICML-10)},
  pages =        {487--494},
  year =         2010
}

@TechReport{	  jlns07,
  author =       "Juditsky, A. and Lan, G. and Nemirovski, A. and Shapiro, A.",
  title =        "Stochastic Approximation approach to Stochastic Programming",
  institution =  "to appear in SIAM J. Optim.",
  year =         2007
}

@Book{		  jongjonktwil:1986,
  address =      {Frankfurt, Germany},
  author =       {H. Th. Jongen and P. Jonker and F. Twilt},
  publisher =    {Peter Lang Verlag},
  title =        {Nonlinear Optimization in $\mathcal{R}^n$ II: Transversality,
                  Flows, Parametric Aspects},
  year =         1986
}

@Article{	  kanzqiqi:2003,
  author =       {C. Kanzow and H. Qi and L. Qi},
  journal =      jota,
  pages =        {333-345},
  title =        {On the minimum norm solution of linear programs},
  volume =       116,
  year =         2003
}

@Article{	  karl:1970,
  author =       {L. Karlovitz},
  journal =      {J. of Approx. Theory},
  title =        {Construction of nearest points in the $\ell^p$, $p$ even and
                  $\ell^1$ norms},
  volume =       3,
  year =         1970
}

@inproceedings{karmarkar1984new,
  title =        {A new polynomial-time algorithm for linear programming},
  author =       {Karmarkar, Narendra},
  booktitle =    {Proceedings of the Sixteenth Annual ACM symposium on Theory of
                  Computing},
  pages =        {302--311},
  year =         1984,
  organization = {ACM}
}

@Book{		  kell:1995,
  address =      {Philadelphia},
  author =       {C. T. Kelley},
  publisher =    {SIAM},
  series =       {Frontiers in applied mathematics},
  title =        {Iterative Methods for Linear and Nonlinear Equations},
  volume =       16,
  year =         1995
}

@Article{	  kellgoulwath:2000,
  author =       {C. Keller and N. I. M. Gould and A. J. Wathen},
  journal =      siammatrix,
  number =       4,
  pages =        {1300--1317},
  title =        {Constraint Preconditioning for Indefinite Linear Systems},
  url =          {citeseer.ist.psu.edu/keller00constraint.html},
  volume =       21,
  year =         2000
}

@Article{	  kimkimkim:2006,
  title =        {Blockwise sparse regression},
  author =       {Kim, Y. and Kim, J. and Kim, Y.},
  journal =      {Statistica Sinica},
  volume =       16,
  number =       2,
  pages =        {375--390},
  year =         2006
}

@Article{	  kimkohlustboydgori:2007,
  author =       {S.-J. Kim and K. Koh and M. Lustig and S. Boyd and D.
                  Gorinevsky},
  title =        {An Interior-Point Method for Large-Scale {L1}-Regularized
                  Least Squares},
  journal =      {IEEE J. Sel. Top. Signal Process.},
  year =         2007,
  volume =       1,
  number =       4,
  pages =        {606-617},
  doi =          {10.1109/JSTSP.2007.910971}
}

@Article{	  kiw03,
  author =       "Kiwiel, K. C.",
  title =        "Convergence of Approximate and Incremental Subgradient Methods
                  for Convex Optimization",
  journal =      siamopt,
  year =         2003,
  volume =       14,
  page =         {807--840}
}

@Article{	  kiw07,
  author =       "Kiwiel, K. C.",
  title =        "On Linear-Time Algorithms for the Continuous Quadratic
                  Knapsack Problem",
  journal =      "Journal of Optimization Theory and Applications",
  year =         2007,
  volume =       134,
  page =         {549--554}
}

@Article{	  kiw95,
  author =       {Kiwiel, Krzysztof C.},
  coden =        {AMOMBN},
  fjournal =     {Applied Mathematics and Optimization. An International Journal
                  with Applications to Stochastics},
  journal =      {Appl. Math. Optim.},
  keywords =     {Regularization, linear programs},
  mrclass =      {90C08 (49J52 90C25)},
  mrnumber =     {MR1340043 (96d:90051)},
  mrreviewer =   {Stefan Scholtes},
  number =       3,
  pages =        {235--254},
  title =        {Finding normal solutions in piecewise linear programming},
  volume =       32,
  year =         1995
}

@Article{	  kiw95b,
  author =       {Kiwiel, Krzysztof C.},
  coden =        {LAAPAW},
  fjournal =     {Linear Algebra and its Applications},
  journal =      {Linear Algebra Appl.},
  keywords =     {Regularization, linear programs},
  mrclass =      {90C08 (49M37 90C30)},
  mrnumber =     {MR1352835 (96g:90042)},
  mrreviewer =   {Stephan Dempe},
  pages =        {1--7},
  title =        {Iterative schemes for the least {$2$}-norm solution of
                  piecewise linear programs},
  volume =       229,
  year =         1995
}

@Article{	  kiw97,
  author =       "Kiwiel, K. C.",
  title =        "Proximal Minimization Methods with Generalized {Bregman}
                  Functions",
  journal =      "SIAM Journal on Control and Optimization",
  year =         1997,
  volume =       35,
  page =         {1142--1168}
}

@TechReport{	  kkw08,
  author =       "Kim, S. and Kojima, M. and Waki, H.",
  title =        "Exploiting sparsity in SDP relaxation for sensor network
                  localization, report B-447",
  institution =  "Tokyo Institute of Technology",
  address =      "Tokyo",
  year =         2008,
  month =        "October"
}

@Article{	  kleywegt2002sample,
  title =        {{The sample average approximation method for stochastic
                  discrete optimization}},
  author =       {Kleywegt, A.J. and Shapiro, A. and Homem-de-Mello, T.},
  journal =      siamopt,
  volume =       12,
  number =       2,
  pages =        {479--502},
  year =         2002,
  publisher =    {Citeseer}
}

@Article{	  kly:2007,
  title =        {A primal-dual active-set method for non-negativity constrained
                  total variation deblurring problems},
  author =       {Krishnan, Dilip and Lin, Ping and Yip, Andy M},
  journal =      ieeetransimproc,
  volume =       16,
  number =       11,
  pages =        {2766--2777},
  year =         2007,
  publisher =    {IEEE}
}

@article{ko1994iterative,
  title =        {An iterative two-step algorithm for linear complementarity
                  problems},
  author =       {Ko, M and Zowe, Jochem and others},
  journal =      {Numerische Mathematik},
  volume =       68,
  number =       1,
  pages =        {95--106},
  year =         1994,
  publisher =    {Springer}
}

@Article{	  kobesuhl:2007,
  author =       {A. Koberstein and U. H. Suhl},
  title =        {Progress in the dual simplex method for large scale {LP}
                  problems: practical dual phase 1 algorithms},
  journal =      compapplopt,
  year =         2007,
  volume =       37,
  number =       1,
  pages =        {49-65},
  month =        {May},
  doi =          {10.1007/s10589-007-9022-3}
}

@TechReport{	  kold:2006,
  author =       {T. G. Kolda},
  institution =  {Sandia National Laboratories},
  local-url =    {file://localhost/Users/mpf/papers/Kold06.pdf},
  title =        {Multilinear operators for higher-order decompositions},
  year =         2006
}

@Article{	  koldbade:2009,
  author =       {Tamara G. Kolda and Brett W. Bader},
  title =        {Tensor Decompositions and Applications},
  journal =      siamreview,
  month =        {September},
  year =         2009,
  volume =       51,
  number =       3,
  pages =        {455--500},
  doi =          {10.1137/07070111X}
}

@TechReport{	  kpw06,
  author =       "Krislock, N. and Piccialli, V. and Wolkowicz, H.",
  title =        "Robust semidefinite programming approaches for sensor network
                  localization with anchors",
  institution =  "Department of Combinatorics and Optimization, University of
                  Waterloo",
  address =      "Waterloo",
  year =         2006,
  month =        "May"
}

@Book{		  kull:1959,
  address =      {New York},
  author =       {Solomon Kullback},
  date-modified ={2007-07-18 14:59:33 -0700},
  publisher =    {Wiley},
  title =        {Information Theory and Statistics},
  year =         1959
}

@Article{	  laiyin:2013,
  author =       {Lai, M. and Yin, W.},
  title =        {Augmented $\ell_1$ and Nuclear-Norm Models with a Globally
                  Linearly Convergent Algorithm},
  journal =      siamsiims,
  volume =       6,
  number =       2,
  pages =        {1059-1091},
  year =         2013,
  doi =          {10.1137/120863290},
  url =          {http://epubs.siam.org/doi/abs/10.1137/120863290},
  eprint =       {http://epubs.siam.org/doi/pdf/10.1137/120863290}
}

@Article{	  langford:2009:sol:1577069.1577097,
  author =       {Langford, John and Li, Lihong and Zhang, Tong},
  title =        {Sparse Online Learning via Truncated Gradient},
  journal =      {J. Mach. Learn. Res.},
  issue_date =   {12/1/2009},
  volume =       10,
  month =        jun,
  year =         2009,
  pages =        {777--801},
  numpages =     25,
  url =          {http://dl.acm.org/citation.cfm?id=1577069.1577097},
  acmid =        1577097,
  publisher =    {JMLR.org}
}

@Misc{		  lars:2001,
  author =       {R. M. Larsen},
  date-modified ={2007-07-18 14:59:32 -0700},
  note =         {\url{http://sun.stanford.edu/~rmunk/PROPACK/}},
  title =        {Combining implicit restart and partial reorthogonalization in
                  {L}anczos bidiagnalization},
  year =         2001
}

@Article{	  lasserre:2008,
  author =       {J. B. Lasserre},
  title =        {A Semidefinite programming approach to the generalized problem
                  of moments},
  journal =      mathprog,
  volume =       112,
  pages =        {65-92},
  year =         2008
}

@Article{	  lathmoorvand:2000,
  author =       {Lieven De Lathauwer and Bart De Moor and Joos Vandewalle},
  date-added =   {2007-10-06 17:34:41 -0700},
  date-modified ={2007-10-06 17:35:04 -0700},
  doi =          {10.1137/S0895479898346995},
  journal =      siammatrix,
  keywords =     {multilinear algebra; singular value decomposition;
                  higher-order tensor; rank reduction},
  number =       4,
  pages =        {1324-1342},
  publisher =    {SIAM},
  title =        {On the Best Rank-1 and Rank-(R[sub 1],R[sub 2],. . .,R[sub N])
                  Approximation of Higher-Order Tensors},
  url =          {http://link.aip.org/link/?SML/21/1324/1},
  volume =       21,
  year =         2000
}

@inproceedings{laue2012hybrid,
  title =        {A hybrid algorithm for convex semidefinite optimization},
  author =       {Laue, S{\"o}ren},
  booktitle =    {Proceedings of the 29th International Conference on Machine
                  Learning (ICML-12)},
  year =         2012
}

@Book{		  lawshans:1995,
  address =      {Philadelphia},
  author =       {Charles L. Lawson and Richard J. Hanson},
  date-modified ={2007-07-18 14:59:34 -0700},
  note =         {Originally published: Prentice-Hall, Englewood Cliffs, NJ,
                  1974},
  number =       15,
  publisher =    siampub,
  series =       {Classics in Applied Mathematics},
  title =        {Solving Least Squares Problems},
  year =         1995
}

@inproceedings{lee2009efficient,
  title =        {Efficient and guaranteed rank minimization by atomic
                  decomposition},
  author =       {Lee, Kiryung and Bresler, Yoram},
  booktitle =    {IEEE International Symposium on Information Theory (ISIT 2009)},
  pages =        {314--318},
  year =         2009,
  organization = {IEEE}
}

@Article{	  lee2014proximal,
  title =        {Proximal Newton-type methods for minimizing composite
                  functions},
  author =       {Lee, Jason D and Sun, Yuekai and Saunders, Michael A},
  journal =      siamopt,
  volume =       24,
  number =       3,
  pages =        {1420--1443},
  year =         2014,
  publisher =    {Society for Industrial and Applied Mathematics}
}

@Article{	  leeseun:1999,
  author =       {D. D. Lee and H. S. Seung},
  journal =      {Nature},
  pages =        {788--791},
  title =        {Learning the parts of objects by non-negative matrix
                  factorization},
  volume =       401,
  year =         1999
}

@InProceedings{	  leeseun:2001,
  author =       {D. D. Lee and H. S. Seung},
  booktitle =    {Advances in Neural Information Processing Systems 13},
  editor =       {Todd K.Leen and Thomas G. Dietterich and Volker Tresp},
  pages =        {556--562},
  publisher =    {MIT Press},
  title =        {Algorithms for non-negative matrix factorization},
  year =         2001
}

@Book{		  lehoucq1998arpack,
  title =        {{ARPACK} Users' guide: solution of large-scale eigenvalue
                  problems with implicitly restarted {Arnoldi} methods},
  author =       {Lehoucq, Richard B and Sorensen, Danny C and Yang, Chao},
  volume =       6,
  year =         1998,
  publisher =    {SIAM}
}

@Article{	  lemaneminest:1995,
  author =       {C. Lemar\'echal and A. Nemirovskii and Y Nesterov},
  title =        {New variants of bundle methods},
  year =         1995,
  pages =        {111--147},
  journal =      mathprog,
  volume =       69
}

@incollection{lemarechal1981bundle,
  title =        {On a bundle algorithm for nonsmooth optimization},
  author =       {Lemarechal, Claude and Strodiot, Jean-Jacques and Bihain,
                  Andr{\'e}},
  booktitle =    {Nonlinear programming 4},
  pages =        {245--282},
  year =         1981,
  publisher =    {Elsevier}
}

@Article{	  levy:2005,
  title =        {A generic algorithm for solving inclusions},
  author =       {Levy, A.B.},
  journal =      siamopt,
  volume =       15,
  number =       2,
  pages =        {430--455},
  year =         2005
}

@Article{	  lewiover:1996,
  author =       {A. S. Lewis and M. L. Overton},
  journal =      actanumerica,
  pages =        {149--190},
  title =        {Eigenvalue optimization},
  volume =       {xx},
  year =         1996
}

@Article{	  lewis1996convex,
  title =        {Convex analysis on the Hermitian matrices},
  author =       {Lewis, Adrian Stephen},
  journal =      siamopt,
  volume =       6,
  number =       1,
  pages =        {164--177},
  year =         1996,
  publisher =    {SIAM}
}

@Article{	  lewis:1995,
  title =        {The convex analysis of unitarily invariant matrix functions},
  author =       {Lewis, Adrian S.},
  journal =      jconvexanal,
  volume =       2,
  number =       1,
  pages =        {173--183},
  year =         1995
}

@Misc{		  leyf:2000,
  author =       {S. Leyffer},
  note =         {\verb+http://www.mcs.anl.gov/\~{}leyffer/MacMPEC.+},
  title =        {{MacMPEC}: {AMPL} collection of {MPECs}},
  year =         2000
}

@TechReport{	  leyf:2002,
  author =       {S. Leyffer},
  institution =  {University of Dundee},
  month =        {Februaru},
  title =        {The Penalty Interior Point Method fails to converge for
                  Mathematical Programs with Equilibrium Constraints},
  year =         2002
}

@TechReport{	  leyf:2005,
  address =      {Illinois},
  author =       {S. Leyffer},
  institution =  {Mathematics and Computer Science Division, Argonne National
                  Laboratory},
  keywords =     {multiobjective, complementarity, pareto},
  month =        {September},
  number =       {ANL/MCS-P1290-0905},
  title =        {A note on multiobjective optimization and complementarity
                  constraints},
  type =         {Preprint},
  year =         2005
}

@Article{	  lin:2007,
  title =        {Projected gradient methods for nonnegative matrix
                  factorization},
  author =       {Chih-Jen Lin},
  journal =      {Neural Computation},
  volume =       19,
  number =       10,
  pages =        {2756--2779},
  year =         2007,
  publisher =    {MIT Press}
}

@article{ling2015self,
  title =        {Self-calibration and biconvex compressive sensing},
  author =       {Ling, Shuyang and Strohmer, Thomas},
  journal =      {Inverse Probl.},
  volume =       31,
  number =       11,
  pages =        115002,
  year =         2015,
  publisher =    {IOP Publishing}
}

@Article{	  linmore:1999,
  author =       {Chih-Jen Lin and Jorge J. Mor\'{e}},
  journal =      siamcomp,
  number =       1,
  pages =        {24--45},
  publisher =    {SIAM},
  title =        {Incomplete Cholesky Factorizations with Limited Memory},
  volume =       21,
  year =         1999
}

@Article{	  linmore:1999b,
  author =       {Ch.-J. Lin and J. J. Mor\'{e}},
  journal =      siamopt,
  number =       4,
  pages =        {1100--1127},
  title =        {Newton's Method for Large Bound-Constrained Optimization
                  Problems},
  volume =       9,
  year =         1999
}

@article{littlestone1994weighted,
  title =        {The weighted majority algorithm},
  author =       {Littlestone, Nick and Warmuth, Manfred K},
  journal =      infcomp,
  volume =       108,
  number =       2,
  pages =        {212--261},
  year =         1994,
  publisher =    {Elsevier}
}

@TechReport{	  liusun:2001,
  author =       {Xinwei Liu and Jie Sun},
  date-modified ={2007-07-18 14:59:32 -0700},
  institution =  {National University of Singapore},
  title =        {Generalized stationary points and an interior point method for
                  mathematical programs with equilibrium constraints},
  year =         2001
}

@TechReport{	  liv08,
  author =       "Liu, Z. and Vandenberghe, L.",
  title =        "Interior-point method for nuclear norm approximation with
                  application to system identification",
  institution =  "Electrical Engineering Department, UCLA",
  address =      "Los Angeles",
  year =         2008
}

@book{beck2017first,
  title={First-order methods in optimization},
  author={Beck, Amir},
  year={2017},
  publisher={SIAM}
}

@TechReport{	  llm06,
  author =       "G. Lan and Z. Lu and R. D. C. Monteiro",
  title =        "Primal-dual first-order methods with $O(1/e)O(1/\epsilon)$
                  iteration-complexity for cone programming",
  institution =  "School of Industrial and Systems Engineering, Georgia
                  Institute of Technology",
  address =      "Atlanta",
  year =         2006,
  month =        "December"
}

@TechReport{	  lmy08,
  author =       "Lu, Z. and Monteiro, R. D. C. and Yuan, M.",
  title =        "Convex optimization methods for dimension reduction and
                  coefficient estimation in multivariate linear regression",
  institution =  "School of Industrial and Systems Engineering, Georgia
                  Institute of Technology",
  address =      "Atlanta",
  year =         2008,
  month =        "January",
  note =         "revised March 2009"
}

@Article{	  lnm07,
  author =       "Lu, Z. and Nemirovski, A. S. and Monteiro, R. D. C.",
  title =        "Large-scale semidefinite programming via a saddle point
                  Mirror-Prox algorithm",
  journal =      "Mathematical Programming",
  year =         2007,
  volume =       109,
  page =         {211--237}
}

@Article{	  loan:2000,
  author =       {C. F. Van Loan},
  date-added =   {2007-09-27 14:46:49 -0700},
  date-modified ={2007-09-27 14:54:56 -0700},
  journal =      compapplmath,
  month =        {November},
  pages =        {85-100},
  title =        {The ubiquitous {Kroneckar} product},
  volume =       123,
  year =         2000
}

@inproceedings{lofberg2004yalmip,
  title =        {YALMIP: A toolbox for modeling and optimization in MATLAB},
  author =       {Lofberg, Johan},
  booktitle =    {2004 IEEE international conference on robotics and automation},
  pages =        {284--289},
  year =         2004,
  organization = {IEEE}
}

@Book{		  lohr1999sampling,
  title =        {{Sampling: design and analysis}},
  author =       {Lohr, Sharon L.},
  year =         1999,
  publisher =    {Duxbury Press},
  address =      {Pacific Grove}
}

@InCollection{	  lovasz:1983,
  year =         1983,
  booktitle =    {Mathematical Programming The State of the Art},
  editor =       {Bachem, Achim and Korte, Bernhard and Grötschel, Martin},
  doi =          {10.1007/978-3-642-68874-4_10},
  title =        {Submodular functions and convexity},
  publisher =    {Springer},
  author =       {Lov\`asz, L.},
  pages =        {235-257},
  language =     {English}
}

@Book{		  lovemorrweso:1988,
  author =       {R. F. Love and J. G. Morris and G. O. Wesolowsky},
  title =        {Facilities location: models and methods},
  year =         1988,
  address =      {New York},
  publisher =    {North-Holland}
}

@TechReport{	  lu08,
  author =       "Lu, Z.",
  title =        "Smooth optimization approach for sparse covariance selection",
  institution =  "Department of Mathematics, Simon Fraser University",
  address =      "Burnaby",
  year =         2008,
  month =        "January",
  note =         "submitted to SIAM J. Optim."
}

@article{lu2012augmented,
  title =        {An augmented Lagrangian approach for sparse principal
                  component analysis},
  author =       {Lu, Zhaosong and Zhang, Yong},
  journal =      mathprog,
  pages =        {1--45},
  year =         2012,
  publisher =    {Springer}
}

@Article{	  luci:1987,
  author =       {Lucidi, S.},
  date-modified ={2007-07-18 14:59:31 -0700},
  fjournal =     {Journal of Optimization Theory and Applications},
  journal =      jota,
  number =       1,
  pages =        {103--117},
  title =        {A new result in the theory and computation of the least-norm
                  solution of a linear program},
  volume =       55,
  year =         1987
}

@Article{	  luci:1987b,
  author =       {Lucidi, S.},
  date-modified ={2007-07-18 14:59:31 -0700},
  fjournal =     {Optimization. A Journal of Mathematical Programming and
                  Operations Research},
  journal =      {Optimization},
  number =       6,
  pages =        {809--823},
  title =        {A finite algorithm for the least two-norm solution of a linear
                  program},
  volume =       18,
  year =         1987
}

@Article{	  ludo:2007,
  author =       {Y. M. Lu and M. N. Do},
  title =        {Multidimensional directional filter banks and surfacelets},
  journal =      ieeetransimproc,
  volume =       16,
  number =       4,
  month =        {April},
  pages =        {918--931},
  year =         2007
}

@Book{		  luen:1984,
  author =       {David G. Luenberger},
  date-modified ={2007-07-18 14:59:33 -0700},
  edition =      {Second},
  publisher =    addisonwesley,
  title =        {Linear and Nonlinear Programming},
  year =         1984
}

@Book{		  luenberger2008linear,
  title =        {{Linear and nonlinear programming}},
  author =       {Luenberger, D.G. and Ye, Y.},
  year =         2008,
  publisher =    {Springer Verlag}
}

@Article{	  luo1993error,
  title =        {{Error bounds and convergence analysis of feasible descent
                  methods: A general approach}},
  author =       {Luo, Z.Q. and Tseng, P.},
  journal =      {Ann. Oper. Res.},
  volume =       46,
  number =       1,
  pages =        {157--178},
  year =         1993
}

@Article{	  luo91,
  author =       "Luo, Z. Q.",
  title =        "On the convergence of the LMS algorithm with adaptive learning
                  rate for linear feedforward networks",
  journal =      "Neural Computation",
  year =         1991,
  volume =       3,
  page =         {226--245}
}

@Article{	  luopang:1994,
  author =       {Z.-Q. Luo and J.-S. Pang},
  journal =      mathprog,
  pages =        {1--28},
  title =        {Error bounds for analytic systems and their applications},
  volume =       67,
  year =         1994
}

@Proceedings{	  luopang:2000,
  editor =       {Z.-Q. Luo and J.-S. Pang},
  journal =      mathprog,
  key =          {LuP00},
  pages =        {221--410},
  title =        {Error bounds in mathematical programming, {\rm Math.\
                  Program.}},
  volume =       88,
  year =         2000
}

@Book{		  luopangralph:1996,
  author =       {Z.-Q. Luo and J.-S. Pang and D. Ralph},
  date-modified ={2007-07-18 14:59:33 -0700},
  publisher =    {Cambridge University Press},
  title =        {Mathematical Programs with Equilibrium Constraints},
  year =         1996
}

@TechReport{	  luosturzhan:1997,
  address =      {Erasmus University, Rotterdam, The Netherlands},
  author =       {Z.-Q. Luo and J. F. Sturm and S. Zhang},
  institution =  {Econometric Institute},
  month =        {April},
  number =       {No. 9719/A},
  title =        {Duality results for conic convex programming},
  type =         {Econometric Institute Report},
  year =         1997
}

@Article{	  lustdonopaul:2007a,
  author =       {M. Lustig and D. L. Donoho and J. M. Pauly},
  title =        {Sparse {MRI}: The application of compressed sensing for rapid
                  {MR} imaging},
  journal =      {Mag. Resonance Med.},
  volume =       58,
  number =       6,
  pages =        {1182--1195},
  month =        {December},
  year =         2007,
  doi =          {10.1002/mrm.21391}
}

@Misc{		  lustdonopaul:2007b,
  author =       {M. Lustig and D. L. Donoho and J. M. Pauly},
  date-added =   {2007-09-14 10:54:08 -0700},
  date-modified ={2007-09-14 14:52:20 -0700},
  howpublished = {\url{http://www.stanford.edu/~mlustig/SparseMRI.html}},
  title =        {Sparse {MRI} {Matlab} code},
  year =         2007
}

@Article{	  lustdonosantpaul:2007,
  author =       {M. Lustig and D. L. Donoho and J. M. Santos and J. M. Pauly},
  title =        {Compressed Sensing {MRI}},
  journal =      {IEEE Signal Process. Mag.},
  volume =       25,
  number =       2,
  pages =        {72--82},
  month =        {March},
  year =         2007
}

@Article{	  lut92,
  author =       "Luo, Z. Q. and Tseng, P.",
  title =        "On the linear convergence of descent methods for convex
                  essentially smooth minimization",
  journal =      siamcontrol,
  year =         1992,
  volume =       30,
  page =         {408--425}
}

@Article{	  lut93,
  author =       "Luo, Z. Q. and Tseng, P.",
  title =        "On the convergence rate of dual ascent methods for linearly
                  constrained convex minimization",
  journal =      "Math. Oper. Res.",
  year =         1993,
  volume =       18,
  page =         {846--867}
}

@Article{	  lut94,
  author =       "Luo, Z. Q. and Tseng, P.",
  title =        "Error bounds and convergence analysis of feasible descent
                  methods: a general approach",
  journal =      "Annals of Operations Research",
  year =         1993,
  volume =       46,
  page =         {157--178}
}

@Article{	  lut94b,
  author =       "Luo, Z. Q. and Tseng, P.",
  title =        "On the rate of convergence of a distributed asynchronous
                  routing algorithm",
  journal =      "Automatic Control, IEEE Transactions",
  year =         1994,
  volume =       39,
  page =         {1123--1129}
}

@TechReport{	  lwy04,
  author =       "Liang, T.-C. and Wang, T.-C. and Ye, Y.",
  title =        "A gradient search method to round the semidefinite programming
                  relaxation solution for ad hoc wireless sensor network
                  localization",
  institution =  "Electrical Engineering, Stanford University",
  year =         2004,
  month =        "October"
}

@MastersThesis{	  mali:2003,
  address =      {Cambridge, MA},
  author =       {Dmitry M. Malioutov},
  month =        {July},
  school =       {Dept. Electrical Engineering, Massachusetts Institute of
                  Technology},
  title =        {A Sparse Signal Reconstruction Perspective for Source
                  Localization with Sensor Arrays},
  year =         2003
}

@Article{	  malicetiwill:2005,
  abstract =     {We present a source localization method based on a sparse
                  representation of sensor measurements with an overcomplete
                  basis composed of samples from the array manifold. We enforce
                  sparsity by imposing penalties based on the $\ell_1$-norm. A
                  number of recent theoretical results on sparsifying properties
                  of $\ell_1$ penalties justify this choice. Explicitly
                  enforcing the sparsity of the representation is motivated by a
                  desire to obtain a sharp estimate of the spatial spectrum that
                  exhibits super-resolution. We propose to use the singular
                  value decomposition (SVD) of the data matrix to summarize
                  multiple time or frequency samples. Our formulation leads to
                  an optimization problem, which we solve efficiently in a
                  second-order cone (SOC) programming framework by an interior
                  point implementation. We propose a grid refinement method to
                  mitigate the effects of limiting estimates to a grid of
                  spatial locations and introduce an automatic selection
                  criterion for the regularization parameter involved in our
                  approach. We demonstrate the effectiveness of the method on
                  simulated data by plots of spatial spectra and by comparing
                  the estimator variance to the Crame\'{e}r-Rao bound (CRB). We
                  observe that our approach has a number of advantages over
                  other source localization techniques, including increased
                  resolution, improved robustness to noise, limitations in data
                  quantity, and correlation of the sources, as well as not
                  requiring an accurate initialization. },
  author =       {Dmitry Malioutov and M\"{u}jad \c{C}etin and Alan S. Willsky},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      ieeetranssigproc,
  keywords =     {Direction-of-arrival estimation, overcomplete representation,
                  sensor array processing, source localization, sparse
                  representation, superresolution},
  month =        {August},
  number =       8,
  pages =        {3010--3022},
  title =        {A sparse signal reconstruction perspective for source
                  localization with sensor arrays},
  volume =       53,
  year =         2005
}

@InProceedings{	  malicetiwill:2005b,
  author =       {D. M. Malioutov and M. \c{C}etin and A. S. Willsky},
  booktitle =    {{IEEE} International Conference on Acoustics, Speech, and
                  Signal Processing},
  location =     {Philadelphia, PA},
  month =        {March},
  pages =        {733--736},
  title =        {Homotopy Continuation for Sparse Signal Representation},
  volume =       5,
  year =         2005
}

@InProceedings{	  malisangwill:2008,
  author =       {Dmitry Malioutov and Sujay Sanghavi and Alan Willsky},
  title =        {Compressed sensing with sequential observations},
  year =         2008,
  month =        {April},
  booktitle =    {Proceedings of the International Conference on Acoustics,
                  Speech, and Signal Processing},
  publisher =    {IEEE Signal Processing Society}
}

@Book{		  mallat:1999,
  author =       {S. Mallat},
  title =        {A Wavlet Tour of Signal Processing},
  publisher =    {Academic Press},
  year =         1999
}

@Article{	  mam99,
  author =       "Mangasarian, O. L. and Musicant, D. R.",
  title =        "Successive over relaxation for support vector machines",
  journal =      "IEEE Trans. Neural Networks",
  year =         1999,
  volume =       10,
  page =         {1032--1037}
}

@Article{	  man84,
  author =       "Mangasarian, O. L.",
  title =        "Sparsity-Preserving SOR Algorithms for Separable Quadratic and
                  Linear Programming",
  journal =      "Comnput. Oper. Res.",
  year =         1984,
  volume =       11,
  page =         {105--112}
}

@Article{	  man93,
  author =       "Mangasarian, O. L.",
  title =        "Mathematical programming in neural networks",
  journal =      "ORSA J. Comput.",
  year =         1993,
  volume =       5,
  page =         {349--360}
}

@Article{	  man95,
  author =       "Mangasarian, O. L.",
  title =        "Parallel gradient distribution in unconstrained optimization",
  journal =      siamcontrol,
  year =         1995,
  volume =       33,
  page =         {1916--1925}
}

@Book{		  mang:1969,
  address =      {New York},
  author =       {O. L. Mangasarian},
  date-modified ={2007-07-18 14:59:33 -0700},
  publisher =    mcgrawhill,
  title =        {Nonlinear Programming},
  year =         1969
}

@Article{	  mang:1984,
  author =       {O. L. Mangasarian},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprogstudy,
  pages =        {206--216},
  title =        {Normal solutions of linear programs},
  volume =       22,
  year =         1984
}

@Article{	  mang:1985,
  author =       {O. L. Mangasarian},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      siamcontrol,
  pages =        {30-37},
  title =        {Sufficiency of exact penalty minimization},
  volume =       23,
  year =         1985
}

@Article{	  mang:1988,
  author =       {O. L. Mangasarian},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      {Oper. Res. Lett.},
  pages =        {21--26},
  title =        {A simple characterization of solution sets of convex programs},
  volume =       7,
  year =         1988
}

@Book{		  mang:1994,
  address =      {New York},
  author =       {O. L. Mangasarian},
  date-modified ={2007-07-18 14:59:33 -0700},
  editor =       {Gene Golub},
  note =         {Originally published: New York, McGraw-Hill, 1969.},
  publisher =    {{SIAM}},
  series =       {Classics in Applied Mathematics},
  title =        {Nonlinear Programming},
  volume =       10,
  year =         1994
}

@Article{	  mang:2004,
  author =       {O. L. Mangasarian},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      jota,
  pages =        {1-18},
  title =        {A {N}ewton method for linear programming},
  volume =       121,
  year =         2004
}

@Article{	  mangfrom:1967,
  author =       {O. L. Mangasarian and S. Fromovitz},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      mathanaappl,
  pages =        {37-47},
  title =        {The {F}ritz-{J}ohn conditions in the presence of equality and
                  inequality constraints},
  volume =       17,
  year =         1967
}

@Article{	  mangmeye:1979,
  author =       {O. L. Mangasarian and R. R. Meyer},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      siamcontrol,
  month =        {November},
  number =       6,
  pages =        {745--752},
  title =        {Nonlinear Perturbation of Linear Programs},
  volume =       17,
  year =         1979
}

@TechReport{	  mannrich:2004,
  address =      {CA},
  author =       {Alan S. Manne and Richard G. Richels},
  date-modified ={2007-07-18 14:59:33 -0700},
  institution =  {Stanford University},
  month =        {June},
  title =        {{MERGE}: An intergrated assessment model for global climate
                  change},
  year =         2004
}

@PhDThesis{	  mara:1978,
  address =      {London, UK},
  author =       {N. Maratos},
  date-modified ={2007-07-18 14:59:32 -0700},
  school =       {Imperial College of Science and Technology},
  title =        {Exact penalty function algorithms for finite dimensional and
                  optimization problems},
  year =         1978
}

@Article{	  mark:1956,
  author =       {H. M. Markowitz},
  title =        {The optimization of a quadratic function subject to
                  constraints},
  journal =      {Nav. Res. Logist. Quart.},
  volume =       3,
  year =         1956,
  pages =        {111--133}
}

@article{markowitz1956optimization,
  title =        {The optimization of a quadratic function subject to linear
                  constraints},
  author =       {Markowitz, Harry},
  journal =      {Naval research logistics Quarterly},
  volume =       3,
  number =       {1-2},
  pages =        {111--133},
  year =         1956,
  publisher =    {Wiley Online Library}
}

@Article{	  martinet:1970,
  author =       {Martinet, B.},
  title =        {R\'egularisation d'in\'equations variationnelles par
                  approximations successives},
  journal =      {Rev. Fran¸caise Informat. Recherche Op´erationnelle},
  volume =       4,
  number =       {Ser. R-3},
  year =         1970,
  pages =        {154–158}
}

@Manual{	  math:1992,
  address =      {Natick, MA},
  author =       {MathWorks},
  date-modified ={2007-07-18 14:59:33 -0700},
  organization = {The {MathWorks}, Inc.},
  title =        {{MATLAB} User's Guide},
  year =         1992
}

@Manual{	  math:1995,
  address =      {Natick, MA},
  author =       {MathWorks},
  date-modified ={2007-07-18 14:59:33 -0700},
  organization = {The {MathWorks}, Inc.},
  title =        {{MATLAB}: External Interfaces},
  year =         1995
}

@Article{	  maynpola:1982,
  author =       {D. Q. Mayne and E. Polak},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      mathprogstudy,
  pages =        {45-61},
  title =        {A superlinearly convergent algorithm for constrained
                  optimization problems},
  volume =       16,
  year =         1982
}

@Article{	  maz93,
  author =       "Mallat, S. and Zhang, Z.",
  title =        "Matching pursuits with time-frequency dictionaries",
  journal =      "Signal Processing, IEEE Transactions",
  year =         1993,
  volume =       41,
  page =         {3397--3415}
}

@Article{	  mcco:1971,
  author =       {Garth P. McCormick},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprog,
  pages =        {217-238},
  title =        {Penalty Function Versus Non-Penalty Function Methods for
                  Constrained Nonlinear Programming Problems},
  volume =       1,
  year =         1971
}

@Book{		  mclature:1993,
  address =      {Mill Valley, CA},
  author =       {Fred W. McLafferty and Franti{\u{s}}ek Ture{\u{c}}ek},
  publisher =    {University Science Books},
  title =        {Interpretation of Mass Spectra},
  edition =      {Fourth},
  year =         1993
}

@Article{	  mendpajotomc:2007,
  author =       {S. Mendelson and A. Pajor and N. Tomczak-Jaegermann},
  title =        {Uniform uncertainty principle for {B}ernoulli and subgaussian
                  ensembles},
  journal =      {Constructive Approximation},
  note =         {To appear},
  doi =          {10.1007/s00365-007-9005-8},
  year =         2008
}

@Article{	  mgb08,
  author =       {L. Meier and S. van de Geer and P. B{\"{u}}hlmann},
  title =        {The Group {L}asso for Logistic Regression},
  journal =      {J. Royal Statist. Soc. B},
  volume =       70,
  pages =        {53--71},
  year =         2008
}

@Article{	  mif81,
  author =       "Mine, H. and Fukushima, M.",
  title =        "A minimization method for the sum of a convex function and a
                  continuously differentiable function",
  journal =      jota,
  year =         1981,
  volume =       33,
  page =         {9--23}
}

@Article{	  mill1:1970,
  author =       {Keith Miller},
  date-added =   {2007-12-13 11:48:09 -0800},
  date-modified ={2007-12-13 11:48:09 -0800},
  journal =      siammath,
  number =       1,
  pages =        {52--74},
  title =        {Least squares methods for ill-posed problems with a prescribed
                  bound},
  volume =       1,
  year =         1970
}

@Article{	  mill:1970,
  author =       {Keith Miller},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      siammath,
  number =       1,
  pages =        {52--74},
  title =        {Least squares methods for ill-posed problems with a prescribed
                  bound},
  volume =       1,
  year =         1970
}

@Misc{		  minfunc,
  author =       {M. Schmidt},
  title =        {{minFunc}: unconstrained differentiable multivariate
                  optimization in {Matlab}},
  url =          {http://www.cs.ubc.ca/~schmidtm/Software/minFunc.html},
  year =         2005
}

@Article{	  mishali2009blind,
  title =        {Blind multiband signal reconstruction: Compressed sensing for
                  analog signals},
  author =       {Mishali, Moshe and Eldar, Yonina C},
  journal =      ieeetranssigproc,
  volume =       57,
  number =       3,
  pages =        {993--1009},
  year =         2009,
  publisher =    {IEEE}
}

@Misc{		  mishyoni:2008,
  author =       {Moshe Mishali and Yonina C. Eldar},
  title =        {Reduce and Boost: Recovering Arbitrary Sets of Jointly Sparse
                  Vectors},
  url =          {http://arxiv.org/abs/0802.1311},
  howpublished = {arXiv 0802.1311},
  month =        {February},
  year =         2008
}

@Misc{		  mnist,
  author =       {Yann LeCun and Corinna Cortes},
  title =        {The {MNIST} database},
  howpublished = {\url{http://yann.lecun.com/exdb/mnist/}},
  year =         2011
}

@Article{	  moguprie:2003,
  author =       {J.M. Moguerza and F.J. Prieto},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      {Math. Program. A},
  pages =        {573-616},
  title =        {An augmented Lagrangian interior-point method using directions
                  of negative curvature},
  volume =       95,
  year =         2003
}

@Article{	  moguprie:2003b,
  author =       {J. M. Moguerza and F. J. Prieto},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      {Math. Program. A},
  pages =        {529-559},
  title =        {Combining search directions using gradient flows},
  volume =       96,
  year =         2003
}

@InProceedings{	  mohanfazel:2010,
  author =       {Mohan, K. and Fazel, M.},
  booktitle =    {American Control Conference (ACC), 2010},
  title =        {Reweighted nuclear norm minimization with application to
                  system identification},
  year =         2010,
  month =        {June},
  pages =        {2953-2959},
  keywords =     {computational complexity;convergence;gradient
                  methods;identification;matrix algebra;minimisation;NP-hard
                  problem;convergence;convex constraints;input-output
                  data;low-order system identification;matrix rank minimization
                  problem;reweighted nuclear norm minimization;reweighted trace
                  minimization;Collaboration;Compressed sensing;Control
                  systems;Convergence;Heuristic algorithms;Iterative
                  algorithms;Machine learning;Machine learning algorithms;Sparse
                  matrices;System identification},
  doi =          {10.1109/ACC.2010.5531594}
}

@InCollection{	  more:1983,
  address =      {Berlin},
  author =       {J. J. Mor\'{e}},
  booktitle =    {Mathematical Programming : The State of the Art},
  date-modified ={2007-07-18 14:59:34 -0700},
  editor =       {A. Bachem and M. Groetschel and B. Korte},
  pages =        {258-287},
  publisher =    springer,
  title =        {Recent developments in algorithms and software for trust
                  region methods},
  year =         1983
}

@Article{	  moremuns:2004,
  author =       {Jorge J. Mor\'{e} and Todd S. Munson},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      mathprog,
  pages =        {151--182},
  title =        {Computing mountain passes and transition states},
  volume =       100,
  year =         2004
}

@Article{	  moresorensen:1983,
  author =       {Jorge J. More and D. C. Sorensen},
  title =        {Computing a Trust Region Step},
  publisher =    {SIAM},
  year =         1983,
  journal =      {SIAM Journal on Scientific and Statistical Computing},
  volume =       4,
  number =       3,
  pages =        {553-572},
  keywords =     {Newton's method; trust region; ellipsoidal constraint; global
                  convergence},
  url =          {http://link.aip.org/link/?SCE/4/553/1},
  doi =          {10.1137/0904038}
}

@Article{	  moretora:1989,
  abstract =     {Presents an algorithm which combines standard active set
                  strategies with the gradient projection method for the
                  solution of quadratic programming problems subject to bounds.
                  The authors show, in particular, that if the quadratic is
                  bounded below on the feasible set then termination occurs at a
                  stationary point in a finite number of iterations. Moreover,
                  if all stationary points are nondegenerate, termination occurs
                  at a local minimizer. A numerical comparison of the algorithm
                  based on the gradient projection algorithm with a standard
                  active set strategy shows that on mildly degenerate problems
                  the gradient projection algorithm requires considerable less
                  iterations and time than the active set strategy. On
                  nondegenerate problems the number of iterations typically
                  decreases by at least a factor of 10. For strongly degenerate
                  problems, the performance of the gradient projection algorithm
                  deteriorates, but it still performs better than the active set
                  method.},
  author =       {J. J. Mor\'{e} and G. Toraldo},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      {Numerische Mathematik},
  number =       4,
  pages =        {377--400},
  title =        {Algorithms for bound constrained quadratic programming
                  problems},
  volume =       55,
  year =         1989
}

@Article{	  moretora:1991,
  author =       {J. J. Mor\'{e} and G. Toraldo},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      siamopt,
  number =       1,
  pages =        {93--113},
  title =        {On the Solution of Large Quadratic Programming Problems with
                  Bound Constraints},
  volume =       1,
  year =         1991
}

@Misc{		  mosek,
  date-added =   {2007-12-13 11:47:47 -0800},
  date-modified ={2007-12-13 11:47:47 -0800},
  howpublished = {Mathematical programming system, \url{http://www.mosek.com}},
  key =          {MOSEK},
  year =         2007
}

@Article{	  mow97,
  author =       "More, J. J. and Wu, Z.",
  title =        "Global continuation for distance geometry problems",
  journal =      siamopt,
  year =         1997,
  volume =       7,
  page =         {814--836}
}

@Article{	  mr1052832,
  author =       {Wright, S. J.},
  coden =        {JOTABN},
  date-added =   {2007-10-20 15:30:07 -0700},
  date-modified ={2007-10-20 15:30:07 -0700},
  fjournal =     {Journal of Optimization Theory and Applications},
  journal =      jota,
  mrclass =      {90C05 (90C06 90C20)},
  mrnumber =     {MR1052832 (91d:90062)},
  mrreviewer =   {Christian Michelot},
  number =       3,
  pages =        {531--554},
  title =        {Implementing proximal point methods for linear programming},
  volume =       65,
  year =         1990
}

@Article{	  mr3127080,
  author =       {Wen, Zaiwen and Yin, Wotao},
  title =        {A feasible method for optimization with orthogonality
                  constraints},
  journal =      mathprog,
  fjournal =     {Mathematical Programming. A Publication of the Mathematical
                  Programming Society},
  volume =       142,
  year =         2013,
  number =       {1-2, Ser. A},
  pages =        {397--434},
  mrclass =      {90C22 (65K10 90C27 90C30)},
  mrnumber =     3127080,
  mrreviewer =   {Roman Sznajder},
  doi =          {10.1007/s10107-012-0584-1},
  url =
                  {http://dx.doi.org.ezproxy.library.ubc.ca/10.1007/s10107-012-0584-1}
}

@InCollection{	  murr:1969,
  address =      {London and New York},
  author =       {W. Murray},
  booktitle =    {Optimization},
  date-modified ={2007-07-18 14:59:32 -0700},
  editor =       {R. Fletcher},
  publisher =    academic,
  title =        {An algorithm for constrained minimization},
  year =         1969
}

@Article{	  murr:1971,
  author =       {W. Murray},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      jota,
  pages =        {189--196},
  title =        {Analytical expressions for the eigenvalues and eigenvectors of
                  the Hessian matrices of barrier and penalty functions},
  volume =       7,
  year =         1971
}

@Article{	  murrprie:1995,
  author =       {W. Murray and F. J. Prieto},
  date-modified ={2007-10-13 17:59:03 -0700},
  journal =      siamopt,
  month =        {August},
  number =       3,
  pages =        {590--640},
  title =        {A sequential quadratic programming algorithm using an
                  incomplete solution of the subproblem},
  volume =       5,
  year =         1995
}

@Article{	  murtsaun:1978,
  author =       {B. A. Murtagh and M. A. Saunders},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprog,
  pages =        {41-72},
  title =        {Large-scale Linearly Constrained Optimization},
  volume =       14,
  year =         1978
}

@Article{	  murtsaun:1982,
  author =       {Bruce A. Murtagh and M. A. Saunders},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      mathprogstudy,
  pages =        {84-117},
  title =        {A Projected {L}agrangian Algorithm and its Implementation for
                  Sparse Nonlinear Constraints},
  volume =       16,
  year =         1982
}

@TechReport{	  murtsaun:1983,
  address =      {Department of Management Science and Engineering, Stanford
                  University, Stanford, CA},
  author =       {Bruce A. Murtagh and M. A. Saunders},
  date-modified ={2007-07-18 14:59:33 -0700},
  institution =  {Systems Optimization Laboratory},
  month =        12,
  number =       {83-20R},
  title =        {{MINOS 5.5} User's Guide},
  year =         1983
}

@Manual{	  nag:1977,
  address =      {Wilkinson House, Jordan Hill Road, Oxford, England},
  annote =       {Authors: P. E. Gill, W. Murray and S. M. Picken},
  date-modified ={2007-12-14 11:58:59 -0800},
  edition =      {Mark 6},
  note =         {{E04UAF}, {E04VAF}, {E04VBF}, {E04WAF}, constrained
                  optimization using sequential augmented {Lagrangian} methods},
  organization = {Numerical Algorithms Group Limited},
  title =        {The {NAG} {Fortran Library Manual}},
  year =         1977
}

@Book{		  nashsofe:1996,
  address =      {New York},
  author =       {Stephen G. Nash and Ariela Sofer},
  date-modified ={2007-07-18 14:59:33 -0700},
  publisher =    mcgrawhill,
  title =        {Linear and Nonlinear Programming},
  year =         1996
}

@Article{	  nata:1995,
  author =       {B. K. Natarajan},
  title =        {Sparse Approximate Solutions to Linear Systems},
  journal =      siamcomp,
  volume =       24,
  number =       2,
  year =         1995,
  month =        {April},
  pages =        {227--234},
  keywords =     {Sparse solutions, linear systems},
  summary =      {The suggested algorithm takes as input $A$, $b$, and
                  $\epsilon$. The algorithm first normalizes each column $a_i$
                  of $A$. Then, at each iteration of the selection phase, the
                  algorithm greedily picks that column of $A$ that is closest in
                  angle to the vector $b$. Then, $b$ and the column vectors of
                  $A$ are projected onto the subspace orthogonal to the chosen
                  column. This procedure is repeated until $\Vert b\Vert_2 \leq
                  \epsilon$. In the solution phase, the algorithm solves the
                  linear system problem $Bx = b^{(0)} - b^{(r)}$ where $B$ is
                  the matrix consisting of those columns of $A$ that were chosen
                  in the selection phase, $b^{(0)}$ is $b$ at the start of the
                  selection phase, and $b^{(r)}$ is $b$ at the end of the
                  selection phase.},
  abstract =     {The following problem is considered: given a matrix $A$ in
                  $\mathbb{R}^{m\times n}$, ($m$ rows and $n$ columns), a vector
                  $b$ in $\mathbb{R}^m$, and $\epsilon > 0$, compute a vector
                  $x$ satisfying $\Vert Ax-b\Vert_2 \leq \epsilon$ if such
                  exists, such that $x$ has the fewest number of non-zero
                  entries over all such vectors. It is shown that the problem is
                  NP-hard, but that the well-known greedy heuristic is good in
                  that it computes a solution with at most $\lceil
                  18\mathrm{Opt}(\epsilon/2) \Vert\mathbf{A}^+\Vert_2^2
                  \ln(\Vert b\Vert_2/\epsilon)\rceil$ non zero entries, where
                  $\mathrm{Opt}(\epsilon/2)$ is the optimum number of nonzero
                  entries at error $\epsilon/2$. $\mathbf{A}$ is the matrix
                  obtained by normalizing each column of $A$ with respect to the
                  $L_2$ norm, and $\mathbf{A}^+$ is its peudo-inverse}
}

@Article{	  neb01,
  author =       "Nedi\'c, A. and Bertsekas, D. P.",
  title =        "Incremental subgradient methods for nondifferentiable
                  optimization",
  journal =      siamopt,
  year =         2001,
  volume =       12,
  page =         {109--138}
}

@Article{	  nedber:2000,
  title =        {{Convergence rate of incremental subgradient algorithms}},
  author =       {Nedic, A. and Bertsekas, D.},
  journal =      {Stochastic Optimization: Algorithms and Applications},
  pages =        {263--304},
  year =         2000,
  publisher =    {Kluwer Academic Pub}
}

@Unpublished{	  needtrop:2008,
  title =        {{CoSaMP}: Iterative signal recovery from incomplete and
                  inaccurate samples},
  author =       {D. Needell and J. A. Tropp},
  month =        {June},
  year =         2008,
  note =         {To appear in {\it Appl. Comp. Harmonic Anal.}}
}

@InProceedings{	  needvers:2008,
  author =       {{Needell}, D. and {Vershynin}, R.},
  title =        "{Greedy signal recovery and uncertainty principles}",
  booktitle =    {Society of Photo-Optical Instrumentation Engineers (SPIE)
                  Conference Series},
  year =         2008,
  series =       {Society of Photo-Optical Instrumentation Engineers (SPIE)
                  Conference Series},
  volume =       6814,
  month =        mar,
  doi =          {10.1117/12.776996},
  adsurl =       {http://adsabs.harvard.edu/abs/2008SPIE.6814E..13N},
  adsnote =      {Provided by the SAO/NASA Astrophysics Data System}
}

@article{negahban2012restricted,
  title =        {Restricted strong convexity and weighted matrix completion:
                  Optimal bounds with noise},
  author =       {Negahban, Sahand and Wainwright, Martin J},
  journal =      jmlr,
  volume =       13,
  number =       {May},
  pages =        {1665--1697},
  year =         2012
}

@Article{	  nem05,
  author =       "Nemirovski, A.",
  title =        "Prox-Method with Rate of Convergence $O(1/t)$ for Variational
                  Inequalities with Lipschitz Continuous Monotone Operators and
                  Smooth Convex-Concave Saddle Point Problems",
  journal =      siamopt,
  year =         2005,
  volume =       15,
  page =         {229--251}
}

@Article{	  nemirovski1994efficient,
  title =        {{Efficient methods in convex programming}},
  author =       {Nemirovski, A.},
  journal =      {Lecture notes},
  year =         1994
}

@Article{	  nemirovski2009robust,
  title =        {Robust stochastic approximation approach to stochastic
                  programming},
  author =       {Nemirovski, A. and Juditsky, A. and Lan, G. and Shapiro, A.},
  journal =      siamopt,
  volume =       19,
  number =       4,
  pages =        {1574--1609},
  year =         2009,
  publisher =    {Society for Industrial and Applied Mathematics}
}

@book{nemirovsky1983problem,
  title =        {Problem complexity and method efficiency in optimization},
  author =       {Nemirovsky, Arkadii Semenovich and Yudin, David Borisovich},
  year =         1983,
  publisher =    {Wiley},
  address =      {New York}
}

@Book{		  nen94,
  address =      {Philadelphia},
  author =       {Y. E. Nesterov and A. Nemirovski},
  date-modified ={2007-07-18 14:59:33 -0700},
  publisher =    siampub,
  series =       {Stud. Appl. Math.},
  title =        {Interior-Point Polynomial Algorithms in Convex Programming},
  volume =       13,
  year =         1994
}

@TechReport{	  nes04a,
  author =       "Nesterov, Y.",
  title =        "Smoothing technique and its applications in semidefinite
                  optimization",
  institution =  "CORE, Catholic University of Louvain, Louvain-la-Neuve",
  address =      "Belgium",
  year =         2004,
  month =        "October"
}

@Book{		  nes04b,
  author =       "Nesterov, Y.",
  title =        "Introductory Lectures on Convex Optimization",
  publisher =    "Kluwer Academic",
  year =         2004,
  address =      "Dordrecht, The Netherlands"
}

@Article{	  nes05a,
  author =       "Nesterov, Y.",
  title =        "Smooth minimization of nonsmooth functions",
  journal =      mathprog,
  year =         2005,
  volume =       103,
  page =         {127--152}
}

@Article{	  nes05b,
  author =       "Nesterov, Y.",
  title =        "Excessive gap technique in nonsmooth convex minimization",
  journal =      siamopt,
  year =         2005,
  volume =       16,
  page =         {235--249}
}

@TechReport{	  nes07,
  title =        {Gradient methods for minimizing composite objective function},
  author =       {Nesterov, Y.},
  institution =  {Center for Operations Research and Econometrics (CORE),
                  Catholic University of Louvain},
  type =         {Tech. Rep.},
  volume =       76,
  year =         2007
}

@Article{	  nes07a,
  author =       "Nesterov, Y.",
  title =        "Dual extrapolation and its applications to solving variational
                  inequalities and related problems",
  journal =      "Math. Program.",
  year =         2007,
  volume =       109,
  page =         {319-344}
}

@TechReport{	  nes07b,
  author =       "Nesterov, Y.",
  title =        "Gradient methods for minimizing composite objective function",
  institution =  "CORE, Catholic University of Louvain",
  address =      "Louvain-la-Neuve, Belgium",
  year =         2007,
  month =        "September"
}

@Article{	  nes88,
  author =       "Nesterov, Y.",
  title =        "On an approach to the construction of optimal methods of
                  minimization of smooth convex functions",
  journal =      "Ekonom. i. Mat. Metody ",
  year =         1988,
  volume =       24,
  page =         {509--517}
}

@Article{	  nes:1983,
  author =       "Nesterov, Y.",
  title =        "A method for unconstrained convex minimization problem with
                  the rate of convergence {$O(1/k^2)$}",
  journal =      "Soviet Math. Dokl.",
  year =         1983,
  volume =       269,
  page =         {543--547}
}

@article{nesterov2009primal,
  title =        {Primal-dual subgradient methods for convex problems},
  author =       {Nesterov, Yurii},
  journal =      {Mathematical programming},
  volume =       120,
  number =       1,
  pages =        {221--259},
  year =         2009,
  publisher =    {Springer}
}

@Article{	  nesterov2009unconstrained,
  title =        {Unconstrained convex minimization in relative scale},
  author =       {Nesterov, Yurii},
  journal =      mathofor,
  volume =       34,
  number =       1,
  pages =        {180--193},
  year =         2009,
  publisher =    {INFORMS}
}

@techreport{nesterov2015complexity,
  title =        {Complexity bounds for primal-dual methods minimizing the model
                  of objective function},
  author =       {Nesterov, Yurii},
  year =         2015,
  month =        feb,
  institution =  {Center for Operations Research and Econometrics}
}

@Article{	  nesterov:2005,
  author =       {Y. Nesterov},
  title =        {Smooth minimization of non-smooth functions},
  journal =      mathprog,
  year =         2005,
  volume =       103,
  pages =        {127-152}
}

@Article{	  nestnemi:1992,
  author =       {Yu. E. Nesterov and A. S. Nemirovski},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      optimmeth,
  pages =        {95--115},
  title =        {Conic formulation of a convex programming problem and duality},
  volume =       1,
  year =         1992
}

@Misc{		  netlib:2006,
  date-modified ={2007-12-14 11:59:07 -0800},
  key =          {Netlib},
  title =        {{NETLIB} Linear Programming Library},
  url =          {\url{http://www.netlib.org/lp/infeas/}},
  year =         2006
}

@Book{		  ney83,
  author =       "Nemirovski, A. and Yudin, D.",
  title =        "Problem Complexity and Method Efficiency in Optimization",
  publisher =    "Wiley",
  year =         1983,
  address =      "New York"
}

@TechReport{	  nie06,
  author =       "Nie, J.",
  title =        "Sum of squares method for sensor network localization",
  institution =  "Department of Mathematics, University of California",
  address =      "Berkeley",
  year =         2006,
  month =        "June",
  note =         "to appear in Comput. Optim. Appl."
}

@InCollection{	  nips2012_4523,
  title =        {A quasi-{Newton} proximal splitting method},
  author =       {Becker, Stephen and Fadili, Jalal},
  booktitle =    {Advances in Neural Information Processing Systems 25},
  editor =       {F. Pereira and C.J.C. Burges and L. Bottou and K.Q.
                  Weinberger},
  pages =        {2618--2626},
  year =         2012,
  publisher =    {Curran Associates, Inc.},
  url =
                  {http://papers.nips.cc/paper/4523-a-quasi-newton-proximal-splitting-method.pdf}
}

@InProceedings{	  nips2012_4797,
  title =        {Stochastic Gradient Descent with Only One Projection},
  author =       {Mahdavi, Mehrdad and Yang, Tianbao and Jin, Rong and Shenghuo
                  Zhu and Jinfeng Yi},
  booktitle =    {Advances in Neural Information Processing Systems 25},
  editor =       {F. Pereira and C.J.C. Burges and L. Bottou and K.Q.
                  Weinberger},
  pages =        {494--502},
  year =         2012,
  url =
                  {http://papers.nips.cc/paper/4797-stochastic-gradient-descent-with-only-one-projection.pdf}
}

@InCollection{	  nips2013_4936,
  author =       {Ke Hou and Zirui Zhou and Anthony Man-Cho So and Zhi-Quan Luo},
  booktitle =    {Advances in Neural Information Processing Systems 26},
  pages =        {710--718},
  title =        {On the Linear Convergence of the Proximal Gradient Method for
                  Trace Norm Regularization},
  url =
                  {http://media.nips.cc/nipsbooks/nipspapers/paper_files/nips26/417.pdf},
  year =         2013,
  bdsk-url-1 =
                  {http://media.nips.cc/nipsbooks/nipspapers/paper_files/nips26/417.pdf}
}

@InProceedings{	  nips2013_5041,
  author =       {Netrapalli, Praneeth and Jain, Prateek and Sanghavi, Sujay},
  booktitle =    {Advances in Neural Information Processing Systems 26},
  editor =       {C.J.C. Burges and L. Bottou and M. Welling and Z. Ghahramani
                  and K.Q. Weinberger},
  pages =        {2796--2804},
  publisher =    {Curran Associates, Inc.},
  title =        {Phase Retrieval using Alternating Minimization},
  year =         2013,
  url =          {http://papers.nips.cc/paper/5041-pha}
}

@InCollection{	  nips2014_5384,
  title =        {Proximal Quasi-{Newton} for Computationally Intensive
                  L1-regularized M-estimators},
  author =       {Zhong, Kai and Yen, En-Hsu and Dhillon, Inderjit S and
                  Ravikumar, Pradeep K},
  booktitle =    {Advances in Neural Information Processing Systems 27},
  editor =       {Z. Ghahramani and M. Welling and C. Cortes and N.D. Lawrence
                  and K.Q. Weinberger},
  pages =        {2375--2383},
  year =         2014,
  publisher =    {Curran Associates, Inc.},
  url =
                  {http://papers.nips.cc/paper/5384-proximal-quasi-newton-for-computationally-intensive-l1-regularized-m-estimators.pdf}
}

@Misc{		  nist:chemwebbook,
  author =       {{National Institute of Standards and Technology}},
  title =        {{NIST Chemistry WebBook}},
  howpublished = {\url{http://webbook.nist.gov/chemistry/}},
  url =          {http://webbook.nist.gov/chemistry/},
  year =         2009
}

@Book{		  nocedal1999,
  author =       "Nocedal, J. and Wright S. J.",
  title =        "Numerical Optimization",
  publisher =    "Springer-Verlag",
  year =         1999,
  address =      "New York"
}

@Book{		  nocewrig:2006,
  address =      {New York},
  author =       {J. Nocedal and S. J. Wright},
  edition =      {Second},
  publisher =    {Springer},
  title =        {Numerical Optimization},
  year =         2006
}

@Book{		  now99,
  address =      {New York},
  author =       {Jorge Nocedal and Stephen J. Wright},
  publisher =    {Springer},
  title =        {Numerical Optimization},
  year =         1999
}

@Article{	  obgx05,
  author =       "Osher, S. and Burger, M. and Goldfarb, D. and Xu. J.",
  title =        "An iterative regularization method for total variation-based
                  image restoration",
  journal =      siammms,
  year =         2005,
  volume =       4,
  page =         {460--489}
}

@Article{	  olivsore:2005,
  author =       {A.R.L. Oliveira and D.C. Sorensen},
  title =        {A new class of preconditioners for large-scale linear systems
                  from interior point methods for linear programming},
  journal =      linalgapp,
  year =         2005,
  volume =       394,
  pages =        {1--24}
}

@Book{		  orr70,
  address =      {London},
  author =       {J. M. Ortega and W. C. Rheinboldt},
  date-modified ={2007-07-18 14:59:33 -0700},
  publisher =    academic,
  title =        {Iterative Solutions of Nonlinear Equations in Several
                  Variables},
  year =         1970
}

@Book{		  ortega2000,
  author =       "Ortega, J. M. and Rheinboldt, W. C.",
  title =        "Iterative Solution of Nonlinear Equations in Several
                  Variables",
  publisher =    "SIAM",
  year =         2000,
  address =      "Philadelphia"
}

@Article{	  osbopresturl:2000a,
  author =       {M. R. Osborne and Brett Presnell and B. A. Turlach},
  date-modified ={2007-09-14 11:00:08 -0700},
  journal =      imanumerana,
  keywords =     {L1},
  local-url =    {file://localhost/Users/mpf/papers/OsboPresTurl00.pdf},
  number =       3,
  pages =        {389--403},
  title =        {A new approach to variable selection in least squares
                  problems},
  volume =       20,
  year =         2000
}

@Article{	  osbopresturl:2000b,
  author =       {M. R. Osborne and B. Presnell and B. A. Turlach},
  date-modified ={2007-09-14 11:00:11 -0700},
  journal =      {J. of Comput. Graph. Statist.},
  keywords =     {L1},
  local-url =    {file://localhost/Users/mpf/papers/OsboPresnTurl99.pdf},
  pages =        {319--337},
  title =        {On the {LASSO} and its dual},
  volume =       9,
  year =         2000
}

@Article{	  osborne1992fisher,
  title =        {Fisher's method of scoring},
  author =       {Osborne, M.R.},
  journal =      {Intern.\@ Stat.\@ Rev.},
  pages =        {99--117},
  year =         1992
}

@Article{	  osborne:1982,
  title =        {A Finite Algorithm for the Rank Regression Problem},
  author =       {Osborne, M. R.},
  journal =      {J. Appl. Prob.},
  volume =       19,
  pages =        {241-252},
  abstract =     {A new approach to the minimization of polyhedral convex
                  functions is applied to give a finite algorithm for the rank
                  regression problem. Numerical results for the Daniel and Wood
                  example are presented.},
  year =         1982,
  publisher =    {Applied Probability Trust}
}

@Misc{		  osborne:2003,
  title =        {{When LP is not a good idea--using structure in polyhedral
                  optimization problems}},
  author =       {Osborne, M. R. },
  year =         2003
}

@Article{	  otj09,
  author =       "G. Obozinski and B. Taskar and M. I. Jordan",
  title =        "Joint covariate selection and joint subspace selection for
                  multiple classification problems",
  journal =      "Stat. Comput.",
  year =         2009
}

@Book{		  outrkocvzowe:1998,
  address =      {Dordrecht, The Netherlands},
  author =       {J. Outrata and M. Kocvara and J. Zowe},
  date-modified ={2007-07-18 14:59:33 -0700},
  publisher =    {Kluwer Academic},
  title =        {Nonsmooth approach to optimization problems with equilibrium
                  constraints: {T}heory, applications, and numerical results},
  year =         1998
}

@InProceedings{	  ouyanggray:2012,
  title =        {Stochastic Smoothing for Nonsmooth Minimizations: Accelerating
                  {SGD} by Exploiting Structure},
  author =       {H. Ouyang and A. Gray},
  booktitle =    {Proc. 29th Intern. Conf. Machine Learning (ICML-12)},
  year =         2012
}

@article{oymak2017universality,
  title =        {Universality laws for randomized dimension reduction, with
                  applications},
  author =       {Oymak, Samet and Tropp, Joel A},
  journal =      imainfoinfer,
  volume =       7,
  number =       3,
  pages =        {337--446},
  year =         2017,
  publisher =    {Oxford University Press}
}

@Article{	  paattapp:1994,
  author =       {P. Paatero and U. Tapper},
  date-added =   {2007-10-20 15:30:26 -0700},
  date-modified ={2007-10-20 15:30:30 -0700},
  journal =      {Envirometrics},
  pages =        {111--126},
  title =        {Positive matrix factorization: A non-negative factor model
                  with optimal utilization of error},
  volume =       5,
  year =         1994
}

@InProceedings{	  pacheco2012minimization,
  title =        {Minimization of Continuous Bethe Approximations: A Positive
                  Variation},
  author =       {Pacheco, Jason and Sudderth, Erik B},
  booktitle =    {Advances in Neural Information Processing Systems},
  pages =        {2573--2581},
  year =         2012
}

@Article{	  pah07,
  author =       "Park, M.-Y. and Hastie, T.",
  title =        "An {L1} regularization-path algorithm for generalized linear
                  models",
  journal =      "J. Roy. Soc. Stat. B",
  year =         2007,
  volume =       69,
  page =         {659--677}
}

@article{paigesaun:1975,
  title =        {Solution of sparse indefinite systems of linear equations},
  author =       {Paige, Christopher C and Saunders, Michael A},
  journal =      siamnumanal,
  volume =       12,
  number =       4,
  pages =        {617--629},
  year =         1975,
  publisher =    {SIAM}
}

@Article{	  paigsaun:1982,
  author =       {C. C. Paige and M. A. Saunders},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      acmmathsoft,
  pages =        {43--71},
  title =        {{LSQR}: An Algorithm for Sparse Linear Equations and Sparse
                  Least Squares},
  volume =       8,
  year =         1982
}

@Article{	  palalasdengq:1982,
  author =       {F. Palacios-Gomez and L. Lasdon and E. Engquist},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      managesci,
  month =        {October},
  number =       10,
  pages =        {1106--1120},
  title =        {Nonlinear optimization by successive linear programming},
  volume =       28,
  year =         1982
}

@Article{	  pan87,
  author =       "Pang, J.-S.",
  title =        "A posteriori error bounds for the linearly constrained
                  variational inequality problem",
  journal =      "Math. Oper. Res.",
  year =         1987,
  volume =       12,
  page =         {474--484}
}

@Article{	  pan:2005,
  author =       {Ping-Qi Pan},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      siamopt,
  number =       1,
  pages =        {49-68},
  publisher =    {SIAM},
  title =        {A Revised Dual Projective Pivot Algorithm for Linear
                  Programming},
  volume =       16,
  year =         2005
}

@Article{	  parikh2013proximal,
  title =        {Proximal algorithms},
  author =       {Parikh, Neal and Boyd, Stephen},
  journal =      {Foundations and Trends in Optimization},
  volume =       1,
  number =       3,
  pages =        {123--231},
  year =         2013
}

@TechReport{	  pataschm:2002,
  author =       {G. Pataki and S. Schmieta},
  date-modified ={2007-07-18 14:59:34 -0700},
  institution =  {Computational Optimization Research Center, Columbia
                  University, New York},
  number =       {Preliminary draft},
  title =        {The {DIMACS} library of semidefinite-quadratic-linear
                  programs},
  year =         {July 2002}
}

@InProceedings{	  patirezakris:1993,
  abstract =     {In this paper we describe a recursive algorithm to compute
                  representations of functions with respect to nonorthogonal and
                  possibly overcomplete dictionaries of elementary building
                  blocks e.g. affine (wavelet) frames. We propose a modification
                  to the Matching Pursuit algorithm of Mallat and Zhang (1992)
                  that maintains full backward orthogonality of the residual
                  (error) at every step and thereby leads to improved
                  convergence. We refer to this modified algorithm as Orthogonal
                  Matching Pursuit (OMP). It is shown that all additional
                  computation required for the OMP algorithm may be performed
                  recursively.},
  author =       {Y. C. Pati and R. Rezaiifar and P. S. Krishnaprasad},
  booktitle =    {Proceedings of the 27th Annual Asilomar Conference on Signals,
                  Systems and Computers},
  month =        {Nov.},
  pages =        {40--44},
  title =        {Orthogonal Matching Pursuit: Recursive Function Approximation
                  with Applications to Wavelet Decomposition},
  volume =       1,
  year =         1993
}

@Article{	  pere:1967,
  author =       {Victor Pereyra},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      siamnumanal,
  pages =        {508--533},
  title =        {Accelerating the Convergence of Discretization Algorithms},
  volume =       4,
  year =         1967
}

@Article{	  piet:1969,
  author =       {T. Pietrzykowski},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamnumanal,
  pages =        {262--304},
  title =        {An exact potential method for constrained maxima},
  volume =       6,
  year =         1969
}

@InCollection{	  pillogrippo:1984,
  author =       {G. Di Pillo and L. Grippo},
  title =        {A class of continuously differentiable exact penalty function
                  algorithms for nonlinear programming problems},
  booktitle =    {System Modelling and Optimization},
  editor =       {E. P. Toft-Christensen},
  publisher =    {Springer-Verlag},
  address =      {Berlin},
  year =         1984,
  pages =        {246–256}
}

@InCollection{	  pla98,
  author =       {J. Platt},
  title =        {Fast training of support vector machines using sequential
                  minimal optimization},
  booktitle =    {Advances in Kernel Methods: Support Vector Learning},
  year =         1998,
  publisher =    {MIT Press},
  address =      {Cambridge, MA, USA}
}

@InCollection{	  plumbley:2006,
  author =       {Mark D. Plumbley},
  title =        {Recovery of Sparse Representations by Polytope Faces Pursuit},
  booktitle =    {Independent Component Analysis and Blind Signal Separation},
  pages =        {206-213},
  publisher =    {Springer},
  year =         2006,
  volume =       {3889/2006},
  series =       {Lecture Notes in Computer Science},
  address =      {Berlin},
  doi =          {10.1007/11679363}
}

@Article{	  pola:1976,
  author =       {Elijah Polak},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      {Automica},
  pages =        {337-342},
  title =        {On the global stabalization of locally convergent algorithms
                  for optimization and root finding},
  volume =       12,
  year =         1976
}

@Book{		  pola:1991,
  address =      {New York},
  author =       {Elijah Polak},
  date-modified ={2007-07-18 14:59:33 -0700},
  editor =       {J. E. Marsden and L. Sirovich},
  number =       124,
  publisher =    springer,
  series =       {Applied Mathematical Sciences},
  title =        {Optimization: {A}lgorithms and Consistent Approximations},
  year =         1991
}

@Article{	  polyak1973method,
  title =        {The method of penalty bounds for constrained extremum
                  problems},
  author =       {Polyak, BT and Tretyakov, NV},
  journal =      {Zh. Vych. Mat i Mat. Fiz},
  volume =       13,
  pages =        {34--46},
  year =         1973
}

@Book{		  polyak1987introduction,
  author =       {Polyak, B. T.},
  title =        {Introduction to optimization},
  publisher =    {Optimization Software},
  year =         1987,
  address =      {New York}
}

@article{polyak:1974,
  title =        {The method of penalty estimates for conditional extremum
                  problems},
  author =       {Polyak, V. T. and Tret'yakov, N. V.},
  journal =      {USSR Computational Mathematics and Mathematical Physics},
  volume =       13,
  number =       1,
  pages =        {42--58},
  year =         1974,
  publisher =    {Elsevier}
}

@TechReport{	  pot09,
  author =       "Pong, T. K. and Tseng, P.",
  title =        "(Robust) edge-based semidefinite programming relaxation of
                  sensor network localization",
  institution =  "Department of Mathematics, University of Washington",
  address =      "Seattle",
  year =         2009,
  month =        "January"
}

@InCollection{	  powe:1969,
  address =      {London and New York},
  author =       {M. J. D. Powell},
  booktitle =    {Optimization},
  chapter =      19,
  date-modified ={2007-07-18 14:59:31 -0700},
  editor =       {R. Fletcher},
  publisher =    academic,
  title =        {A method for nonlinear constraints in minimization problems},
  year =         1969
}

@Article{	  prt08,
  author =       "Pfander, G. B. and Rauhut, H. and Tanner, J.",
  title =        "Identification of Matrices Having a Sparse Representation",
  journal =      "IEEE Trans. Signal Proc.",
  year =         2008,
  volume =       56,
  page =         {5376--5388}
}

@Article{	  pshe:1970,
  author =       {Borris N. Pshenichnyj},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      {Mathematical notes of the Academy of Sciences of the USSR},
  note =         {[English translation]; Original Russian: Matematicheskie
                  Zametki, 8 (1970), pp.~635--640. (Note that the authors name
                  is transliterated as Pshenichnyi)},
  pages =        {827-830},
  title =        {{N}ewton's {M}ethod for the solution of systems of equalities
                  and inequalities},
  volume =       8,
  year =         1970
}

@Book{		  pshe:1994,
  address =      {Berlin},
  annote =       {Stephen S. Wilson},
  author =       {Borris N. Pshenichnyj},
  date-modified ={2007-07-18 14:59:34 -0700},
  publisher =    springer,
  title =        {The Linearization Method for Constrained Optimization},
  year =         1994
}

@TechReport{	  raghbieg:2003,
  author =       {Arvind U. Raghunathan and Lorenz T. Biegler},
  date-modified ={2007-07-18 14:59:33 -0700},
  institution =  {Carnegie Mellon University, Department of Chemical
                  Engineering},
  title =        {Interior point methods for mathematical programs with
                  complementarity constraints},
  year =         2003
}

@Article{	  ralpwrig:2000,
  author =       {Danny Ralph and Stephen J. Wright},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      mathofor,
  pages =        {179--194},
  title =        {Superlinear convergence of an interior-point method despite
                  dependent constraints},
  volume =       25,
  year =         2000
}

@TechReport{	  ralpwrig:2003,
  author =       {Danny Ralph and Stephen J. Wright},
  date-modified ={2007-07-18 14:59:34 -0700},
  institution =  {Computer Sciences, University of Wisconsin},
  month =        {December},
  number =       {03-04},
  title =        {Some properties of regularization schemes for {MPEC}s},
  year =         2003
}

@article{rao2015forward,
  title =        {Forward--backward greedy algorithms for atomic norm
                  regularization},
  author =       {Rao, Nikhil and Shah, Parikshit and Wright, Stephen},
  journal =      ieeetranssigproc,
  volume =       63,
  number =       21,
  pages =        {5798--5811},
  year =         2015,
  publisher =    {IEEE}
}

@Article{	  raoengacottpalmkreu:2003,
  abstract =     {We develop robust methods for subset selection based on the
                  minimization of diversity measures. A Bayesian framework is
                  used to account for noise in the data and a maximum a
                  posteriori (MAP) estimation procedure leads to an iterative
                  procedure which is a regularized version of the focal
                  underdetermined system solver (FOCUSS) algorithm. The
                  convergence of the regularized FOCUSS algorithm is established
                  and it is shown that the stable fixed points of the algorithm
                  are sparse. We investigate three different criteria for
                  choosing the regularization parameter: quality of fit;
                  sparsity criterion; L-curve. The L-curve method, as applied to
                  the problem of subset selection, is found not to be robust,
                  and we propose a novel modified L-curve procedure that solves
                  this problem. Each of the regularized FOCUSS algorithms is
                  evaluated through simulation of a detection problem, and the
                  results are compared with those obtained using a sequential
                  forward selection algorithm termed orthogonal matching pursuit
                  (OMP). In each case, the regularized FOCUSS algorithm is shown
                  to be superior to the OMP in noisy environments. },
  author =       {Bhaskar D. Rao and Kjersti Engan and Shane F. Cotter and Jason
                  Palmer and Kenneth Kreutz-Delgado},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      ieeetranssigproc,
  keywords =     {Diversity measures, linear inverse problems, matching pursuit,
                  regularization, sparsity, subset selection, undetermined
                  systems},
  month =        {March},
  number =       3,
  pages =        {760--770},
  title =        {Subset selection in noise based on diversity measure
                  minimization},
  volume =       51,
  year =         2003
}

@InProceedings{	  raokreu:1998,
  abstract =     {We consider procedures to enhance the reliability of basis
                  selection procedures with particular attention being given to
                  methods based on minimizing diversity measures. To deal with
                  noise in the data, basis selection procedures based on a
                  Bayesian framework are considered. An algorithm based on the
                  MAP estimation procedure is developed which leads to a
                  regularized version of the FOCUSS algorithm. Another approach
                  considered is to select basis vectors over multiple
                  measurement vectors thereby achieving an averaging effect and
                  enhancing the reliability. New diversity measures are
                  presented for this purpose, and algorithms are derived for
                  minimizing them },
  address =      {Pacific Grove, CA, USA},
  author =       {Bhaskar D. Rao and Kenneth Kreutz-Delgado},
  booktitle =    {Conference Record of Thirty-Second Asilomar Conference on
                  Signals, Systems and Computers},
  date-modified ={2007-07-18 14:59:32 -0700},
  month =        {November},
  pages =        {752--756},
  publisher =    {IEEE},
  title =        {Basis selection in the presence of noise},
  volume =       1,
  year =         1998
}

@Article{recht2010guaranteed,
  title =        {Guaranteed Minimum-Rank Solutions of Linear Matrix Equations
                  via Nuclear Norm Minimization},
  year =         2010,
  journal =      siamreview,
  volume =       52,
  number =       3,
  pages =        {471-501},
  author =       {Benjamin Recht and Maryam Fazel and Pablo A. Parrilo},
  keywords =     {rank; convex optimization; matrix norms; random matrices;
                  compressed sensing; semidefinite programming; 90C25; 90C59;
                  15A52; }
}

@InProceedings{	  rechxuhass:2008,
  author =       {Benjamin Recht and Weiyu Xu and Babak Hassibi},
  title =        {Necessary and sufficient conditions for success of the nuclear
                  norm heuristic for rank minimization},
  booktitle =    {47th IEEE Conference on Decision and Control},
  pages =        {3065--3070},
  publisher =    {IEEE},
  month =        {December},
  year =         2008
}

@Book{		  rene:2001,
  address =      {Philadelphia},
  author =       {J. Renegar},
  date-modified ={2007-07-18 14:59:31 -0700},
  publisher =    siampub,
  series =       {MPS/SIAM Series on Optimization},
  title =        {A Mathematical View of Interior-Point Methods in Convex
                  Optimization},
  year =         2001
}

@Misc{		  rfp07,
  author =       {Benjamin Recht and Maryam Fazel and Pablo A. Parrilo},
  title =        {Guaranteed minimum-rank solutions of linear matrix equations
                  via nuclear norm minimization},
  url =          {http://arxiv.org/abs/0706.4138},
  howpublished = {arXiv 0706.4138},
  month =        {June},
  year =         2007
}

@Article{	  richtarik2011improved,
  title =        {Improved algorithms for convex minimization in relative scale},
  author =       {Richt{\'a}rik, Peter},
  journal =      siamopt,
  volume =       21,
  number =       3,
  pages =        {1141--1167},
  year =         2011,
  publisher =    {SIAM}
}

@Article{	  robi:1971,
  author =       {Stephen M. Robinson},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      numermath,
  pages =        {341-347},
  title =        {Extension of {N}ewton's {M}ethod to nonlinear functions with
                  values in a cone},
  volume =       19,
  year =         1971
}

@Article{	  robi:1972,
  author =       {Stephen M. Robinson},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      mathprog,
  pages =        {145-156},
  title =        {A Quadratically-Convergent Algorithm for General Nonlinear
                  Programming Problems},
  volume =       3,
  year =         1972
}

@Article{	  robi:1974,
  author =       {Stephen M. Robinson},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprog,
  pages =        {1-16},
  title =        {Perturbed {K}uhn-{T}ucker Points and Rates of Convergence for
                  a Class of Nonlinear-Programming Algorithms},
  volume =       7,
  year =         1974
}

@Article{	  robi:1984,
  author =       {Stephen M. Robinson},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprogstudy,
  pages =        {217-230},
  title =        {Local structure of feasible sets in nonlinear programming,
                  Part {II}: Nondegeneracy},
  volume =       22,
  year =         1984
}

@PhDThesis{	  robi:2007,
  abstract =     {Nonlinearly constrained optimization problems may be solved by
                  minimizing a se- quence of simpler subproblems based on the
                  properties of a so-called \emph{merit function} that balances
                  the (usually) conflicting aims of reducing the ob jective
                  function and satisfying the constraints. Sometimes this merit
                  function is minimized directly as an unconstrained function,
                  in which case convergence is achieved by adjusting the
                  relative weighting of the ob jective and constraints between
                  subproblems. Alter- natively, some model of the merit function
                  is minimized sub ject to simple bounds and/or linearizations
                  of the constraints. In this case, the merit function drives
                  the algorithm by assessing the ``quality'' of points generated
                  by the subproblem. A new primal-dual augmented Lagrangian
                  merit function is proposed that may be minimized with respect
                  to both the primal \emph{and} dual variables. A benefit of
                  this approach is that each subproblem may be regularized by
                  imposing explicit bounds on the dual variables. Two
                  primal-dual variants of classical primal methods are given: a
                  primal-dual bound constrained Lagrangian (pdBCL) method and a
                  primal-dual l1 linearly constrained Lagrangian (pd$\ell1$-LCL)
                  method. },
  author =       {D. P. Robinson},
  date-added =   {2007-10-13 18:02:27 -0700},
  date-modified ={2007-10-13 18:04:05 -0700},
  local-url =    {file://localhost/Users/mpf/papers/Robinson07.pdf},
  school =       {University of California, San Diego},
  title =        {Primal-dual methods for nonlinear optimization},
  year =         2007
}

@PhDThesis{	  robinson:2007,
  author =       {Daniel Robinson},
  title =        {Primal Dual Methods for Nonlinear Optimization},
  school =       {University of California, San Diego},
  year =         2007,
  month =        {September}
}

@Book{		  rockafellar1970convex,
  address =      {Princeton},
  author =       {R. T. Rockafellar},
  publisher =    {Princeton University Press},
  title =        {Convex Analysis},
  year =         1970
}

@Book{		  rockafellar1974conjugate,
  author =       "Rockafellar. R. T.",
  title =        "Conjugate Duality and Optimization",
  publisher =    "Society for Industrial and Applied Mathematics",
  year =         1974,
  address =      "Philadelphia"
}

@Article{	  rockafellar1976augmented,
  author =       {R. T. Rockafellar},
  title =        {Augmented {L}agrangians and applications of the Proximal Point
                  Algorithm in convex programming},
  journal =      {Mathematics of Operations Research},
  volume =       1,
  number =       2,
  pages =        {97--116},
  year =         1976
}

@Book{		  rockafellar1998variational,
  author =       {R. T. Rockafellar and R. J. B. Wets},
  publisher =    {Springer},
  title =        {Variational Analysis},
  volume =       317,
  year =         1998,
  note =         {3rd printing}
}

@Article{	  rockafellar:1990,
  author =       {R. T. Rockafellar},
  title =        {Computational schemes for large-scale problems in extended
                  linear-quadratic programming},
  journal =      mathprog,
  year =         1990,
  pages =        {447--474}
}

@Article{	  rockafellar:1993,
  title =        {Lagrange Multipliers and Optimality},
  author =       {Rockafellar, R. T.},
  journal =      siamreview,
  volume =       35,
  number =       2,
  pages =        {pp. 183-238},
  url =          {http://www.jstor.org/stable/2133143},
  abstract =     {Lagrange multipliers used to be viewed as auxiliary variables
                  introduced in a problem of constrained minimization in order
                  to write first-order optimality conditions formally as a
                  system of equations. Modern applications, with their emphasis
                  on numerical methods and more complicated side conditions than
                  equations, have demanded deeper understanding of the concept
                  and how it fits into a larger theoretical picture. A major
                  line of research has been the nonsmooth geometry of one-sided
                  tangent and normal vectors to the set of points satisfying the
                  given constraints. Another has been the game-theoretic role of
                  multiplier vectors as solutions to a dual problem.
                  Interpretations as generalized derivatives of the optimal
                  value with respect to problem parameters have also been
                  explored. Lagrange multipliers are now being seen as arising
                  from a general rule for the subdifferentiation of a nonsmooth
                  objective function which allows black-and-white constraints to
                  be replaced by penalty expressions. This paper traces such
                  themes in the current theory of Lagrange multipliers,
                  providing along the way a free-standing exposition of basic
                  nonsmooth analysis as motivated by and applied to this
                  subject.},
  year =         1993
}

@Misc{		  romb:2005,
  author =       {J. Romberg},
  date-modified ={2007-07-18 14:59:33 -0700},
  howpublished = {{\sc Matlab} solver for {DS} problem,
                  \url{http://www.l1-magic.org/}},
  title =        {{l1dantzig\_pd.m}},
  year =         2005
}

@InBook{	  rose:1963,
  author =       {J. B. Rosen},
  date-modified ={2007-07-18 14:59:34 -0700},
  editor =       {R. L. Graves and P. Wolfe},
  publisher =    mcgrawhill,
  title =        {Recent Advances in Mathematical Programming},
  year =         1963
}

@InCollection{	  rose:1963b,
  address =      {New York},
  author =       {J. B. Rosen},
  booktitle =    {Recent Advances in Mathematical Programming},
  date-modified ={2007-07-18 14:59:32 -0700},
  editor =       {R. L. Graves and P. Wolfe},
  pages =        {159-176},
  publisher =    mcgrawhill,
  title =        {Convex Partition Programming},
  year =         1963
}

@TechReport{	  rose:1977,
  address =      {Minneapolis, MN},
  author =       {J. B. Rosen},
  date-modified ={2007-07-18 14:59:34 -0700},
  institution =  {Computer Science Department, University of Minnesota},
  month =        {August},
  number =       {77-8},
  title =        {Two-phase algorithm for nonlinear constraint problems},
  year =         1977
}

@InProceedings{	  rose:1978,
  address =      {New York},
  author =       {J. B. Rosen},
  booktitle =    {Nonlinear Programming 3},
  date-modified ={2007-07-18 14:59:34 -0700},
  editor =       {O. Mangasarian and R. Meyer and S. Robinson},
  pages =        {97--124},
  publisher =    academic,
  title =        {{Two-phase} algorithm for nonlinear constraint problems},
  year =         1978
}

@InCollection{	  rosekreu:1972,
  address =      {London},
  author =       {J. B. Rosen and J. Kreuser},
  booktitle =    {Numerical Methods for Nonlinear Optimization},
  date-modified ={2007-07-18 14:59:31 -0700},
  editor =       {F. A. Lootsma},
  pages =        {297--300},
  publisher =    academic,
  title =        {A Gradient Projection Algorithm for Non-Linear Constraints},
  year =         1972
}

@InProceedings{	  roux2012stochastic,
  title =        {A Stochastic Gradient Method with an Exponential Convergence
                  Rate for Finite Training Sets},
  author =       {Roux, Nicolas L and Schmidt, Mark and Bach, Francis R},
  booktitle =    {Advances in Neural Information Processing Systems},
  pages =        {2663--2671},
  year =         2012
}

@Book{		  roydenf:2010,
  author =       {H. L. Royden and P. M. Fitzpatrick},
  title =        {Real analysis},
  publisher =    {Prentice Hall},
  year =         2010,
  month =        {Boston},
  note =         {4th edition}
}

@Article{	  rrt94,
  author =       "Ravi, S. S. and Rosenkrantz, D. J. and Tayi, G. K.",
  title =        "Heuristic and special case algorithms for dispersion problems",
  journal =      "Oper. Res.",
  year =         1994,
  volume =       42,
  page =         {299--310}
}

@Article{	  rsmb04,
  author =       "Rohl, C. A. and Strauss, C. E. M. and Misura, K. and Baker,
                  D.",
  title =        "Protein structure prediction using Rosetta",
  journal =      "Methods Enzym.",
  year =         2004,
  volume =       383,
  page =         {66--93}
}

@Article{	  rudioshefate:1992,
  author =       {L. Rudin and S. Osher and E. Fatemi},
  journal =      {Physica D},
  pages =        {259--268},
  title =        {Nonlinear total variation based noise removal algorithms},
  volume =       60,
  year =         1992
}

@Misc{		  rwt,
  author =       {R. Baraniuk and H. Choi and F. Fernandes and B. Hendricks and
                  R. Neelamani and V. Ribeiro and J. Romberg and R. Gopinath and
                  H.-T Guo and M. Lang and J. E. Odegard and D. Wei},
  date-added =   {2007-09-18 22:09:54 -0700},
  date-modified ={2007-09-18 22:09:54 -0700},
  howpublished = {\url{http://www.dsp.rice.edu/software/rwt.shtml}},
  title =        {{Rice Wavelet Toolbox}},
  year =         1993
}

@Article{	  ryanosbo:1986,
  title =        {On the solution of highly degenerate linear programmes},
  author =       {Ryan, D. M. and Osborne, M.R.},
  journal =      mathprog,
  volume =       41,
  number =       1,
  pages =        {385--392},
  year =         1986
}

@InProceedings{	  sangbuc:2000,
  author =       {E. Sang and S. Buchholz},
  title =        {Introduction to the {CoNLL-2000 Shared Task: Chunking}},
  booktitle =    {Proceedings of Conference on Natural Language Learning},
  pages =        {127--132},
  year =         2000
}

@Article{	  sardy2004c,
  author =       "Sardy, S. and Tseng, P.",
  title =        "On the statistical analysis of smoothing by maximizing dirty
                  Markov random field posterior distributions",
  journal =      "J. Amer. Statist. Assoc.",
  year =         2004,
  volume =       99,
  page =         {191--204}
}

@Article{	  sas02,
  author =       "Sagastizabal, C. A. and Solodov, M. V.",
  title =        "Parallel variable distribution for constrained optimization",
  journal =      "Computational Optimization and Applications",
  year =         2002,
  volume =       22,
  page =         {111--131}
}

@Article{	  sat04,
  author =       "Sardy, S. and Antoniadis, A. and Tseng, P.",
  title =        "Automatic smoothing with wavelets for a wide class of
                  distributions",
  journal =      "J. Comput. Graph. Stat.",
  year =         2004,
  volume =       13,
  page =         {399--421}
}

@Article{	  sat04a,
  author =       {S. Sardy and P. Tseng},
  journal =      {J. Amer. Statist. Assoc.},
  pages =        {191-204},
  title =        {On the statistical analysis of smoothing by maximizing dirty
                  Markov random field posterior distributions},
  volume =       99,
  year =         2004
}

@Article{	  sat04b,
  author =       "Sardy, S. and Tseng, P.",
  title =        "{AMlet}, {RAMlet}, and {GAMlet}: automatic nonlinear fitting
                  of additive models, robust and generalized, with wavelets",
  journal =      "J. Comput. Graph. Stat.",
  year =         2004,
  volume =       13,
  page =         {283--309}
}

@InCollection{	  saun:1996,
  address =      {Philadelphia},
  author =       {M. A. Saunders},
  booktitle =    {Linear and Nonlinear Conjugate Gradient-Related Methods},
  date-modified ={2007-07-18 14:59:32 -0700},
  editor =       {L. Adams and J. L. Nazareth},
  pages =        {92--100},
  publisher =    siampub,
  title =        {Cholesky-based methods for sparse least squares: {T}he
                  benefits of regularization},
  year =         1996
}

@Misc{		  saun:2010,
  author =       {Michael A. Saunders},
  howpublished = {\url{http://www.stanford.edu/group/SOL/software/pdco.html}},
  title =        {{PDCO: Primal-Dual interior method for Convex Objectives}},
  month =        {April},
  year =         2010
}

@TechReport{	  sauntoml:1996,
  address =      {Department of {EES} \& {OR}, Stanford, CA 94305},
  author =       {M. A. Saunders and J. A. Tomlin},
  date-modified ={2007-07-18 14:59:34 -0700},
  institution =  {Stanford University},
  month =        {December},
  note =         {Also IBM Research Report RJ 10064},
  number =       {SOL Report 96-4},
  title =        {Solving regularized linear programs using barrier methods and
                  {KKT} systems},
  year =         1996
}

@Article{	  sbt00,
  author =       "Sardy, S. and Bruce, A. and Tseng, P.",
  title =        "Block coordinate relaxation methods for nonparametric wavelet
                  denoising",
  journal =      "J. Comput. Graph. Stat.",
  year =         2000,
  volume =       9,
  page =         {361--379}
}

@Article{	  sbt01,
  author =       "Sardy, S. and Bruce, A. and Tseng, P.",
  title =        "Robust wavelet denoising",
  journal =      "IEEE Trans. Signal Proc.",
  year =         2001,
  volume =       49,
  page =         {1146--1152}
}

@Article{	  schescho:2000,
  author =       {Holger Scheel and Stefan Scholtes},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathofor,
  month =        {February},
  number =       1,
  title =        {Mathematical programs with complementarity constraints:
                  Stationarity, optimality, and sensitivity},
  volume =       25,
  year =         2000
}

@TechReport{	  schi:2003,
  author =       {K. Schittkowski},
  date-modified ={2007-07-18 14:59:34 -0700},
  institution =  {Department of Mathematics, University of Bayreuth},
  title =        {{QL}: {A} {F}ortran code for convex quadratic programming -
                  {U}ser's guide},
  year =         2003
}

@Article{	  schittkowski:1981,
  author =       {K. Schittkowski},
  title =        {The nonlinear programming method of {Wilson, Han, and Powell}
                  with an augmented {Lagrangian} type line search function. {I.}
                  Convergence analysis},
  journal =      numermath,
  volume =       38,
  number =       1,
  pages =        {83–114},
  year =         {1981/82}
}

@Article{	  schmidtrouxbach:2011,
  title =        {Convergence rates of inexact proximal-gradient methods for
                  convex optimization},
  author =       {Schmidt, Mark and Roux, Nicolas Le and Bach, Francis},
  journal =      {arXiv preprint arXiv:1109.2415},
  year =         2011
}

@Article{	  scho:2001,
  author =       {S. Scholtes},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamopt,
  number =       4,
  pages =        {918-936},
  title =        {Convergence properties of a regularization scheme for
                  mathematical programs with complementarity constraints},
  volume =       11,
  year =         2001
}

@Article{	  schopfer:2012,
  author =       {Sch\"opfer, F.},
  title =        {Exact Regularization of Polyhedral Norms},
  journal =      siamopt,
  volume =       22,
  number =       4,
  pages =        {1206-1223},
  year =         2012,
  doi =          {10.1137/11085236X},
  url =          {http://epubs.siam.org/doi/abs/10.1137/11085236X}
}

@Article{	  schostoh:1999,
  author =       {S. Scholtes and M. St\"ohr},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamcontrol,
  pages =        {617-652},
  title =        {Exact penalization of mathematical programs with equilibrium
                  constraints},
  volume =       37,
  year =         1999
}

@Article{	  schostoh:2001,
  author =       {S. Scholtes and M. St\"ohr},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      mathofor,
  pages =        {851-863},
  title =        {How stringent is the linear independence condition for
                  mathematical programs with equilibrium constraints?},
  volume =       26,
  year =         2001
}

@InProceedings{	  schraudolph:2007,
  author =       {Nicol N. Schraudolph and Jin Yu and Simon G\"unter},
  title =        {\href{http://nic.schraudolph.org/pubs/SchYuGue07.pdf}{ A
                  Stochastic Quasi-{N}ewton Method for Online Convex
                  Optimization}},
  pages =        {436--443},
  editor =       {Marina Meila and Xiaotong Shen},
  booktitle =    {Proc.\ 11$^{th}$ Intl.\ Conf.\ Artificial Intelligence and
                  Statistics (AIStats)},
  address =      {San Juan, Puerto Rico},
  volume =       2,
  series =       {Workshop Conf.\@ Proc.},
  publisher =    {J.\@ Machine Learning Res.},
  year =         2007,
  b2h_type =     {Top Conferences},
  b2h_topic =    {Quasi-Newton Methods},
  abstract =     {We develop stochastic variants of the well-known BFGS
                  quasi-Newton optimization method, in both full and
                  memory-limited (LBFGS) forms, for online optimization of
                  convex functions. The resulting algorithm performs comparably
                  to a well-tuned natural gradient descent but is scalable to
                  very high-dimensional problems. On standard benchmarks in
                  natural language processing, it asymptotically outperforms
                  previous stochastic gradient methods for parameter estimation
                  in conditional random fields. We are working on analyzing the
                  convergence of online (L)BFGS, and extending it to non-convex
                  optimization problems. }
}

@Article{	  sdpt3:2003,
  author =       {Reha H T\"ut\"unc\"u and Kim Chuan Toh and Michael J. Todd},
  title =        {Solving semidefinite-quadratic-linear programs using {SDPT3}},
  journal =      mathprog,
  volume =       95,
  year =         2003,
  pages =        {189--217}
}

@Article{	  seti:1992,
  author =       {R. Setiono},
  date-modified ={2007-10-20 15:06:49 -0700},
  journal =      jota,
  number =       3,
  pages =        {425--444},
  title =        {Interior proximal point algorithm for linear programs},
  volume =       74,
  year =         1992
}

@article{shalev2011large,
  title =        {Large-scale convex minimization with a low-rank constraint},
  author =       {Shalev-Shwartz, Shai and Gonen, Alon and Shamir, Ohad},
  journal =      {arXiv preprint arXiv:1106.1622},
  year =         2011
}

@MastersThesis{	  shan:2008,
  address =      {Vancouver},
  author =       {Shidong Shan},
  month =        {August},
  school =       {Dept. Computer Science, University of British Columbia},
  title =        {A {Levenberg-Marquardt} method for large-scale
                  bound-constrained nonlinear least-squares},
  year =         2008
}

@Article{	  shannophua:1978,
  author =       {Shanno, D. F. and Phua, K.-H.},
  affiliation =  {The University of Arizona Tucson AZ USA},
  title =        {Matrix conditioning and nonlinear optimization},
  journal =      {Mathematical Programming},
  publisher =    {Springer Berlin / Heidelberg},
  keyword =      {Mathematics and Statistics},
  pages =        {149-160},
  volume =       14,
  issue =        1,
  url =          {http://dx.doi.org/10.1007/BF01588962},
  note =         {10.1007/BF01588962},
  abstract =     {In a series of recent papers, Oren, Oren and Luenberger, Oren
                  and Spedicato, and Spedicato have developed the self-scaling
                  variable metric algorithms. These algorithms alter Broyden's
                  single parameter family of approximations to the inverse
                  Hessian to a double parameter family. Conditions are given on
                  the new parameter to minimize a bound on the condition number
                  of the approximated inverse Hessian while insuring improved
                  step-wise convergence.},
  year =         1978
}

@Article{	  shanvand:1999,
  author =       {D. Shanno and R. Vanderbei},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      compapplopt,
  pages =        {231--252},
  title =        {An interior-point algorithm for nonconvex nonlinear
                  programming},
  volume =       13,
  year =         1999
}

@InProceedings{	  shashaza:2005,
  author =       {A. Shashua and T. Hazan},
  booktitle =    {{IEEE} Proceedings of Intl. Conf. Comp. Vision},
  date-added =   {2007-10-20 16:04:31 -0700},
  date-modified ={2007-10-20 16:05:22 -0700},
  title =        {Non-negative tensor factorization with applications to
                  statistics and computer vision},
  year =         2005
}

@article{shefi2016dual,
  title =        {A dual method for minimizing a nonsmooth objective over one
                  smooth inequality constraint},
  author =       {Shefi, Ron and Teboulle, Marc},
  journal =      mathprog,
  volume =       159,
  number =       {1-2},
  pages =        {137--164},
  year =         2016,
  publisher =    {Springer}
}

@Unpublished{	  shew:1994,
  author =       {J. R. Shewchuk},
  month =        {August},
  note =         {See the author's website: http://www-2.cs.cmu.edu/\tild jrs/},
  title =        {An Introduction to the Conjugate Gradient Method Without the
                  Agonizing Pain},
  year =         1994
}

@Misc{		  silvlim:2007,
  author =       {V. de Silva and L. Lim},
  howpublished = {To appear in {\it SIAM J. Matrix Anal. Appl.}},
  title =        {Tensor rank and the ill-posedness of the best low-rank
                  approximation problem},
  year =         2007
}

@Misc{		  slimpy:2007,
  key =          {\url{http://slim.eos.ubc.ca/SLIMpy}},
  author =       {F. Herrmann and S. Ross-Ross},
  title =        {{SlimPy}: {A Python} interface to {Unix}-like pipe based
                  linear operators},
  howpublished = {\url{http://slim.eos.ubc.ca/SLIMpy}},
  year =         2007
}

@Book{		  smit:2004,
  address =      {Hoboken, NJ},
  author =       {R. Martin Smith},
  publisher =    johnwileysons,
  title =        {Understanding mass spectra: A basic approach},
  edition =      {Second},
  year =         2004
}

@Article{	  sol98,
  author =       "Solodov, M. V.",
  title =        "Incremental gradient algorithms with step sizes bounded away
                  from zero",
  journal =      "Comput. Optim. Appl.",
  year =         1998,
  volume =       11,
  page =         {23--35}
}

@Article{	  solodov1998incremental,
  title =        {{Incremental gradient algorithms with stepsizes bounded away
                  from zero}},
  author =       {Solodov, M.V.},
  journal =      {Computational Optimization and Applications},
  volume =       11,
  number =       1,
  pages =        {23--35},
  year =         1998,
  publisher =    {Springer}
}

@Article{	  soy07,
  author =       "So, A. M.-C. and Yinyu Ye",
  title =        "Theory of semidefinite programming for sensor network
                  localization",
  journal =      "Math. Program.",
  year =         2007,
  volume =       109,
  page =         {367--384}
}

@Misc{		  sparselab,
  author =       {David L. Donoho and Iddo Driori and Victoria C. Stodden and
                  Yaakov Tsaig},
  date-added =   {2007-12-13 11:47:57 -0800},
  date-modified ={2007-12-13 11:47:57 -0800},
  howpublished = {\url{http://sparselab.stanford.edu/}},
  title =        {Sparselab},
  year =         2007
}

@Misc{		  spec:2009,
  author =       {Eckard Specht},
  title =        {Packing of circles in the unit circle},
  url =          {http://hydra.nat.uni-magdeburg.de/packing/cci/cci.html},
  year =         2009
}

@Article{	  springerlink:10.1007/s10107-009-0306-5,
  author =       {Ma, Shiqian and Goldfarb, Donald and Chen, Lifeng},
  affiliation =  {Department of Industrial Engineering and Operations Research,
                  Columbia University, New York, NY 10027, USA},
  title =        {Fixed point and {Bregman} iterative methods for matrix rank
                  minimization},
  journal =      mathprog,
  publisher =    {Springer Berlin / Heidelberg},
  keyword =      {Mathematics and Statistics},
  pages =        {321-353},
  volume =       128,
  issue =        1,
  doi =          {10.1007/s10107-009-0306-5},
  abstract =     {The linearly constrained matrix rank minimization problem is
                  widely applicable in many fields such as control, signal
                  processing and system identification. The tightest convex
                  relaxation of this problem is the linearly constrained nuclear
                  norm minimization. Although the latter can be cast as a
                  semidefinite programming problem, such an approach is
                  computationally expensive to solve when the matrices are
                  large. In this paper, we propose fixed point and Bregman
                  iterative algorithms for solving the nuclear norm minimization
                  problem and prove convergence of the first of these
                  algorithms. By using a homotopy approach together with an
                  approximate singular value decomposition procedure, we get a
                  very fast, robust and powerful algorithm, which we call FPCA
                  (Fixed Point Continuation with Approximate SVD), that can
                  solve very large matrix rank minimization problems (the code
                  can be downloaded from
                  http://www.columbia.edu/~sm2756/FPCA.htm for non-commercial
                  use). Our numerical results on randomly generated and real
                  matrix completion problems demonstrate that this algorithm is
                  much faster and provides much better recoverability than
                  semidefinite programming solvers such as SDPT3. For example,
                  our algorithm can recover 1000 × 1000 matrices of rank 50 with
                  a relative error of 10 −5 in about 3 min by sampling only 20\%
                  of the elements. We know of no other method that achieves as
                  good recoverability. Numerical experiments on online
                  recommendation, DNA microarray data set and image inpainting
                  problems demonstrate the effectiveness of our algorithms.},
  year =         2011
}

@Article{	  springerlink:10.1007/s10107-010-0437-8,
  author =       {Liu, Yong-Jin and Sun, Defeng and Toh, Kim-Chuan},
  affiliation =  {Faculty of Science, Shenyang Aerospace University, 110136
                  Shenyang, People’s Republic of China},
  title =        {An implementable proximal point algorithmic framework for
                  nuclear norm minimization},
  year =         2012,
  volume =       133,
  number =       {1--2},
  journal =      mathprog,
  publisher =    {Springer Berlin / Heidelberg},
  keyword =      {Mathematics and Statistics},
  pages =        {1-38},
  doi =          {10.1007/s10107-010-0437-8},
  abstract =     {The nuclear norm minimization problem is to find a matrix with
                  the minimum nuclear norm subject to linear and second order
                  cone constraints. Such a problem often arises from the convex
                  relaxation of a rank minimization problem with noisy data, and
                  arises in many fields of engineering and science. In this
                  paper, we study inexact proximal point algorithms in the
                  primal, dual and primal-dual forms for solving the nuclear
                  norm minimization with linear equality and second order cone
                  constraints. We design efficient implementations of these
                  algorithms and present comprehensive convergence results. In
                  particular, we investigate the performance of our proposed
                  algorithms in which the inner sub-problems are approximately
                  solved by the gradient projection method or the accelerated
                  proximal gradient method. Our numerical results for solving
                  randomly generated matrix completion problems and real matrix
                  completion problems show that our algorithms perform favorably
                  in comparison to several recently proposed state-of-the-art
                  algorithms. Interestingly, our proposed algorithms are
                  connected with other algorithms that have been studied in the
                  literature.}
}

@Article{	  sth03,
  author =       "Strohmer, T. and Heath, R. Jr.",
  title =        "Grassmannian frames with applications to coding and
                  communications.",
  journal =      "Appl. Comp. Harm. Anal.",
  year =         2003,
  volume =       14,
  page =         {257--275}
}

@Unpublished{	  stojparvhass:2008,
  author =       {M. Stojnic and F. Parvaresh and B. Hassibi},
  title =        {On the reconstruction of block-sparse signals with an optimal
                  number of measurements},
  month =        {March},
  year =         2008,
  note =         {Available at arXiv 0804.0041}
}

@TechReport{	  stur:2001,
  author =       {J. F. Sturm},
  date-modified ={2007-07-18 14:59:34 -0700},
  institution =  {Department of Econometrics, Tilburg University, Tilburg, The
                  Netherlands},
  title =        {Using {SeDuMi} 1.02, A {Matlab} toolbox for optimization over
                  symmetric cones (updated for {V}ersion 1.05)},
  year =         {August 1998 -- October 2001}
}

@Article{	  sturlies:2005,
  author =       {Eric de Sturler and J\"{o}rg Liesen},
  doi =          {10.1137/S1064827502411006},
  journal =      siamcomp,
  keywords =     {saddle point systems; indefinite systems; eigenvalue bounds;
                  Krylov subspace methods; preconditioning; constrained
                  optimization; mesh-flattening},
  number =       5,
  pages =        {1598-1619},
  publisher =    {SIAM},
  title =        {Block-Diagonal and Constraint Preconditioners for Nonsymmetric
                  Indefinite Linear Systems. Part I: Theory},
  url =          {http://link.aip.org/link/?SCE/26/1598/1},
  volume =       26,
  year =         2005
}

@Misc{		  surfacelettoolbox,
  author =       {Y. Lu},
  howpublished =
                  {\url{http://www.mathworks.com/matlabcentral/fileexchange/14485}},
  title =        {{Surfacelet toolbox}},
  year =         2008
}

@TechReport{	  syos08,
  author =       "J. Shi and W. Yin and S. Osher and P. Sajda",
  title =        "A fast algorithm for large scale {L1}-regularized logistic
                  regression",
  institution =  "Department of Computational and Applied Mathematics, Rice
                  University",
  address =      "Houston",
  year =         2008
}

@InProceedings{	  takhlaskwakietal:2006,
  author =       {D. Takhar and J. N. Laska and M. Wakin and M. Duarte and D.
                  Baron and S. Sarvotham and K. K. Kelly and R. G. Baraniuk},
  booktitle =    {Proceedings of the IS\&T/SPIE Symposium on Electronic Imaging:
                  Computational Imaging},
  month =        {January},
  title =        {A new camera architecture based on optical-domain compression},
  volume =       6065,
  year =         2006
}

@TechReport{	  tao-user-ref:2007,
  author =       "S. J. Benson and L. Curfman McInnes and J. Mor\'{e} and J.
                  Sarich",
  title =        "{TAO} User Manual (Revision 1.8)",
  year =         2007,
  institution =  "Mathematics and Computer Science Division, Argonne National
                  Laboratory",
  address =      {Argonne, IL},
  number =       "ANL/MCS-TM-242",
  note =         "\url{http://www.mcs.anl.gov/tao}",
  type =         {Tech. rep.}
}

@Article{	  tapi:1977,
  author =       {R. A. Tapia},
  journal =      jota,
  pages =        {135--194},
  title =        {Diagonalized multiplier methods and quasi-{N}ewton methods for
                  constrained optimization},
  volume =       22,
  year =         1977
}

@Article{	  teb97,
  author =       "Teboulle, M.",
  title =        "Convergence of proximal-like algorithms",
  journal =      siamopt,
  year =         1997,
  volume =       7,
  page =         {1069--1083}
}

@Article{	  teus:2013,
  author =       {T. Teuber and G. Steidl and R. H. Chan},
  title =        {Minimization and parameter estimation for seminorm
                  regularization models with {I}-divergence constraints},
  journal =      {Inverse Probl.},
  volume =       29,
  number =       3,
  year =         2013,
  abstract =     {In this paper, we analyze the minimization of seminorms
                  {$\|L\cdot\|$} on {$\mathbb {R}^n$} under the constraint of a
                  bounded I-divergence $D(b,H\cdot)$ for rather general linear
                  operators $H$ and $L$. The I-divergence is also known as
                  Kullback–Leibler divergence and appears in many models in
                  imaging science, in particular when dealing with Poisson data
                  but also in the case of multiplicative Gamma noise. Often H
                  represents, e.g., a linear blur operator and L is some
                  discrete derivative or frame analysis operator. A central part
                  of this paper consists in proving relations between the
                  parameters of I-divergence constrained and penalized problems.
                  To solve the I-divergence constrained problem, we consider
                  various first-order primal–dual algorithms which reduce the
                  problem to the solution of certain proximal minimization
                  problems in each iteration step. One of these proximation
                  problems is an I-divergence constrained least-squares problem
                  which can be solved based on Morozov’s discrepancy principle
                  by a Newton method. We prove that these algorithms produce not
                  only a sequence of vectors which converges to a minimizer of
                  the constrained problem but also a sequence of parameters
                  which converges to a regularization parameter so that the
                  corresponding penalized problem has the same solution.
                  Furthermore, we derive a rule for automatically setting the
                  constraint parameter for data corrupted by multiplicative
                  Gamma noise. The performance of the various algorithms is
                  finally demonstrated for different image restoration tasks
                  both for images corrupted by Poisson noise and multiplicative
                  Gamma noise.}
}

@Article{	  tgs06,
  author =       {Joel A. Tropp and Anna C. Gilbert and Martin J. Strauss},
  title =        {Algorithms for Simultaneous Sparse Approximation: Part I:
                  Greedy Pursuit},
  journal =      {Signal Processing},
  volume =       86,
  issue =        3,
  year =         2006,
  pages =        {572--588}
}

@article{tibshirani1996regression,
  title =        {Regression shrinkage and selection via the lasso},
  author =       {Tibshirani, Robert},
  journal =      royalstatsb,
  pages =        {267--288},
  year =         1996,
  publisher =    {JSTOR}
}

@Article{	  tibssaunrosszhuknig:2005,
  author =       {R. Tibshirani and M. Saunders and S. Rosset and J. Zhu and K.
                  Knight},
  year =         2005,
  title =        {Sparsity and smoothness via the fused lasso},
  journal =      {J. Royal Statistical Society: Series B (Statistical
                  Methodology)},
  number =       {Part 1},
  volume =       67,
  pages =        {91–108},
  doi =          {10.1111/j.1467-9868.2005.00490.x}
}

@Article{	  tik63a,
  author =       {Andrey N. Tikhonov},
  date-modified ={2007-12-13 11:49:11 -0800},
  journal =      {Soviet Math. Dokl.},
  note =         {English translation of Dokl. Akad. Nauk. SSSR, 153:1 (1963),
                  pp 49--52},
  number =       6,
  pages =        {1624--1647},
  title =        {Regularization of incorrectly posed problems},
  volume =       4,
  year =         1963
}

@Article{	  tikh:1963b,
  author =       {Andrey N. Tikhonov},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      {Soviet Math. Dokl.},
  note =         {English translation of Dokl. Akad. Nauk. SSSR, 151:3 (1963)
                  pp. 501--504},
  number =       4,
  pages =        {1035--1038},
  title =        {Solution of incorrectly formulated problems and the
                  regularization method},
  volume =       4,
  year =         1963
}

@Book{		  tikharse:1977,
  address =      {Washington, D.C.},
  author =       {A. N. Tikhonov and V. Y. Arsenin},
  date-modified ={2007-07-18 14:59:34 -0700},
  note =         {Translated from Russian},
  publisher =    {V. H. Winston and Sons},
  title =        {Solutions of Ill-Posed Problems},
  year =         1977
}

@Article{	  todd:2001,
  author =       {M. J. Todd},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      actanumerica,
  pages =        {515--560},
  title =        {Semidefinite optimization},
  volume =       10,
  year =         2001
}

@PhDThesis{	  toft:1996,
  author =       {P. Toft},
  school =       {Department of Mathematical Modelling, Technical University of
                  Denmark},
  title =        {The Radon transform: Theory and implementation},
  year =         1996
}

@TechReport{	  toml:1975,
  author =       {John A. Tomlin},
  institution =  {Department of Operations Research, Stanford University},
  number =       {SOL 75-12},
  title =        {A parametric bounding method for finding a minimum
                  {$\ell_\infty$}-norm solution to a system of equations},
  type =         {Tech. Rep.},
  year =         1975
}

@TechReport{	  toy09,
  author =       "Toh, K.-C. and Yun, S.",
  title =        "An accelerated proximal gradient algorithm for nuclear
                  regularized least squares problems",
  institution =  "Department of Mathematics, National University of Singapore",
  address =      "Singapore",
  year =         2009
}

@book{trefethen1997numerical,
  title =        {Numerical linear algebra},
  author =       {Trefethen, Lloyd N and Bau III, David},
  volume =       50,
  year =         1997,
  publisher =    {Siam}
}

@Article{	  trg07,
  title =        {Signal Recovery From Random Measurements Via Orthogonal
                  Matching Pursuit},
  author =       {Tropp, J. A and Gilbert, A. C},
  journal =      ieeetransinfo,
  volume =       53,
  number =       12,
  pages =        {4655--4666},
  year =         2007,
  abstract =     {This article demonstrates theoretically and empirically that a
                  greedy algorithm called Orthogonal Matching Pursuit (OMP) can
                  reliably recover a signal with m nonzero entries in dimension
                  $d$ given $O(m ln d)$ random linear measurements of that
                  signal. This is a massive improvementover previous results for
                  OMP, which require $O(m^2)$ measurements. The new results for
                  OMP are comparable with recent results for another algorithm
                  called Basis Pursuit (BP). The OMP algorithm is much faster
                  and much easier to implement, which makes it an attractive
                  alternative to BPfor signal recovery problems}
}

@Article{	  tro04,
  author =       {Joel A. Tropp},
  date-modified ={2007-09-15 09:32:05 -0700},
  journal =      {{IEEE} Trans. Inform. Theory},
  month =        {October},
  number =       10,
  pages =        {2231-2242},
  title =        {Greed is Good: Algorithmic Results for Sparse Approximation},
  volume =       50,
  year =         2004
}

@Article{	  tro06a,
  abstract =     {This paper studies a difficult and fundamental problem that
                  arises throughout electrical engineering, applied mathematics,
                  and statistics. Suppose that one forms a short linear
                  combination of elementary signals drawn from a large, fixed
                  collection. Given an observation of the linear combination
                  that has been contaminated with additive noise, the goal is to
                  identify which elementary signals participated and to
                  approximate their coefficients. Although many algorithms have
                  been proposed, there is little theory which guarantees that
                  these algorithms can accurately and efficiently solve the
                  problem. This paper studies a method called convex relaxation,
                  which attempts to recover the ideal sparse signal by solving a
                  convex program. This approach is powerful because the
                  optimization can be completed in polynomial time with standard
                  scientific software. The paper provides general conditions
                  which ensure that convex relaxation succeeds. As evidence of
                  the broad impact of these results, the paper describes how
                  convex relaxation can be used for several concrete signal
                  recovery problems. It also describes applications to channel
                  coding, linear regression, and numerical analysis. },
  author =       {Joel A. Tropp},
  journal =      ieeetransinfo,
  keywords =     {Algorithms, approximation methods, basis pursuit, convex
                  program, linear regression, optimization methods, orthogonal
                  matching pursuit, sparse representations},
  month =        {March},
  number =       3,
  pages =        {1030--1051},
  title =        {Just relax: Convex programming methods for identifying sparse
                  signals in noise},
  volume =       52,
  year =         2006
}

@Article{	  tro06b,
  author =       {Joel A. Tropp},
  title =        {Algorithms for Simultaneous Sparse Approximation: Part II:
                  Convex Relaxation},
  journal =      {Signal Processing},
  volume =       86,
  issue =        3,
  year =         2006,
  pages =        {589--602}
}

@Article{	  tropp2004,
  author =       "Tropp, J. A.",
  title =        "Greed is good: algorithmic results for sparse approximation",
  journal =      "IEEE Trans. Inf. Theory",
  year =         2004,
  volume =       50,
  page =         {2231--2242}
}

@InBook{	  tse00,
  author =       "Paul Tseng",
  chapter =      "Error bounds and superlinear convergence analysis of sonic
                  Newton-type methods in optimization",
  title =        "Nonlinear Optimization and Related Topics",
  publisher =    "Kiuwer",
  address =      "Dordrecht",
  year =         2000,
  page =         {445--462}
}

@Article{	  tse00b,
  author =       "Paul Tseng",
  title =        "Convergence of block coordinate descent method for
                  nondifferentiable minimization",
  journal =      jota,
  year =         2001,
  volume =       109,
  page =         {473--492}
}

@Article{	  tse07,
  author =       "Paul Tseng",
  title =        "Second-order cone programming relaxation of sensor network
                  localization",
  journal =      siamopt,
  year =         2007,
  volume =       18,
  page =         {156--185}
}

@TechReport{	  tse08,
  author =       "Paul Tseng",
  title =        "On accelerated proximal gradient methods for convex-concave
                  optimization",
  institution =  "Department of Mathematics, University of Washington",
  address =      "Seattle",
  year =         2008,
  month =        "May",
  note =         "submitted to SIAM J. Optim."
}

@Article{	  tse09,
  author =       "Paul Tseng",
  title =        "Further results on a stable recovery of sparse overcomplete
                  representations in the presence of noise",
  journal =      ieeetransinfo,
  year =         2009,
  volume =       55,
  page =         {888--899}
}

@Article{	  tse91,
  author =       "Paul Tseng",
  title =        "On the rate of convergence of a partially asynchronous
                  gradient projection algorithm",
  journal =      siamopt,
  year =         1991,
  volume =       1,
  page =         {603--619}
}

@Article{	  tse93,
  author =       "Paul Tseng",
  title =        "Dual coordinate descent methods for non-strictly convex
                  minimization",
  journal =      "Math. Prog.",
  year =         1993,
  volume =       59,
  page =         {231--247}
}

@Article{	  tse98,
  author =       "Paul Tseng",
  title =        "An incremental gradient(-projection) method with momentum term
                  and adaptive stepsize rule",
  journal =      siamopt,
  year =         1998,
  volume =       8,
  page =         {506--531}
}

@Article{	  tse99,
  author =       {P. Tseng},
  journal =      {Comput. Optim. Appl.},
  pages =        {221--230},
  title =        {Convergence and error bound for perturbation of linear
                  programs},
  volume =       13,
  year =         1999
}

@Article{	  tseng:1998,
  author =       {Paul Tseng},
  title =        {An Incremental Gradient(-Projection) Method with Momentum Term
                  and Adaptive Stepsize Rule},
  publisher =    {SIAM},
  year =         1998,
  journal =      siamopt,
  volume =       8,
  number =       2,
  pages =        {506-531},
  keywords =     {incremental gradient method; gradient projection; convergence
                  analysis; backpropagation; nonlinear neural network training},
  url =          {http://link.aip.org/link/?SJE/8/506/1},
  doi =          {10.1137/S1052623495294797}
}

@Article{	  tseng:2010,
  author =       {Tseng, Paul},
  title =        {Approximation accuracy, gradient methods, and error bound for
                  structured convex optimization},
  journal =      mathprog,
  publisher =    {Springer Berlin / Heidelberg},
  keyword =      {Mathematics and Statistics},
  pages =        {263-295},
  volume =       125,
  issue =        2,
  doi =          {10.1007/s10107-010-0394-2},
  year =         2010
}

@Article{	  tsy08,
  author =       "Paul Tseng and S. Yun",
  title =        "A coordinate gradient descent method for linearly constrained
                  smooth optimization and support vector machines training",
  journal =      "Comput. Optim. Appl.",
  year =         2008
}

@Article{	  tsy09a,
  author =       "Paul Tseng and S. Yun",
  title =        "A coordinate gradient descent method for nonsmooth separable
                  minimization",
  journal =      "Math. Program.",
  year =         2009,
  volume =       117,
  page =         {387--423}
}

@Article{	  tsy09b,
  author =       "Paul Tseng and S. Yun",
  title =        "A block-coordinate gradient descent method for linearly
                  constrained nonsmooth separable optimization",
  journal =      jota,
  year =         2009,
  volume =       140,
  page =         {513--535}
}

@Article{	  turlvenawrig:2005,
  title =        {Simultaneous variable selection},
  author =       {Turlach, B.A. and Venables, W.N. and Wright, S.J.},
  journal =      {Technometrics},
  volume =       47,
  number =       3,
  pages =        {349--363},
  year =         2005,
  publisher =    {American Statistical Association}
}

@Article{	  ulbr:2004,
  author =       {S. Ulbrich},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprog,
  pages =        {217--245},
  title =        {On the superlinear local convergence of a filter-{SQP} method},
  volume =       100,
  year =         2004
}

@Article{	  ulbrulbr:2003,
  author =       {M. Ulbrich and S. Ulbrich},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprog,
  pages =        {103--135},
  title =        {Non-monotone trust region methods for nonlinear equality
                  constrained optimization without a penalty function},
  volume =       95,
  year =         2003
}

@Article{	  van-:1982,
  author =       {G. {Van Der Hoek}},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      mathprogstudy,
  pages =        {162--189},
  title =        {Asymptotic Properties of Reduction Methods Applying Linearly
                  Equality Constrained Reduced Problems},
  volume =       16,
  year =         1982
}

@Article{	  vand:1995,
  author =       {R. J. Vanderbei},
  date-added =   {2007-10-19 18:34:07 -0700},
  date-modified ={2007-10-19 18:34:20 -0700},
  journal =      siamopt,
  number =       1,
  pages =        {100-113},
  title =        {Symmetric Quasi-Definite Matrices},
  volume =       5,
  year =         1995
}

@Misc{		  vand:2002,
  author =       {Robert Vanderbei},
  date-modified ={2007-07-18 14:59:32 -0700},
  month =        {December},
  title =        {Benchmarks for nonlinear optimization. {\rm
                  http://www.princeton.edu/\tild rvdb/ bench.html}},
  year =         2002
}

@Article{	  vandboyd:1996,
  author =       {Lieven Vandenberghe and Stephen Boyd},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      siamreview,
  month =        {March},
  number =       1,
  pages =        {49--95},
  title =        {Semidefinite programming},
  volume =       38,
  year =         1996
}

@Misc{		  vandenberghe:2010,
  url =          {http://www.seas.ucla.edu/~vandenbe/publications/coneprog.pdf},
  year =         2010,
  title =        {The {CVXOPT} linear and quadratic cone program solvers},
  author =       {L. Vandenberghe}
}

@Book{		  vapnik95,
  author =       {Vapnik,~V.},
  title =        {The Nature of Statistical Learning Theory},
  publisher =    {Springer},
  year =         1995,
  address =      {New York, NY, USA}
}

@PhDThesis{	  vasi:2009,
  author =       {Vasiloglou, Nikolaos},
  title =        {Isometry and convexity in dimensionality reduction},
  school =       {Georgia Institute of Technology},
  year =         2009
}

@Article{	  vddoelascher:2011,
  author =       {Kees van den Doel and Uri M. Ascher},
  title =        {Adaptive and Stochastic Algorithms for Electrical Impedance
                  Tomography and DC Resistivity Problems with Piecewise Constant
                  Solutions and Many Measurements},
  journal =      siamcomp,
  volume =       34,
  number =       1,
  year =         2012,
  ee =           {http://dx.doi.org/10.1137/110826692},
  bibsource =    {DBLP, http://dblp.uni-trier.de}
}

@Article{	  vicewrig:2002,
  author =       {L. N. Vicente and S. Wright},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      compapplopt,
  pages =        {311--328},
  title =        {Local convergence of a primal-dual method for degenerate
                  nonlinear programming},
  volume =       22,
  year =         2002
}

@Book{		  vogel:1987,
  title =        {Computational methods for inverse problems},
  author =       {Vogel, C.R.},
  volume =       23,
  year =         1987,
  publisher =    {Society for Industrial Mathematics}
}

@InCollection{	  vonneumann:1937,
  author =       {J. von Neumann},
  title =        {Some matrix inequalities and metrization of matric-space},
  booktitle =    {Univ. Tomsk. Rev.},
  series =       {Collected Works},
  publisher =    {Pergamon},
  address =      {Oxford},
  year =         1962,
  volume =       {IV},
  pages =        {205-218}
}

@Article{	  wachbieg:2005,
  author =       {Andreas W\"achter and Lorenz T. Biegler},
  journal =      siamopt,
  volume =       16,
  number =       1,
  pages =        {1--31},
  title =        {Line Search Filter Methods for Nonlinear Programming:
                  Motivation and Global Convergence},
  year =         2005
}

@Article{	  wachbieg:2005b,
  author =       {Andreas W\"achter and Lorenz T. Biegler},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      siamopt,
  number =       1,
  pages =        {32--48},
  title =        {Line Search Filter Methods for Nonlinear Programming: Local
                  Convergence},
  volume =       16,
  year =         2005
}

@Article{	  waldspurger2015phase,
  title =        {Phase recovery, maxcut and complex semidefinite programming},
  author =       {Waldspurger, Ir{\'e}ne and d'Aspremont, Alexandre and Mallat,
                  St{\'e}phane},
  journal =      mathprog,
  volume =       149,
  number =       {1-2},
  pages =        {47--81},
  year =         2015,
  publisher =    {Springer}
}

@Article{	  waldspurger:2015,
  author =       {I. Waldspurger, A. d'Aspremont, S. Mallat},
  title =        {Phase Recovery, MaxCut and Complex Semidefinite Programming},
  journal =      mathprog,
  year =         2015,
  month =        {February},
  volume =       149,
  pages =        {47-81}
}

@Article{	  wellwebe:2001,
  author =       {M. Welling and M. Weber},
  date-added =   {2007-09-13 22:01:05 -0700},
  date-modified ={2007-09-13 22:01:14 -0700},
  journal =      {Pattern Recog. Letters},
  pages =        {1255--1261},
  title =        {Positive tensor factorization},
  volume =       22,
  year =         2001
}

@Article{	  wen2010fast,
  title =        {A fast algorithm for sparse reconstruction based on shrinkage,
                  subspace optimization, and continuation},
  author =       {Wen, Zaiwen and Yin, Wotao and Goldfarb, Donald and Zhang,
                  Yin},
  journal =      {SIAM Journal on Scientific Computing},
  volume =       32,
  number =       4,
  pages =        {1832--1857},
  year =         2010,
  publisher =    {SIAM}
}

@Article{	  wen:2013,
  author =       {Wen, Zaiwen and Yin, Wotao},
  title =        {A feasible method for optimization with orthogonality
                  constraints},
  journal =      mathprog,
  fjournal =     {Mathematical Programming. A Publication of the Mathematical
                  Programming Society},
  volume =       142,
  year =         2013,
  number =       {1-2},
  pages =        {397--434},
  doi =          {10.1007/s10107-012-0584-1}
}

@Article{	  whi96,
  author =       "White, D. J.",
  title =        "A heuristic approach to a weighted maxmin dispersion problem",
  journal =      "IMA Journal of Management Mathematics",
  year =         1996,
  volume =       9,
  page =         {219--231}
}

@Misc{		  wiki:hello-world,
  author =       {Wikipedia},
  title =        {"Hello, World!" program --- Wikipedia{,} The Free
                  Encyclopedia},
  year =         2015,
  url =
                  "https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&page=%22Hello%2C_World%21%22_program&id=667185966",
  note =         {[Online; accessed 18-June-2015]}
}

@Misc{		  wiki:isotonic-regression,
  author =       "Wikipedia",
  title =        "Isotonic regression --- Wikipedia{,} The Free Encyclopedia",
  year =         2014,
  url =
                  "http://en.wikipedia.org/w/index.php?title=Isotonic_regression&oldid=639175260",
  note =         "[Online; accessed 28-May-2015]"
}

@Article{	  wils:1992,
  author =       {D. G. Wilson},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      {SIAG/OPT Views and News},
  pages =        {9--10},
  title =        {A brief introduction to the IBM Optimization Subroutine
                  Library},
  volume =       1,
  year =         1992
}

@Article{	  wintitabs:2013,
  year =         2013,
  journal =      jota,
  doi =          {10.1007/s10957-013-0323-7},
  title =        {Addressing Rank Degeneracy in Constraint-Reduced
                  Interior-Point Methods for Linear Optimization},
  url =          {http://dx.doi.org/10.1007/s10957-013-0323-7},
  publisher =    {Springer US},
  keywords =     {Linear programming; Linear optimization; Constraint reduction;
                  Primal–dual interior point; Regularization},
  author =       {Winternitz, LukeB. and Tits, AndréL. and Absil, P.-A.},
  pages =        {1-31},
  language =     {English}
}

@TechReport{	  wnf07,
  author =       "Wright, S. J. and Nowak, R. D. and Figueiredo, M. A. T.",
  title =        "Sparse reconstruction by separable approximation",
  institution =  "Computer Sciences Department, University of Wisconsin",
  address =      "Madison",
  year =         2007,
  month =        "October"
}

@Book{		  wolkowicz2000handbook,
  title =        {Handbook of semidefinite programming: theory, algorithms, and
                  applications},
  author =       {Wolkowicz, Henry and Saigal, Romesh and Vandenberghe, Lieven},
  volume =       27,
  year =         2000,
  publisher =    {Springer}
}

@Book{		  wri97,
  author =       "Wright, S. J.",
  title =        "Primal-Dual Interior-Point Methods",
  publisher =    "SIAM",
  year =         1997,
  address =      "Philadelphia"
}

@Article{	  wrig:1990,
  author =       {Wright, S. J.},
  coden =        {JOTABN},
  fjournal =     {Journal of Optimization Theory and Applications},
  journal =      jota,
  mrclass =      {90C05 (90C06 90C20)},
  mrnumber =     {MR1052832 (91d:90062)},
  mrreviewer =   {Christian Michelot},
  number =       3,
  pages =        {531--554},
  title =        {Implementing proximal point methods for linear programming},
  volume =       65,
  year =         1990
}

@Article{	  wrig:1998,
  author =       {M. H. Wright},
  date-modified ={2007-07-18 14:59:32 -0700},
  journal =      siamopt,
  pages =        {84-111},
  title =        {Ill-conditioning and computational error in primal-dual
                  methods for nonlinear programming},
  volume =       9,
  year =         1998
}

@inproceedings{wright2009robust,
  title =        {Robust principal component analysis: Exact recovery of
                  corrupted low-rank matrices via convex optimization},
  author =       {Wright, John and Ganesh, Arvind and Rao, Shankar and Peng,
                  Yigang and Ma, Yi},
  booktitle =    {Advances in Neural Information Processing Systems
                  (NIPS 2009)},
  pages =        {2080--2088},
  year =         2009
}

@article{wright2013compressive,
  title =        {Compressive principal component pursuit},
  author =       {Wright, John and Ganesh, Arvind and Min, Kerui and Ma, Yi},
  journal =      imainfoinfer,
  volume =       2,
  number =       1,
  pages =        {32--68},
  year =         2013,
  publisher =    {Oxford University Press}
}

@Article{	  wright:1998,
  title =        {Superlinear Convergence of a Stabilized SQP Method to a
                  Degenerate Solution},
  author =       {Wright, S.J.},
  journal =      compapplopt,
  volume =       11,
  number =       3,
  pages =        {253--275},
  year =         1998,
  publisher =    {Springer}
}

@Article{	  wright:2002,
  author =       {S. J. Wright},
  title =        {Modifying {SQP} for degenerate problems},
  journal =      siamopt,
  year =         2002,
  volume =       13,
  number =       2,
  pages =        {470--497}
}

@Article{	  wrigralp:1996,
  author =       {Stephen J. Wright and Danny Ralph},
  date-modified ={2007-07-18 14:59:31 -0700},
  journal =      mathofor,
  pages =        {815--838},
  title =        {A superliner infeasible-interior-point algorithm for monotone
                  complementarity problems},
  volume =       21,
  year =         1996
}

@Article{	  wuye:2002,
  author =       {Z. Wu and J. J. Ye},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      mathprog,
  number =       1,
  pages =        {301--314},
  title =        {On error bounds for lower semicontinuous functions},
  volume =       92,
  year =         2002
}

@TechReport{	  wyyz07,
  author =       "Y. Wang and J. Yang and W. Yin and Y. Zhang",
  title =        "A new alternating minimization algorithm for total variation
                  image reconstruction",
  institution =  "Department of Computational and Applied Mathematics, Rice
                  University",
  address =      "Houston",
  year =         2007,
  note =         "to appear in SIAM Imaging Sci."
}

@Article{	  wzyb08,
  author =       "Wang, Z. and Zheng, S. and Ye, Y. and Boyd, S.",
  title =        "Further relaxations of the semidefinite programming approach
                  to sensor network localization",
  journal =      siamopt,
  year =         2008,
  volume =       19,
  page =         {655--673}
}

@article{xiao2010dual,
  title =        {Dual averaging methods for regularized stochastic learning and
                  online optimization},
  author =       {Xiao, Lin},
  journal =      jmlr,
  volume =       11,
  number =       {Oct},
  pages =        {2543--2596},
  year =         2010
}

@Article{	  xueye:2000,
  author =       {G. Xue and Y. Ye},
  title =        {An efficient algorithm for minimizing a sum of p-norms},
  journal =      siamopt,
  volume =       10,
  number =       2,
  pages =        {551--579},
  year =         2000
}

@Misc{		  yall1:2015,
  author =       {Yin Zhang and Wei Deng and Junfeng Yang and and Wotao Yin},
  url =          {http://yall1.blogs.rice.edu/},
  year =         2011
}

@Article{	  yamashita2004identification,
  title =        {On the identification of degenerate indices in the nonlinear
                  complementarity problem with the proximal point algorithm},
  author =       {Yamashita, Nobuo and Dan, Hiroshige and Fukushima, Masao},
  journal =      mathprog,
  volume =       99,
  number =       2,
  pages =        {377--397},
  year =         2004,
  publisher =    {Springer}
}

@Article{	  yamayabe:1996,
  author =       {H. Yamashita and H. Yabe},
  date-modified ={2007-07-18 14:59:34 -0700},
  journal =      mathprog,
  pages =        {377--397},
  title =        {Superlinear and quadratic convergence of some primal-dual
                  interior point methods for constrained optimization},
  volume =       75,
  year =         1996
}

@Book{		  ye97,
  author =       "Ye, Y.",
  title =        "Interior point Algorithms: Theory and Analysis",
  publisher =    "John Wiley \& Sons",
  year =         1997,
  address =      "New York"
}

@Article{	  ye:1992,
  title =        {On the finite convergence of interior-point algorithms for
                  linear programming},
  author =       {Ye, Yinyu},
  journal =      mathprog,
  volume =       57,
  number =       {1-3},
  pages =        {325--335},
  year =         1992
}

@Book{		  ye:1997,
  address =      {Chichester, UK},
  author =       {Y. Ye},
  date-modified ={2007-07-18 14:59:33 -0700},
  publisher =    {Wiley},
  title =        {Interior-Point Algorithms: Theory and Analysis},
  year =         1997
}

@Article{	  yelm07,
  author =       "M. Yuan and A. Ekici and Z. Lu and R. Monteiro",
  title =        "Dimension reduction and coefficient estimation in multivariate
                  linear regression",
  journal =      "J. Royal Stat. Soc. B.",
  year =         2007,
  volume =       69,
  page =         {329--346}
}

@article{yin2010analysis,
  title =        {Analysis and generalizations of the linearized Bregman method},
  author =       {Yin, Wotao},
  journal =      siamsiims,
  volume =       3,
  number =       4,
  pages =        {856--877},
  year =         2010,
  publisher =    {SIAM}
}

@article{yip:1986,
  title =        {A note on the stability of solving a rank-p modification of a
                  linear system by the Sherman-Morrison-Woodbury formula},
  author =       {Yip, EL},
  journal =      siamscistatcomp,
  volume =       7,
  number =       2,
  pages =        {507--513},
  year =         1986,
  publisher =    {SIAM}
}

@Article{	  yjc08,
  author =       "Ye, J. and Ji, S. and Chen, J.",
  title =        "Multi-class discriminant kernel learning via convex
                  programming",
  journal =      "J. Machine Learning Res.",
  year =         2008,
  volume =       9,
  page =         {719--758}
}

@Article{	  yogd08,
  author =       "W. Yin and S. Osher and D. Goldfarb and J. Darbon",
  title =        "{Bregman} iterative algorithms for L1 minimization with
                  applications to compressed sensing",
  journal =      siamsiims,
  year =         2008,
  volume =       1,
  page =         {143--168}
}

@Article{	  yul06,
  author =       "M. Yuan and Y. Lin",
  title =        "Model selection and estimation in regression with grouped
                  variables",
  journal =      "J. Royal Stat. Soc. B.",
  year =         2006,
  volume =       68,
  page =         {49--67}
}

@Article{	  yul07,
  author =       "M. Yuan and Y. Lin",
  title =        "Model selection and estimation in the Gaussian graphical
                  model",
  journal =      "Biometrika",
  year =         2007,
  volume =       94,
  page =         {19--35}
}

@InProceedings{yurtsever2017sketchy,
  title =        {Sketchy Decisions: Convex Low-Rank Matrix Optimization with
                  Optimal Storage},
  author =       {Yurtsever, A. and Udell, M. and Tropp, J. A. and Cevher, V.},
  booktitle =    {International Conference on Artificial Intelligence and
                  Statistics (AISTATS 2017)},
  year =         2017,
  pages =        {1188--1196},
  comment =      {Oral Presentation}
}

@TechReport{	  yut08,
  author =       "S. Yunand K.-C. Toh",
  title =        "A coordinate gradient descent method for L1-regularized convex
                  minimization",
  institution =  "Department of Mathematics, National University of Singapore",
  address =      "Singapore",
  year =         2008,
  note =         "submitted to Comput. Optim. Appl."
}

@Article{	  yuzhaowang:2005,
  author =       {H.-Y. Yu and S.-Y. Zhao and Ge Wang},
  journal =      {Phys. Med. Biol.},
  pages =        {5583--5595},
  title =        {A differentiable Shepp-Logan phantom and its application in
                  exact cone-beam {CT}},
  volume =       50,
  year =         2005
}

@TechReport{	  yzy08,
  author =       "J. Yang and Y. Zhang and W. Yin",
  title =        "An efficient {TVL1} algorithm for deblurring multichannel
                  images corrupted by impulsive noise",
  institution =  "Department of Computational and Applied Mathematics, Rice
                  University",
  address =      "Houston",
  year =         2008
}

@article{zeng2014ordered,
  title =        {The Ordered Weighted $\ell_1$ Norm: Atomic Formulation,
                  Projections, and Algorithms},
  author =       {Zeng, Xiangrong and Figueiredo, M{\'a}rio AT},
  journal =      {arXiv:1409.4271},
  year =         2014
}

@Article{	  zhaoli:2002,
  author =       {Y.-B. Zhao and D. Li},
  date-modified ={2007-07-18 14:59:33 -0700},
  journal =      siamopt,
  number =       4,
  pages =        {893-912},
  title =        {Locating the Least 2-Norm Solution of Linear Programs via a
                  Path-Following Method},
  volume =       12,
  year =         2002
}

@TechReport{	  zhc08,
  author =       "M. Zhu and T. F. Chan",
  title =        "An efficient primal-dual hybrid gradient algorithm for total
                  variation image restoration",
  institution =  "Department of Mathematics, UCLA",
  address =      "Los Angeles",
  year =         2008
}

@InProceedings{	  zhenjaco:2008a,
  author =       {Jing Zheng and Eddie Jacobs},
  editor =       {Z. Rahman and Stephen E. Reichenbach and Mark A. Neifeld},
  title =        {Application of compressive sensing theory in infrared imaging
                  systems},
  publisher =    {SPIE},
  year =         2008,
  booktitle =    {Visual Information Processing XVII},
  volume =       6978,
  numpages =     8,
  location =     {Orlando, FL, USA},
  url =          {http://link.aip.org/link/?PSI/6978/69780J/1},
  doi =          {10.1117/12.776967}
}

@InProceedings{	  zhenjaco:2008b,
  author =       {Jing Zheng and Eddie Jacobs},
  editor =       {G. C. Holst},
  title =        {The application of Compressive Sensing technique on a
                  stationary surveillance camera system},
  publisher =    {SPIE},
  year =         2008,
  booktitle =    {Infrared Imaging Systems: Design, Analysis, Modeling, and
                  Testing XIX},
  volume =       6941,
  numpages =     8,
  location =     {Orlando, FL, USA},
  url =          {http://link.aip.org/link/?PSI/6941/69410H/1},
  doi =          {10.1117/12.779321}
}

@Article{	  zibupear:2001,
  author =       {M. Zibulevsky and B. A. Pearlmutter},
  issue =        4,
  journal =      {Neural Computation},
  pages =        {863--882},
  title =        {Blind source separation by sparse decomposition in a signal
                  dictionary},
  volume =       13,
  year =         2001
}

@Article{	  zou2005regularization,
  title =        {Regularization and variable selection via the elastic net},
  author =       {Zou, Hui and Hastie, Trevor},
  journal =      {Journal of the Royal Statistical Society: Series B
                  (Statistical Methodology)},
  volume =       67,
  number =       2,
  pages =        {301--320},
  year =         2005,
  publisher =    {Wiley Online Library}
}

@TechReport{	  zwc08,
  author =       "M. Zhu and S. J. Wright and T. F. Chan",
  title =        "Duality-based algorithms for total-variation regularized image
                  restoration",
  institution =  "Department of Mathematics, UCLA",
  address =      "Los Angeles",
  year =         2008
}

@article{bogdan2013statistical,
  title={Statistical estimation and testing via the sorted L1 norm},
  author={Bogdan, Malgorzata and Berg, Ewout van den and Su, Weijie and Cand{\`e}s, Emmanuel},
  journal={arXiv preprint arXiv:1310.1969},
  year={2013}
}

@article{bondell2008simultaneous,
  title={Simultaneous regression shrinkage, variable selection, and supervised clustering of predictors with OSCAR},
  author={Bondell, Howard D and Reich, Brian J},
  journal={Biometrics},
  volume={64},
  number={1},
  pages={115--123},
  year={2008},
  publisher={Wiley Online Library}
}

@article{bertsekas2011unifying,
  title={A unifying polyhedral approximation framework for convex optimization},
  author={Bertsekas, Dimitri P and Yu, Huizhen},
  journal= siamopt,
  volume={21},
  number={1},
  pages={333--360},
  year={2011},
  publisher={SIAM}
}

@article{kelley1960cutting,
  title={The cutting-plane method for solving convex programs},
  author={Kelley, Jr, James E},
  journal=jsiam,
  volume={8},
  number={4},
  pages={703--712},
  year={1960},
  publisher={SIAM}
}

@article{kiwiel1990proximity,
  title={Proximity control in bundle methods for convex nondifferentiable minimization},
  author={Kiwiel, Krzysztof C},
  journal=mathprog,
  volume={46},
  number={1-3},
  pages={105--122},
  year={1990},
  publisher={Springer}
}

@inproceedings{le2008bundle,
  title={Bundle methods for machine learning},
  author={Le, Quoc V and Smola, Alex J and Vishwanathan, Svn},
  booktitle={Advances in Neural Information Processing Systems
                  (NIPS 2008)},
  pages={1377--1384},
  year={2008}
}

@inproceedings{rao2015collaborative,
  title={Collaborative filtering with graph information: Consistency and scalable methods},
  author={Rao, Nikhil and Yu, Hsiang-Fu and Ravikumar, Pradeep K and Dhillon, Inderjit S},
  booktitle={Advances in Neural Information Processing Systems
                  (NIPS 2015)},
  pages={2107--2115},
  year={2015}
}

@inproceedings{belkin2002laplacian,
  title={Laplacian eigenmaps and spectral techniques for embedding and clustering},
  author={Belkin, Mikhail and Niyogi, Partha},
  booktitle={Advances in Neural Information Processing Systems
                  (NIPS 2002)},
  pages={585--591},
  year={2002}
}

@article{belkin2003laplacian,
  title={Laplacian eigenmaps for dimensionality reduction and data representation},
  author={Belkin, Mikhail and Niyogi, Partha},
  journal={Neural computation},
  volume={15},
  number={6},
  pages={1373--1396},
  year={2003},
  publisher={MIT Press}
}

@article{shechtman2015phase,
  title={Phase retrieval with application to optical imaging: a contemporary overview},
  author={Shechtman, Yoav and Eldar, Yonina C and Cohen, Oren and Chapman, Henry Nicholas and Miao, Jianwei and Segev, Mordechai},
  journal=ieeesigprocmag,
  volume={32},
  number={3},
  pages={87--109},
  year={2015},
  publisher={IEEE}
}

@article{chi2020harnessing,
  title={Harnessing Sparsity Over the Continuum: Atomic norm minimization for superresolution},
  author={Chi, Yuejie and Da Costa, Maxime Ferreira},
  journal=ieeesigprocmag,
  volume={37},
  number={2},
  pages={39--57},
  year={2020},
  publisher={IEEE}
}

@article{Meinshausen06,
  author = {Meinshausen, Nicolai and Buhlmann, Peter},
  year = {2006},
  month = {09},
  pages = {},
  title = {High dimensional graphs and variable selection with the LASSO},
  volume = {34},
  journal = {The Annals of Statistics}
}

@article{Ghaoui12,
  author    = {Laurent El Ghaoui and
               Vivian Viallon and
               Tarek Rabbani},
  title     = {Safe Feature Elimination in Sparse Supervised Learning},
  journal   = {J. Pacific Optim.},
  volume    = {8},
  number    = {4},
  pages     = {667--698},
  year      = {2012}
}

@inproceedings{wang2013lasso,
  title={Lasso Screening Rules via Dual Polytope Projection.},
  author={Wang, Jie and Zhou, Jiayu and Wonka, Peter and Ye, Jieping},
  booktitle={Advances in Neural Information Processing Systems (NIPS 2013)},
  pages={1070--1078},
  year={2013},
  organization={Citeseer}
}

@inproceedings{liu2014safe,
  title={Safe screening with variational inequalities and its application to lasso},
  author={Liu, Jun and Zhao, Zheng and Wang, Jie and Ye, Jieping},
  booktitle={International Conference on Machine Learning},
  pages={289--297},
  year={2014},
  organization={PMLR}
}

@inproceedings{WangZLWY14,
  author    = {Jie Wang and
               Jiayu Zhou and
               Jun Liu and
               Peter Wonka and
               Jieping Ye},
  title     = {A Safe Screening Rule for Sparse Logistic Regression},
  booktitle={Advances in Neural Information Processing Systems (NIPS 2014)},
  pages     = {1053--1061},
  year      = {2014}
}

@article{Raj2015ScreeningRF,
  title={Screening Rules for Convex Problems},
  author={Anant Raj and Jakob Olbrich and Bernd G{\"a}rtner and Bernhard Sch{\"o}lkopf and Martin Jaggi},
  journal={ArXiv},
  year={2015},
  volume={abs/1609.07478}
}

@article{BonnefoyERG15,
  author    = {Antoine Bonnefoy and
               Valentin Emiya and
               Liva Ralaivola and
               R{\'{e}}mi Gribonval},
  title     = {Dynamic Screening: Accelerating First-Order Algorithms for the Lasso
               and Group-Lasso},
  journal   = ieeetranssigproc,
  volume    = {63},
  number    = {19},
  pages     = {5121--5132},
  year      = {2015}
}

@article{XiangWR17,
  author    = {Zhen James Xiang and
               Yun Wang and
               Peter J. Ramadge},
  title     = {Screening Tests for Lasso Problems},
  journal   = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  volume    = {39},
  number    = {5},
  pages     = {1008--1027},
  year      = {2017}
}

@article{NdiayeFGS17,
  author    = {Eug{\`{e}}ne Ndiaye and
               Olivier Fercoq and
               Alexandre Gramfort and
               Joseph Salmon},
  title     = {Gap Safe Screening Rules for Sparsity Enforcing Penalties},
  journal   = {J. Mach. Learn. Res.},
  volume    = {18},
  pages     = {128:1--128:33},
  year      = {2017}
}

@inproceedings{ZhangHLYCHW17,
  author    = {Weizhong Zhang and
               Bin Hong and
               Wei Liu and
               Jieping Ye and
               Deng Cai and
               Xiaofei He and
               Jie Wang},
  title     = {Scaling Up Sparse Support Vector Machines by Simultaneous Feature
               and Sample Reduction},
  booktitle = {Proceedings of ICML},
  year      = {2017},
}

@article{kuang2017screening,
  title={A Screening Rule for $\ell_1$-Regularized Ising Model Estimation},
  author={Kuang, Zhaobin and Geng, Sinong and Page, David},
  journal={Advances in neural information processing systems (NIPS 2017)},
  volume={30},
  pages={720},
  year={2017},
  publisher={NIH Public Access}
}

@inproceedings{Atamtrk2020SafeSR,
  title={Safe Screening Rules for l0-Regression},
  author={Alper Atamturk and Andres Gomez},
  booktitle = {Proceedings of ICML},
  year={2020}
}

@inproceedings{Bao20,
  title={Fast OSCAR and OWL with safe screening rules},
  author={Runxue Bao and Bin Gu and Heng Huang},
  booktitle = {Proceedings of ICML},
  year={2020}
}

@inproceedings{ZhouZ15,
  title     = {Safe Subspace Screening for Nuclear Norm Regularized Least Squares Problems},
  author    = {Qiang Zhou and Qi Zhao},
  booktitle = {Proceedings of ICML},
  pages     = {1103--1112},
  year      = {2015}
}

@article{Sun2020SafeSF,
  title={Safe Screening for the Generalized Conditional Gradient Method},
  author={Yifan Sun and Francis R. Bach},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.09718}
}

@article{FanS2010,
  author = {Jianqing Fan and Rui Song},
  title = {Sure Independence Screening in Generalized Linear Models with NP-dimensionality},
  journal   = {Annals of Statistics},
  volume    = {38},
  number    =  {6},
  pages     = {3567--3604},
  year      = {2010}
}

@article{FanFS2011,
  author = {Jianqing Fan and Yang Feng and Rui Song},
  title = {Nonparametric Independence Screening in Sparse Ultra-High-Dimensional Additive Models},
  journal   = jasa,
  volume    = {106},
  number    = {494},
  pages     = {544--557},
  year      = {2011}
}

@article{ZhuLLZ2011,
  author = {Li-Ping Zhu and Lexin Li and Runze Li and Li-Xing Zhu},
  title = {Model-Free Feature Screening for Ultrahigh-Dimensional Data},
  journal = jasa,
  volume = {106},
  number = {496},
  pages = {1464-1475},
  year  = {2011},
  publisher = {Taylor & Francis},
  URL = { https://doi.org/10.1198/jasa.2011.tm10563},
}

@InCollection{svmlight,
    author =   {T. Joachims},
    booktitle =  {Advances in Kernel Methods - Support Vector
                    Learning},
    title =  {Making large-Scale {SVM} Learning Practical},
    publisher =  {MIT Press},
    address =  {Cambridge, MA},
    year =   1999,
    chapter =  11,
    pages =  {169--184}
}

@article{tibshirani2012strong,
  title={Strong rules for discarding predictors in lasso-type problems},
  author={Tibshirani, Robert and Bien, Jacob and Friedman, Jerome and Hastie, Trevor and Simon, Noah and Taylor, Jonathan and Tibshirani, Ryan J},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={74},
  number={2},
  pages={245--266},
  year={2012},
  publisher={Wiley Online Library}
}

@article{krislock2010explicit,
  title={Explicit sensor network localization using semidefinite representations and facial reductions},
  author={Krislock, Nathan and Wolkowicz, Henry},
  journal=siamopt,
  volume={20},
  number={5},
  pages={2679--2708},
  year={2010},
  publisher={SIAM}
}

@article{Oustry00,
  author    = {Fran{\c{c}}ois Oustry},
  title     = {A second-order bundle method to minimize the maximum eigenvalue function},
  journal   = mathprog,
  volume    = {89},
  number    = {1},
  pages     = {1--33},
  year      = {2000}
}

@article{kakade2009duality,
  title={On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization},
  author={Kakade, Sham and Shalev-Shwartz, Shai and Tewari, Ambuj},
  journal={Unpublished Manuscript, http://ttic. uchicago. edu/shai/papers/KakadeShalevTewari09. pdf},
  volume={2},
  number={1},
  year={2009}
}

@book{dumitrescu2007positive,
  title={Positive trigonometric polynomials and signal processing applications},
  author={Dumitrescu, Bogdan},
  volume={103},
  year={2007},
  publisher={Springer}
}

@article{nutini2019active,
  title={“Active-set complexity” of proximal gradient: How long does it take to find the sparsity pattern?},
  author={Nutini, Julie and Schmidt, Mark and Hare, Warren},
  journal={Optimization Letters},
  volume={13},
  number={4},
  pages={645--655},
  year={2019},
  publisher={Springer}
}

@inproceedings{rennie2005fast,
  title={Fast maximum margin matrix factorization for collaborative prediction},
  author={Rennie, Jasson DM and Srebro, Nathan},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={713--719},
  year={2005}
}

@article{candes2010matrix,
  title={Matrix completion with noise},
  author={Candes, Emmanuel J and Plan, Yaniv},
  journal={Proceedings of the IEEE},
  volume={98},
  number={6},
  pages={925--936},
  year={2010},
  publisher={IEEE}
}

@article{georghiades2001few,
  title={From few to many: Illumination cone models for face recognition under variable lighting and pose},
  author={Georghiades, Athinodoros S. and Belhumeur, Peter N. and Kriegman, David J.},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={23},
  number={6},
  pages={643--660},
  year={2001},
  publisher={IEEE}
}

@article{bezanson2017julia,
  title={Julia: A fresh approach to numerical computing},
  author={Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
  journal={SIAM review},
  volume={59},
  number={1},
  pages={65--98},
  year={2017},
  publisher={SIAM}
}

@article{ahmed2013blind,
  title={Blind deconvolution using convex programming},
  author={Ahmed, Ali and Recht, Benjamin and Romberg, Justin},
  journal=ieeetransinfo,
  volume={60},
  number={3},
  pages={1711--1732},
  year={2013},
  publisher={IEEE}
}

@article{mccoy2014sharp,
  title={Sharp recovery bounds for convex demixing, with applications},
  author={McCoy, Michael B and Tropp, Joel A},
  journal=focm,
  volume={14},
  number={3},
  pages={503--567},
  year={2014},
  publisher={Springer}
}

@inproceedings{starck2005morphological,
  title={Morphological component analysis},
  author={Starck, J-L and Moudden, Y and Bobin, J and Elad, M and Donoho, DL},
  booktitle={Wavelets XI},
  volume={5914},
  pages={59140Q},
  year={2005},
  organization={International Society for Optics and Photonics}
}

@article{shalev2011online,
  title={Online learning and online convex optimization},
  author={Shalev-Shwartz, Shai and others},
  journal={Foundations and trends in Machine Learning},
  volume={4},
  number={2},
  pages={107--194},
  year={2011}
}

@article{tropp2012comparison,
  title={A comparison principle for functions of a uniformly random subspace},
  author={Tropp, Joel A},
  journal={Probability Theory and Related Fields},
  volume={153},
  number={3},
  pages={759--769},
  year={2012},
  publisher={Springer}
}

@book{meckes2019random,
  title={The random matrix theory of the classical compact groups},
  author={Meckes, Elizabeth S},
  volume={218},
  year={2019},
  publisher={Cambridge University Press}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}

@article{li2020review,
  title={A review of applications in federated learning},
  author={Li, Li and Fan, Yuxi and Tse, Mike and Lin, Kuo-Yi},
  journal={Computers \& Industrial Engineering},
  pages={106854},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Proceedings of AISTATS},
  pages={1273--1282},
  year={2017},
}

@article{yang2019federated,
  title={Federated machine learning: Concept and applications},
  author={Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={10},
  number={2},
  pages={1--19},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{wang2021field,
  title={A field guide to federated optimization},
  author={Wang, Jianyu and Charles, Zachary and Xu, Zheng and Joshi, Gauri and McMahan, H Brendan and Al-Shedivat, Maruan and Andrew, Galen and Avestimehr, Salman and Daly, Katharine and Data, Deepesh and others},
  journal={arXiv preprint arXiv:2107.06917},
  year={2021}
}

@inproceedings{li2019convergence,
  title={On the convergence of fedavg on non-iid data},
  author={Li, Xiang and Huang, Kaixuan and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
  booktitle={Proceedings of ICLR},
  year={2020}
}

@article{kairouz2019advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={arXiv preprint arXiv:1912.04977},
  year={2019}
}

@article{li2018federated,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={Proceedings of MLSys},
  year={2020}
}

@inproceedings{yuan2021federated,
  title={Federated composite optimization},
  author={Yuan, Honglin and Zaheer, Manzil and Reddi, Sashank},
  booktitle={Proceedings of ICML},
  pages={12253--12266},
  year={2021},
}

@inproceedings{karimireddy2020mime,
  title={Mime: Mimicking centralized stochastic algorithms in federated learning},
  author={Karimireddy, Sai Praneeth and Jaggi, Martin and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank J and Stich, Sebastian U and Suresh, Ananda Theertha},
  booktitle={Proceedings of NeurIPS},
  year={2021}
}

@article{li2020federated,
  title={Federated learning: Challenges, methods, and future directions},
  author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={IEEE Signal Processing Magazine},
  volume={37},
  number={3},
  pages={50--60},
  year={2020},
  publisher={IEEE}
}

@inproceedings{zeng2008fast,
  title={Fast training support vector machines using parallel sequential minimal optimization},
  author={Zeng, Zhi-Qiang and Yu, Hong-Bin and Xu, Hua-Rong and Xie, Yan-Qi and Gao, Ji},
  booktitle={2008 3rd international conference on intelligent system and knowledge engineering},
  volume={1},
  pages={997--1001},
  year={2008},
  organization={IEEE}
}

@article{joachims1999making,
  title={Making large-scale support vector machine learning practical, Advances in Kernel Methods},
  author={Joachims, Thorsten},
  journal={Support vector learning},
  year={1999},
  publisher={MIT press}
}

@article{jakovetic2014linear,
  title={Linear convergence rate of a class of distributed augmented lagrangian algorithms},
  author={Jakoveti{\'c}, Du{\v{s}}an and Moura, Jos{\'e} MF and Xavier, Joao},
  journal={IEEE Transactions on Automatic Control},
  volume={60},
  number={4},
  pages={922--936},
  year={2014},
  publisher={IEEE}
}

@inproceedings{wei2012distributed,
  title={Distributed alternating direction method of multipliers},
  author={Wei, Ermin and Ozdaglar, Asuman},
  booktitle={2012 IEEE 51st IEEE Conference on Decision and Control (CDC)},
  pages={5445--5450},
  year={2012},
  organization={IEEE}
}

@inproceedings{scaman2017optimal,
  title={Optimal algorithms for smooth and strongly convex distributed optimization in networks},
  author={Scaman, Kevin and Bach, Francis and Bubeck, S{\'e}bastien and Lee, Yin Tat and Massouli{\'e}, Laurent},
  booktitle={international conference on machine learning},
  pages={3027--3036},
  year={2017},
  organization={PMLR}
}

@article{liu2021decentralized,
  title={Decentralized Learning With Lazy and Approximate Dual Gradients},
  author={Liu, Yanli and Sun, Yuejiao and Yin, Wotao},
  journal={IEEE Transactions on Signal Processing},
  volume={69},
  pages={1362--1377},
  year={2021},
  publisher={IEEE}
}

@inproceedings{koloskova2020unified,
  title={A unified theory of decentralized SGD with changing topology and local updates},
  author={Koloskova, Anastasia and Loizou, Nicolas and Boreiri, Sadra and Jaggi, Martin and Stich, Sebastian},
  booktitle={International Conference on Machine Learning},
  pages={5381--5393},
  year={2020},
  organization={PMLR}
}

@article{dembo1982inexact,
  title={Inexact newton methods},
  author={Dembo, Ron S and Eisenstat, Stanley C and Steihaug, Trond},
  journal={SIAM Journal on Numerical analysis},
  volume={19},
  number={2},
  pages={400--408},
  year={1982},
  publisher={SIAM}
}

@article{lewis2004rcv1,
  title={Rcv1: A new benchmark collection for text categorization research},
  author={Lewis, David D and Yang, Yiming and Russell-Rose, Tony and Li, Fan},
  journal={Journal of machine learning research},
  volume={5},
  number={Apr},
  pages={361--397},
  year={2004},
  publisher={Goldsmiths, University of London}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{Scaman2017OptimalAF,
  title={Optimal Algorithms for Smooth and Strongly Convex Distributed Optimization in Networks},
  author={Kevin Scaman and Francis R. Bach and S{\'e}bastien Bubeck and Yin Tat Lee and Laurent Massouli{\'e}},
  booktitle={Proceedings of ICML},
  year={2017}
}

@article{necoara2017random,
  title={Random block coordinate descent methods for linearly constrained optimization over networks},
  author={Necoara, Ion and Nesterov, Yurii and Glineur, Fran{\c{c}}ois},
  journal={Journal of Optimization Theory and Applications},
  volume={173},
  number={1},
  pages={227--254},
  year={2017},
  publisher={Springer}
}

@book{Bertsekas89,
    author = {Bertsekas, Dimitri P. and Tsitsiklis, John N.},
    title = {Parallel and Distributed Computation: Numerical Methods},
    year = {1989},
    isbn = {0136487009},
    publisher = {Prentice-Hall, Inc.},
    address = {USA}
}

@article{BoydGPS06,
  author    = {Stephen P. Boyd and
               Arpita Ghosh and
               Balaji Prabhakar and
               Devavrat Shah},
  title     = {Randomized gossip algorithms},
  journal   = {{IEEE} Trans. Inf. Theory},
  volume    = {52},
  number    = {6},
  pages     = {2508--2530},
  year      = {2006}
}

@article{NedicO09,
  author    = {Angelia Nedic and
               Asuman E. Ozdaglar},
  title     = {Distributed Subgradient Methods for Multi-Agent Optimization},
  journal   = {{IEEE} Trans. Autom. Control.},
  volume    = {54},
  number    = {1},
  pages     = {48--61},
  year      = {2009}
}

@article{DuchiAW12,
  author    = {John C. Duchi and
               Alekh Agarwal and
               Martin J. Wainwright},
  title     = {Dual Averaging for Distributed Optimization: Convergence Analysis
               and Network Scaling},
  journal   = {{IEEE} Trans. Autom. Control.},
  volume    = {57},
  number    = {3},
  pages     = {592--606},
  year      = {2012}
}

@article{RichtarikT16,
  author    = {Peter Richt{\'{a}}rik and
               Martin Tak{\'{a}}c},
  title     = {Parallel coordinate descent methods for big data optimization},
  journal   = {Mathematical Programming},
  volume    = {156},
  number    = {1-2},
  pages     = {433--484},
  year      = 2016
}

@article{ShiLWY15,
  author    = {Wei Shi and
               Qing Ling and
               Gang Wu and
               Wotao Yin},
  title     = {{EXTRA:} An Exact First-Order Algorithm for Decentralized Consensus
               Optimization},
  journal   = {{SIAM} J. Optim.},
  volume    = {25},
  number    = {2},
  pages     = {944--966},
  year      = {2015}
}

@inproceedings{WoodworthPS20,
  author    = {Blake E. Woodworth and
               Kumar Kshitij Patel and
               Nati Srebro},
  title     = {Minibatch vs Local {SGD} for Heterogeneous Distributed Learning},
  booktitle = {Proceedings of NeurIPS},
  year      = {2020},
}

@article{McMahan17,
  author    = {H. Brendan McMahan},
  title     = {A survey of Algorithms and Analysis for Adaptive Online Learning},
  journal   = {Journal of Machine Learning Research},
  volume    = {18},
  pages     = {90:1--90:50},
  year      = {2017}
}

@InProceedings{pmlr-v119-karimireddy20a,
  title = 	 {{SCAFFOLD}: Stochastic Controlled Averaging for Federated Learning},
  author =       {Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={Proceedings of ICML},
  pages = 	 {5132--5143},
  year = 	 {2020}
}

@article{platt1998sequential,
  title={Sequential Minimal Optimization : A Fast Algorithm for Training Support Vector Machines},
  author={John Platt},
  journal={Microsoft Research Technical Report},
  year={1998}
}

@article{libsvm,
    author = {Chang, Chih-Chung and Lin, Chih-Jen},
    title = {{LIBSVM}: A library for support vector machines},
    journal = {ACM Transactions on Intelligent Systems and Technology},
    volume = 2,
    issue = 3,
    year = 2011,
    pages = {27:1--27:27},
    note =	 {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}}
}

@article{CassioliLS13,
  author    = {Andrea Cassioli and
               David Di Lorenzo and
               Marco Sciandrone},
  title     = {On the convergence of inexact block coordinate descent methods for
               constrained optimization},
  journal   = {Eur. J. Oper. Res.},
  volume    = {231},
  number    = {2},
  pages     = {274--281},
  year      = {2013}
}

@article{TappendenRG16,
  author    = {Rachael Tappenden and
               Peter Richt{\'{a}}rik and
               Jacek Gondzio},
  title     = {Inexact Coordinate Descent: Complexity and Preconditioning},
  journal   = {J. Optim. Theory Appl.},
  volume    = {170},
  number    = {1},
  pages     = {144--176},
  year      = {2016}
}

@article{LiuSY21,
  author    = {Yanli Liu and
               Yuejiao Sun and
               Wotao Yin},
  title     = {Decentralized Learning With Lazy and Approximate Dual Gradients},
  journal   = {{IEEE} Trans. Signal Process.},
  volume    = {69},
  pages     = {1362--1377},
  year      = {2021}
}

@inproceedings{JohnsonZ13,
 author = {Johnson, Rie and Zhang, Tong},
 booktitle = {Proceedings of {NeurIPS}},
 pages = {315--323},
 title = {Accelerating Stochastic Gradient Descent using Predictive Variance Reduction},
 volume = {26},
 year = {2013}
}

@inproceedings{DefazioBL14,
 author = {Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
 booktitle = {Proceedings of {NeurIPS}},
 pages = {1646--1654},
 title = {SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives},
 volume = {27},
 year = {2014}
}

@book{cvxopt_lecture,
    author    = {Yurii E. Nesterov},
    title     = {Introductory Lectures on Convex Optimization - {A} Basic Course},
    series    = {Applied Optimization},
    volume    = 87,
    publisher = {Springer},
    year      = 2004
}

@article{Nesterov12,
    author    = {Yurii Nesterov},
    title     = {Efficiency of Coordinate Descent Methods on Huge-Scale Optimization
                 Problems},
    journal   = {SIAM Journal on Optimization},
    volume    = 22,
    number    = 2,
    pages     = {341--362},
    year      = 2012
}

@inproceedings{LeeS13,
    author    = {Yin Tat Lee and
               Aaron Sidford},
    title     = {Efficient Accelerated Coordinate Descent Methods and Faster Algorithms
               for Solving Linear Systems},
    booktitle = {Proceedings of FOCS},
    pages     = {147--156},
    year      = 2013
}

@article{LinLX15,
  author    = {Qihang Lin and
               Zhaosong Lu and
               Lin Xiao},
  title     = {An Accelerated Randomized Proximal Coordinate Gradient Method and
               its Application to Regularized Empirical Risk Minimization},
  journal   = {{SIAM} Journal on Optimization},
  volume    = {25},
  number    = {4},
  pages     = {2244--2273},
  year      = {2015}
}

@inproceedings{ZhuQRY16,
    author    = {Zeyuan {Allen Zhu} and
               Zheng Qu and
               Peter Richt{\'{a}}rik and
               Yang Yuan},
    title     = {Even Faster Accelerated Coordinate Descent Using Non-Uniform Sampling},
    booktitle = {Proceedings of {ICML}},
    pages     = {1110--1119},
    year      = 2016
}

@article{NesterovAccCD,
  author    = {Yurii Nesterov and Sebastian Stich},
  title     = {Efficiency of accelerated coordinate descent method on
structured optimization problems.},
  journal   = {Technical report, CORE Discussion Papers},
  year      = {2016}
}

@InProceedings{Lu18,
  title = 	 {Accelerating Greedy Coordinate Descent Methods},
  author =       {Lu, Haihao and Freund, Robert and Mirrokni, Vahab},
  booktitle = 	 {Proceedings of ICML},
  pages = 	 {3257--3266},
  year = 	 {2018}
}

@inproceedings{Scaman2018OptimalAF,
  title={Optimal Algorithms for Non-Smooth Distributed Optimization in Networks},
  author={Kevin Scaman and Francis R. Bach and S{\'e}bastien Bubeck and Yin Tat Lee and Laurent Massouli{\'e}},
  booktitle={Proceedings of NeurIPS},
  year={2018}
}

@article{LiuW15,
  author    = {Ji Liu and
               Stephen J. Wright},
  title     = {Asynchronous Stochastic Coordinate Descent: Parallelism and Convergence
               Properties},
  journal   = {{SIAM} Journal on Optimization},
  volume    = {25},
  number    = {1},
  pages     = {351--376},
  year      = 2015
}

@article{0002WRBS15,
    author    = {Ji Liu and
               Stephen J. Wright and
               Christopher R{\'{e}} and
               Victor Bittorf and
               Srikrishna Sridhar},
    title     = {An asynchronous parallel stochastic coordinate descent algorithm},
    journal   = {Journal Machine Learning Research},
    volume    = {16},
    pages     = {285--322},
    year      = 2015
}

@misc{BCD_julie,
    Author = {Julie Nutini and Issam Laradji and Mark Schmidt},
    Title = {Let's Make Block Coordinate Descent Go Fast: Faster Greedy Rules, Message-Passing, Active-Set Complexity, and Superlinear Convergence},
    Year = {2017},
    Eprint = {arXiv:1712.08859},
}

@inproceedings{NutiniSLFK15,
    author    = {Julie Nutini and
                 Mark W. Schmidt and
                 Issam H. Laradji and
                 Michael P. Friedlander and
                 Hoyt A. Koepke},
    title     = {Coordinate Descent Converges Faster with the Gauss-Southwell Rule
                 Than Random Selection},
    booktitle = {Proceedings of the International Conference on Machine Learning},
    pages     = {1632--1641},
    year      = 2015
}

@inproceedings{federated2016,
title	= {Federated Learning: Strategies for Improving Communication Efficiency},
author	= {Jakub Konecny and H. Brendan McMahan and Felix X. Yu and Peter Richtarik and Ananda Theertha Suresh and Dave Bacon},
year	= {2016},
URL	= {https://arxiv.org/abs/1610.05492},
booktitle	= {NIPS Workshop on Private Multi-Party Machine Learning}
}


@article{zhang2020hierarchically,
  title={Hierarchically fair federated learning},
  author={Zhang, Jingfeng and Li, Cheng and Robles-Kelly, Antonio and Kankanhalli, Mohan},
  journal={arXiv preprint arXiv:2004.10386},
  year={2020}
}

@inproceedings{song2019profit,
  title={Profit allocation for federated learning},
  author={Song, Tianshu and Tong, Yongxin and Wei, Shuyue},
  booktitle={2019 IEEE International Conference on Big Data (Big Data)},
  pages={2577--2586},
  year={2019},
  organization={IEEE}
}

@incollection{wei2020efficient,
  title={Efficient and Fair Data Valuation for Horizontal Federated Learning},
  author={Wei, Shuyue and Tong, Yongxin and Zhou, Zimu and Song, Tianshu},
  booktitle={Federated Learning},
  pages={139--152},
  year={2020},
  publisher={Springer}
}

@incollection{wang2020principled,
  title={A Principled Approach to Data Valuation for Federated Learning},
  author={Wang, Tianhao and Rausch, Johannes and Zhang, Ce and Jia, Ruoxi and Song, Dawn},
  booktitle={Federated Learning},
  pages={153--167},
  year={2020},
  publisher={Springer}
}

@techreport{shapley201617,
  title={A VALUE FOR N-PERSON GAMES},
  author={Shapley, LS},
  year={1952},
  institution={RAND CORP SANTA MONICA CA}
}

@inproceedings{nishio2019client,
  title={Client selection for federated learning with heterogeneous resources in mobile edge},
  author={Nishio, Takayuki and Yonetani, Ryo},
  booktitle={ICC 2019-2019 IEEE International Conference on Communications (ICC)},
  pages={1--7},
  year={2019},
  organization={IEEE}
}

@article{koutris2015query,
  title={Query-based data pricing},
  author={Koutris, Paraschos and Upadhyaya, Prasang and Balazinska, Magdalena and Howe, Bill and Suciu, Dan},
  journal={Journal of the ACM (JACM)},
  volume={62},
  number={5},
  pages={1--44},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@article{koutris2012querymarket,
  title={Querymarket demonstration: Pricing for online data markets},
  author={Koutris, Paraschos and Upadhyaya, Prasang and Balazinska, Magdalena and Howe, Bill and Suciu, Dan},
  journal={Proceedings of the VLDB Endowment},
  volume={5},
  number={12},
  pages={1962--1965},
  year={2012},
  publisher={VLDB Endowment}
}

@inproceedings{koutris2013toward,
  title={Toward practical query pricing with querymarket},
  author={Koutris, Paraschos and Upadhyaya, Prasang and Balazinska, Magdalena and Howe, Bill and Suciu, Dan},
  booktitle={proceedings of the 2013 ACM SIGMOD international conference on management of data},
  pages={613--624},
  year={2013}
}

@article{heckman2015pricing,
  title={A pricing model for data markets},
  author={Heckman, Judd Randolph and Boehmer, Erin Laurel and Peters, Elizabeth Hope and Davaloo, Milad and Kurup, Nikhil Gopinath},
  journal={iConference 2015 Proceedings},
  year={2015},
  publisher={iSchools}
}

@article{pipino2002data,
  title={Data quality assessment},
  author={Pipino, Leo L and Lee, Yang W and Wang, Richard Y},
  journal={Communications of the ACM},
  volume={45},
  number={4},
  pages={211--218},
  year={2002},
  publisher={ACM New York, NY, USA}
}

@article{pei2020survey,
  title={A survey on data pricing: from economics to data science},
  author={Pei, Jian},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2020},
  publisher={IEEE}
}

@article{cong2021data,
  title={Data Pricing in Machine Learning Pipelines},
  author={Cong, Zicun and Luo, Xuan and Jian, Pei and Zhu, Feida and Zhang, Yong},
  journal={arXiv preprint arXiv:2108.07915},
  year={2021}
}

@article{gul1989bargaining,
  title={Bargaining foundations of Shapley value},
  author={Gul, Faruk},
  journal={Econometrica: Journal of the Econometric Society},
  pages={81--95},
  year={1989},
  publisher={JSTOR}
}

@article{dubey1975uniqueness,
  title={On the uniqueness of the Shapley value},
  author={Dubey, Pradeep},
  journal={International Journal of Game Theory},
  volume={4},
  number={3},
  pages={131--139},
  year={1975},
  publisher={Springer}
}

@article{cohen2005feature,
  title={Feature selection based on the shapley value},
  author={Cohen, Shay and Ruppin, Eytan and Dror, Gideon},
  journal={In other words},
  volume={1},
  pages={98Eqr},
  year={2005}
}

@inproceedings{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  booktitle={Proceedings of the 31st international conference on neural information processing systems},
  pages={4768--4777},
  year={2017}
}

@article{strumbelj2010efficient,
  title={An efficient explanation of individual classifications using game theory},
  author={Strumbelj, Erik and Kononenko, Igor},
  journal={The Journal of Machine Learning Research},
  volume={11},
  pages={1--18},
  year={2010},
  publisher={JMLR. org}
}

@inproceedings{ghorbani2019data,
  title={Data shapley: Equitable valuation of data for machine learning},
  author={Ghorbani, Amirata and Zou, James},
  booktitle={International Conference on Machine Learning},
  pages={2242--2251},
  year={2019},
  organization={PMLR}
}

@inproceedings{jia2019towards,
  title={Towards efficient data valuation based on the shapley value},
  author={Jia, Ruoxi and Dao, David and Wang, Boxin and Hubis, Frances Ann and Hynes, Nick and G{\"u}rel, Nezihe Merve and Li, Bo and Zhang, Ce and Song, Dawn and Spanos, Costas J},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={1167--1176},
  year={2019},
  organization={PMLR}
}

@inproceedings{ghorbani2020distributional,
  title={A distributional framework for data valuation},
  author={Ghorbani, Amirata and Kim, Michael and Zou, James},
  booktitle={International Conference on Machine Learning},
  pages={3535--3544},
  year={2020},
  organization={PMLR}
}

@inproceedings{kwon2021efficient,
  title={Efficient computation and analysis of distributional Shapley values},
  author={Kwon, Yongchan and Rivas, Manuel A and Zou, James},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={793--801},
  year={2021},
  organization={PMLR}
}

@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={International Conference on Machine Learning},
  pages={1885--1894},
  year={2017},
  organization={PMLR}
}

@article{hampel1974influence,
  title={The influence curve and its role in robust estimation},
  author={Hampel, Frank R},
  journal={Journal of the american statistical association},
  volume={69},
  number={346},
  pages={383--393},
  year={1974},
  publisher={Taylor \& Francis}
}

@inproceedings{wang2019measure,
  title={Measure contribution of participants in federated learning},
  author={Wang, Guan and Dang, Charlie Xiaoqian and Zhou, Ziye},
  booktitle={2019 IEEE International Conference on Big Data (Big Data)},
  pages={2597--2604},
  year={2019},
  organization={IEEE}
}

@inproceedings{yoon2020data,
  title={Data valuation using reinforcement learning},
  author={Yoon, Jinsung and Arik, Sercan and Pfister, Tomas},
  booktitle={International Conference on Machine Learning},
  pages={10842--10851},
  year={2020},
  organization={PMLR}
}

@inproceedings{zhao2021efficient,
  title={Efficient Client Contribution Evaluation for Horizontal Federated Learning},
  author={Zhao, Jie and Zhu, Xinghua and Wang, Jianzong and Xiao, Jing},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3060--3064},
  year={2021},
  organization={IEEE}
}

@article{lecun-mnisthandwrittendigit-2010,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

@inproceedings{Krizhevsky09learningmultiple,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Alex Krizhevsky},
  year={2009}
}

@article{udell2019big,
  title={Why are big data matrices approximately low rank?},
  author={Udell, Madeleine and Townsend, Alex},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={1},
  number={1},
  pages={144--160},
  year={2019},
  publisher={SIAM}
}

@article{koren2009matrix,
  title={Matrix factorization techniques for recommender systems},
  author={Koren, Yehuda and Bell, Robert and Volinsky, Chris},
  journal={Computer},
  volume={42},
  number={8},
  pages={30--37},
  year={2009},
  publisher={IEEE}
}

@book{keshavan2012efficient,
  title={Efficient algorithms for collaborative filtering},
  author={Keshavan, Raghunandan Hulikal},
  year={2012},
  publisher={Stanford University}
}

@article{sun2016guaranteed,
  title={Guaranteed matrix completion via non-convex factorization},
  author={Sun, Ruoyu and Luo, Zhi-Quan},
  journal={IEEE Transactions on Information Theory},
  volume={62},
  number={11},
  pages={6535--6579},
  year={2016},
  publisher={IEEE}
}

@article{yu2014parallel,
  title={Parallel matrix factorization for recommender systems},
  author={Yu, Hsiang-Fu and Hsieh, Cho-Jui and Si, Si and Dhillon, Inderjit S},
  journal={Knowledge and Information Systems},
  volume={41},
  number={3},
  pages={793--819},
  year={2014},
  publisher={Springer}
}

@article{chin2016libmf,
  title={LIBMF: A Library for Parallel Matrix Factorization in Shared-memory Systems.},
  author={Chin, Wei-Sheng and Yuan, Bo-Wen and Yang, Meng-Yuan and Zhuang, Yong and Juan, Yu-Chin and Lin, Chih-Jen},
  journal={J. Mach. Learn. Res.},
  volume={17},
  number={1},
  pages={2971--2975},
  year={2016}
}

@inproceedings{zemel2013learning,
  title={Learning fair representations},
  author={Zemel, Rich and Wu, Yu and Swersky, Kevin and Pitassi, Toni and Dwork, Cynthia},
  booktitle={International conference on machine learning},
  pages={325--333},
  year={2013},
  organization={PMLR}
}

@article{donini2018empirical,
  title={Empirical risk minimization under fairness constraints},
  author={Donini, Michele and Oneto, Luca and Ben-David, Shai and Shawe-Taylor, John S and Pontil, Massimiliano},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{li2019fair,
  title={Fair resource allocation in federated learning},
  author={Li, Tian and Sanjabi, Maziar and Beirami, Ahmad and Smith, Virginia},
  journal={arXiv preprint arXiv:1905.10497},
  year={2019}
}

@incollection{lyu2020collaborative,
  title={Collaborative fairness in federated learning},
  author={Lyu, Lingjuan and Xu, Xinyi and Wang, Qian and Yu, Han},
  booktitle={Federated Learning},
  pages={189--204},
  year={2020},
  publisher={Springer}
}

@article{chu2021fedfair,
  title={Fedfair: Training fair models in cross-silo federated learning},
  author={Chu, Lingyang and Wang, Lanjun and Dong, Yanjie and Pei, Jian and Zhou, Zirui and Zhang, Yong},
  journal={arXiv preprint arXiv:2109.05662},
  year={2021}
}

@article{metropolis1949monte,
  title={The monte carlo method},
  author={Metropolis, Nicholas and Ulam, Stanislaw},
  journal={Journal of the American statistical association},
  volume={44},
  number={247},
  pages={335--341},
  year={1949},
  publisher={Taylor \& Francis}
}

@article{maleki2013bounding,
  title={Bounding the estimation error of sampling-based Shapley value approximation},
  author={Maleki, Sasan and Tran-Thanh, Long and Hines, Greg and Rahwan, Talal and Rogers, Alex},
  journal={arXiv preprint arXiv:1306.4265},
  year={2013}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

@inproceedings{krizhevsky2009learning,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Alex Krizhevsky},
  year={2009}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{liebchen2008data,
  title={Data sets and data quality in software engineering},
  author={Liebchen, Gernot A and Shepperd, Martin},
  booktitle={Proceedings of the 4th international workshop on Predictor models in software engineering},
  pages={39--44},
  year={2008}
}

@article{karimi2020deep,
  title={Deep learning with noisy labels: Exploring techniques and remedies in medical image analysis},
  author={Karimi, Davood and Dou, Haoran and Warfield, Simon K and Gholipour, Ali},
  journal={Medical Image Analysis},
  volume={65},
  pages={101759},
  year={2020},
  publisher={Elsevier}
}

@article{zar1972significance,
  title={Significance testing of the Spearman rank correlation coefficient},
  author={Zar, Jerrold H},
  journal={Journal of the American Statistical Association},
  volume={67},
  number={339},
  pages={578--580},
  year={1972},
  publisher={Taylor \& Francis}
}

@article{zar2005spearman,
  title={Spearman rank correlation},
  author={Zar, Jerrold H},
  journal={Encyclopedia of biostatistics},
  volume={7},
  year={2005},
  publisher={Wiley Online Library}
}

@article{jaccard1912distribution,
  title={The distribution of the flora in the alpine zone. 1},
  author={Jaccard, Paul},
  journal={New phytologist},
  volume={11},
  number={2},
  pages={37--50},
  year={1912},
  publisher={Wiley Online Library}
}

@article{fan2021improving,
  title={Improving Fairness for Data Valuation in Federated Learning},
  author={Fan, Zhenan and Fang, Huang and Zhou, Zirui and Pei, Jian and Friedlander, Michael P and Liu, Changxin and Zhang, Yong},
  journal={arXiv preprint arXiv:2109.09046},
  year={2021}
}

@article{Gong2016PrivateDA,
  title={Private Data Analytics on Biomedical Sensing Data via Distributed Computation},
  author={Yanmin Gong and Yuguang Fang and Yuanxiong Guo},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  year={2016},
  volume={13},
  pages={431-444}
}

@article{Zhang2018FeatureDistributedSF,
  title={Feature-Distributed SVRG for High-Dimensional Linear Classification},
  author={Gong-Duo Zhang and Shen-Yi Zhao and Hao Gao and Wu-Jun Li},
  journal={ArXiv},
  year={2018},
  volume={abs/1802.03604}
}

@article{liu2019communication,
  title={A communication efficient collaborative learning framework for distributed features},
  author={Liu, Yang and Kang, Yan and Zhang, Xinwei and Li, Liping and Cheng, Yong and Chen, Tianjian and Hong, Mingyi and Yang, Qiang},
  journal={arXiv preprint arXiv:1912.11187},
  year={2019}
}

@article{Hu2019FDMLAC,
  title={FDML: A Collaborative Machine Learning Framework for Distributed Features},
  author={Yaochen Hu and Di Niu and Jianming Yang and Shengping Zhou},
  journal={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  year={2019}
}

@article{Gu2020PrivacyPreservingAF,
  title={Privacy-Preserving Asynchronous Federated Learning Algorithms for Multi-Party Vertically Collaborative Learning},
  author={Bin Gu and An Xu and Zhouyuan Huo and Cheng Deng and Heng Huang},
  journal={ArXiv},
  year={2020},
  volume={abs/2008.06233}
}

@article{chen2020vafl,
  title={Vafl: a method of vertical asynchronous federated learning},
  author={Chen, Tianyi and Jin, Xiao and Sun, Yuejiao and Yin, Wotao},
  journal={arXiv preprint arXiv:2007.06081},
  year={2020}
}

@article{han2021data,
  title={Data Valuation for Vertical Federated Learning: An Information-Theoretic Approach},
  author={Han, Xiao and Wang, Leye and Wu, Junjie},
  journal={arXiv preprint arXiv:2112.08364},
  year={2021}
}

@book{achen1982interpreting,
  title={Interpreting and using regression},
  author={Achen, Christopher H},
  volume={29},
  year={1982},
  publisher={Sage}
}

@article{brown2012conditional,
  title={Conditional likelihood maximisation: a unifying framework for information theoretic feature selection},
  author={Brown, Gavin and Pocock, Adam and Zhao, Ming-Jie and Luj{\'a}n, Mikel},
  journal={The journal of machine learning research},
  volume={13},
  pages={27--66},
  year={2012},
  publisher={JMLR. org}
}

@article{dinh2020federated,
  title={Federated learning over wireless networks: Convergence analysis and resource allocation},
  author={Dinh, Canh T and Tran, Nguyen H and Nguyen, Minh NH and Hong, Choong Seon and Bao, Wei and Zomaya, Albert Y and Gramoli, Vincent},
  journal={IEEE/ACM Transactions on Networking},
  volume={29},
  number={1},
  pages={398--409},
  year={2020},
  publisher={IEEE}
}

@inproceedings{platt1998fast,
author = {Platt, John},
title = {Fast Training of Support Vector Machines Using Sequential Minimal Optimization},
booktitle = {Advances in Kernel Methods - Support Vector Learning},
year = {1998},
month = {January},
publisher = {MIT Press},
edition = {Advances in Kernel Methods - Support Vector Learning},
}

@article{blackard1999comparative,
  title={Comparative accuracies of artificial neural networks and discriminant analysis in predicting forest cover types from cartographic variables},
  author={Blackard, Jock A and Dean, Denis J},
  journal={Computers and electronics in agriculture},
  volume={24},
  number={3},
  pages={131--151},
  year={1999},
  publisher={Elsevier}
}

@article{glrm,
    title = {Generalized Low Rank Models},
    author ={Madeleine Udell and Horn, Corinne and Zadeh, Reza and Boyd, Stephen},
    doi = {10.1561/2200000055},
    year = {2016},
    archivePrefix = "arXiv",
    eprint = {1410.0342},
    primaryClass = "stat-ml",
    journal = {Foundations and Trends in Machine Learning},
    number = {1},
    volume = {9},
    issn = {1935-8237},
    url = {http://dx.doi.org/10.1561/2200000055},
}

@article{kendall1938new,
  title={A new measure of rank correlation},
  author={Kendall, Maurice G},
  journal={Biometrika},
  volume={30},
  number={1/2},
  pages={81--93},
  year={1938},
  publisher={JSTOR}
}

@article{Bubeck15,
    author    = {S{\'{e}}bastien Bubeck},
    title     = {Convex Optimization: Algorithms and Complexity},
    journal   = {Foundations and Trends in Machine Learning},
    volume    = 8,
    number    = {3-4},
    pages     = {231--357},
    year      = 2015
}

@article{zhu1997algorithm,
  title={Algorithm 778: L-BFGS-B: Fortran subroutines for large-scale bound-constrained optimization},
  author={Zhu, Ciyou and Byrd, Richard H and Lu, Peihuang and Nocedal, Jorge},
  journal={ACM Transactions on mathematical software (TOMS)},
  volume={23},
  number={4},
  pages={550--560},
  year={1997},
  publisher={ACM New York, NY, USA}
}

@book{sra2012optimization,
  title={Optimization for machine learning},
  author={Sra, Suvrit and Nowozin, Sebastian and Wright, Stephen J},
  year={2012},
  publisher={Mit Press}
}

@book{shi2011optimization,
  title={Optimization based data mining: theory and applications},
  author={Shi, Yong and Tian, Yingjie and Kou, Gang and Peng, Yi and Li, Jianping},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@article{mattingley2010real,
  title={Real-time convex optimization in signal processing},
  author={Mattingley, John and Boyd, Stephen},
  journal={IEEE Signal processing magazine},
  volume={27},
  number={3},
  pages={50--61},
  year={2010},
  publisher={IEEE}
}

@book{palomar2010convex,
  title={Convex optimization in signal processing and communications},
  author={Palomar, Daniel P and Eldar, Yonina C},
  year={2010},
  publisher={Cambridge university press}
}

@inproceedings{wolf2020transformers,
  title={Transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  booktitle={Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations},
  pages={38--45},
  year={2020}
}

@incollection{combettes2011proximal,
  title={Proximal splitting methods in signal processing},
  author={Combettes, Patrick L and Pesquet, Jean-Christophe},
  booktitle={Fixed-point algorithms for inverse problems in science and engineering},
  pages={185--212},
  year={2011},
  publisher={Springer}
}

@article{shalev2013stochastic,
  title={Stochastic dual coordinate ascent methods for regularized loss minimization.},
  author={Shalev-Shwartz, Shai and Zhang, Tong},
  journal={Journal of Machine Learning Research},
  volume={14},
  number={2},
  year={2013}
}

@article{jaggi2014communication,
  title={Communication-efficient distributed dual coordinate ascent},
  author={Jaggi, Martin and Smith, Virginia and Tak{\'a}c, Martin and Terhorst, Jonathan and Krishnan, Sanjay and Hofmann, Thomas and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{komodakis2015playing,
  title={Playing with duality: An overview of recent primal? dual approaches for solving large-scale optimization problems},
  author={Komodakis, Nikos and Pesquet, Jean-Christophe},
  journal={IEEE Signal Processing Magazine},
  volume={32},
  number={6},
  pages={31--54},
  year={2015},
  publisher={IEEE}
}











